{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P75gWMshhfv_"
   },
   "source": [
    "# Начальная инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:55:37.639526Z",
     "iopub.status.busy": "2023-04-26T16:55:37.637888Z",
     "iopub.status.idle": "2023-04-26T16:55:37.670648Z",
     "shell.execute_reply": "2023-04-26T16:55:37.669564Z",
     "shell.execute_reply.started": "2023-04-26T16:55:37.639487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-May-2023 18:37:34\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().strftime('%d-%B-%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:55:42.267673Z",
     "iopub.status.busy": "2023-04-26T16:55:42.267293Z",
     "iopub.status.idle": "2023-04-26T16:55:45.049328Z",
     "shell.execute_reply": "2023-04-26T16:55:45.047918Z",
     "shell.execute_reply.started": "2023-04-26T16:55:42.267640Z"
    },
    "id": "65078f9a",
    "outputId": "0b40f77d-a829-4f88-8e9d-83f02bf0e4b5"
   },
   "outputs": [],
   "source": [
    "# Подключение библиотек\n",
    "\n",
    "# !pip install torch torchvision torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# !pip install scikit-learn\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import torch.optim as optim\n",
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:55:57.694675Z",
     "iopub.status.busy": "2023-04-26T16:55:57.694117Z",
     "iopub.status.idle": "2023-04-26T16:55:57.703366Z",
     "shell.execute_reply": "2023-04-26T16:55:57.701778Z",
     "shell.execute_reply.started": "2023-04-26T16:55:57.694643Z"
    },
    "id": "qZMoTvwu7wGy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Подключение вычислений на видеокарту, если доступна\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:55:59.434618Z",
     "iopub.status.busy": "2023-04-26T16:55:59.434250Z",
     "iopub.status.idle": "2023-04-26T16:55:59.442389Z",
     "shell.execute_reply": "2023-04-26T16:55:59.441325Z",
     "shell.execute_reply.started": "2023-04-26T16:55:59.434587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count = os.cpu_count()\n",
    "\n",
    "num_workers = cpu_count if device == torch.device(\"cpu\") else 0\n",
    "num_workers, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:56:01.119755Z",
     "iopub.status.busy": "2023-04-26T16:56:01.119356Z",
     "iopub.status.idle": "2023-04-26T16:56:01.135750Z",
     "shell.execute_reply": "2023-04-26T16:56:01.134489Z",
     "shell.execute_reply.started": "2023-04-26T16:56:01.119707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
      "env: PYTHONHASHSEED=42\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "%env PYTHONHASHSEED=42\n",
    "\n",
    "def set_random_state(random_state):\n",
    "    torch.manual_seed(random_state)\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(random_state)\n",
    "        torch.cuda.manual_seed(random_state)\n",
    "\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "set_random_state(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:57:05.844178Z",
     "iopub.status.busy": "2023-04-26T16:57:05.843796Z",
     "iopub.status.idle": "2023-04-26T16:57:05.849819Z",
     "shell.execute_reply": "2023-04-26T16:57:05.848749Z",
     "shell.execute_reply.started": "2023-04-26T16:57:05.844141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-May-2023 18:37:49\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now().strftime('%d-%B-%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение нейронных сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "PATH = 'dumps/'\n",
    "with open(PATH + 'X_train_ft_pre_trained.pkl', mode='rb') as file:\n",
    "    X_train_ft_pre_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_train_w2v_pre_trained.pkl', mode='rb') as file:\n",
    "    X_train_w2v_pre_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_test_w2v_pre_trained.pkl', mode='rb') as file:\n",
    "    X_test_w2v_pre_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_test_w2v_self_trained.pkl', mode='rb') as file:\n",
    "    X_test_w2v_self_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'WordsIdPad_train.pkl', mode='rb') as file:\n",
    "    WordsIdPad_train = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_test_ft_pre_trained.pkl', mode='rb') as file:\n",
    "    X_test_ft_pre_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_train_ft_self_trained.pkl', mode='rb') as file:\n",
    "    X_train_ft_self_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'WordsIdPad_test.pkl', mode='rb') as file:\n",
    "    WordsIdPad_test = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_test_ft_self_trained.pkl', mode='rb') as file:\n",
    "    X_test_ft_self_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_train_w2v_self_trained.pkl', mode='rb') as file:\n",
    "    X_train_w2v_self_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'y_train.pkl', mode='rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'y_test.pkl', mode='rb') as file:\n",
    "    y_test = pickle.load(file)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(WordsIdPad_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T07:08:51.002275Z",
     "iopub.status.busy": "2023-04-26T07:08:51.001539Z",
     "iopub.status.idle": "2023-04-26T07:08:51.012292Z",
     "shell.execute_reply": "2023-04-26T07:08:51.011046Z",
     "shell.execute_reply.started": "2023-04-26T07:08:51.002234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"embeddings\": ['w2v_pretrained', 'ft_pretrained', 'w2v_selftrained', 'ft_selftrained', 'torch.nn'],\n",
    "    \"activation_fn\": [F.relu],\n",
    "    \"learning_rate\": [0.001],\n",
    "    \"epochs\": [20, 10],\n",
    "    \"optimizer\": [optim.Adam],\n",
    "    \"batch_size\": [2048],\n",
    "    \"layers_count\": [3],\n",
    "    \"kernel_size\": [3],\n",
    "    \"stride\": [1],\n",
    "    \"initialization\": [None, torch.nn.init.kaiming_uniform_, torch.nn.init.xavier_uniform_],\n",
    "    \"regularization\": ['None', 'dropout', 'l2_reg'],\n",
    "    \"normalization\": [None, torch.nn.LayerNorm, torch.nn.BatchNorm1d],\n",
    "    \"scheduler\": [None, torch.optim.lr_scheduler.ExponentialLR, torch.optim.lr_scheduler.MultiStepLR]\n",
    "}\n",
    "\n",
    "params_list = ParameterGrid(param_grid)\n",
    "len(params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T07:08:53.619436Z",
     "iopub.status.busy": "2023-04-26T07:08:53.618466Z",
     "iopub.status.idle": "2023-04-26T07:08:53.630813Z",
     "shell.execute_reply": "2023-04-26T07:08:53.629734Z",
     "shell.execute_reply.started": "2023-04-26T07:08:53.619367Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, \n",
    "                 device=None, \n",
    "                 layers_count=None, \n",
    "                 activation_function=None, \n",
    "                 kernel=None, \n",
    "                 stride=None,\n",
    "                 internal=None,\n",
    "                 initialization=None,\n",
    "                 regularization=None,\n",
    "                 normalization=None,\n",
    "                 batch_size=None\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_size = 300\n",
    "        self.num_words = 10000\n",
    "        self.seq_len = 20 if internal else 1\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.num_words + 1, self.embedding_size, padding_idx=0, device=device) if internal else None\n",
    "        \n",
    "        self.fa = activation_function\n",
    "        \n",
    "        self.layers = nn.ModuleList([])\n",
    "        \n",
    "        self.drop = nn.Dropout1d(p=0.2) if regularization == 'dropout' else nn.Dropout1d(p=0)\n",
    "        self.norm = None\n",
    "        if normalization:\n",
    "            if normalization.__name__ == 'LayerNorm':\n",
    "                 self.norm = normalization((self.embedding_size, self.seq_len), device=device)\n",
    "            elif normalization.__name__ == 'BatchNorm1d':\n",
    "                self.norm = normalization(self.embedding_size, device=device)\n",
    "        \n",
    "        output_shape = self.seq_len\n",
    "        padding = kernel // 2\n",
    "        \n",
    "        for i in range(layers_count):\n",
    "            self.layers.append(nn.Conv1d(in_channels = self.embedding_size, out_channels = self.embedding_size, kernel_size = kernel, stride = stride, padding = padding, device=device))\n",
    "            output_shape = 1 + (output_shape + 2*padding - kernel) // stride\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(output_shape * self.embedding_size, 2, device=device)\n",
    "        \n",
    "        if initialization:\n",
    "            self.init_weights(nn.Linear, initialization)\n",
    "            self.init_weights(nn.Conv1d, initialization)\n",
    "\n",
    "    def init_weights(self, ModuleClass, weights_initializator):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, ModuleClass):\n",
    "                weights_initializator(module.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if self.embedding:\n",
    "            x = self.embedding(x)\n",
    "            x = x.reshape(len(x), self.embedding_size, self.seq_len)\n",
    "        else:\n",
    "            x = x[:, :, None]\n",
    "        \n",
    "        for conv_layer in self.layers:\n",
    "            x = conv_layer(x)\n",
    "            x = self.fa(x)\n",
    "            if self.norm:\n",
    "                x = self.norm(x)\n",
    "            x = self.drop(x)\n",
    "        \n",
    "        x = self.fc(x.reshape(x.shape[0], -1))\n",
    "        \n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T07:08:56.105676Z",
     "iopub.status.busy": "2023-04-26T07:08:56.105017Z",
     "iopub.status.idle": "2023-04-26T07:41:06.315659Z",
     "shell.execute_reply": "2023-04-26T07:41:06.314484Z",
     "shell.execute_reply.started": "2023-04-26T07:08:56.105632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810/810 [48:55<00:00,  3.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchmetrics\n",
    "from torchmetrics.classification import Accuracy, F1Score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "total = []\n",
    "\n",
    "# accuracy_criterion = Accuracy(task='multiclass', num_classes=2, multidim_average='global', average='weighted').to(device)\n",
    "f1_criterion = F1Score(task='multiclass', num_classes=2, multidim_average='global', average='weighted').to(device)\n",
    "\n",
    "for params in tqdm(params_list):\n",
    "    \n",
    "    learningRate = params['learning_rate']\n",
    "    optimizer_type = params['optimizer']\n",
    "    layers_count = params['layers_count']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    fa = params['activation_fn']\n",
    "    kernel_size = params['kernel_size']\n",
    "    stride = params['stride']\n",
    "    embeddings = params['embeddings']\n",
    "    initialization = params['initialization']\n",
    "    regularization = params['regularization']\n",
    "    normalization = params['normalization']\n",
    "    scheduler = params['scheduler']\n",
    "\n",
    "    net = Net(device=device, \n",
    "              layers_count=layers_count, \n",
    "              activation_function=fa, \n",
    "              kernel=kernel_size, \n",
    "              stride=stride, \n",
    "              internal=embeddings and (embeddings=='torch.nn'),\n",
    "              regularization=regularization,\n",
    "              initialization=initialization,\n",
    "              normalization=normalization,\n",
    "              batch_size=batch_size\n",
    "             ).to(device)\n",
    "    optimizer = optimizer_type(net.parameters(), lr=learningRate, weight_decay=(0.01 if regularization == 'l2_reg' else 0))\n",
    "    if scheduler:\n",
    "        if scheduler.__name__ == 'ExponentialLR':\n",
    "            scheduler = scheduler(optimizer, gamma=0.9)\n",
    "        elif scheduler.__name__ == 'MultiStepLR':\n",
    "            scheduler = scheduler(optimizer, milestones=list(range(0, epochs)), gamma=0.9)\n",
    "    \n",
    "    \n",
    "    XX_train, yy_train, XX_val, yy_val, XX_test, yy_test = [], [], [], [], [], []\n",
    "    \n",
    "    # divide into different embeddings\n",
    "    \n",
    "    if embeddings == 'w2v_pretrained':\n",
    "        XX_train, XX_val, yy_train, yy_val = train_test_split(X_train_w2v_pre_trained, y_train, test_size=0.2, random_state=random_state)\n",
    "        XX_test, yy_test = X_test_w2v_pre_trained, y_test\n",
    "    elif embeddings == 'w2v_selftrained':\n",
    "        XX_train, XX_val, yy_train, yy_val = train_test_split(X_train_w2v_self_trained, y_train, test_size=0.2, random_state=random_state)\n",
    "        XX_test, yy_test = X_test_w2v_self_trained, y_test\n",
    "    elif embeddings == 'ft_pretrained':\n",
    "        XX_train, XX_val, yy_train, yy_val = train_test_split(X_train_ft_pre_trained, y_train, test_size=0.2, random_state=random_state)\n",
    "        XX_test, yy_test = X_test_ft_pre_trained, y_test\n",
    "    elif embeddings == 'ft_selftrained':\n",
    "        XX_train, XX_val, yy_train, yy_val = train_test_split(X_train_ft_self_trained, y_train, test_size=0.2, random_state=random_state)\n",
    "        XX_test, yy_test = X_test_ft_self_trained, y_test\n",
    "    elif embeddings == 'torch.nn':\n",
    "        XX_train, XX_val, yy_train, yy_val = train_test_split(WordsIdPad_train, y_train, test_size=0.2, random_state=random_state)\n",
    "        XX_test, yy_test = WordsIdPad_test, y_test\n",
    "    \n",
    "    features_train = torch.tensor(XX_train, device=device, dtype=(torch.int32 if embeddings == 'torch.nn' else torch.float))\n",
    "    targets_train = torch.tensor(yy_train, device=device, dtype=torch.int32)\n",
    "    \n",
    "    features_val = torch.tensor(XX_val, device=device, dtype=(torch.int32 if embeddings == 'torch.nn' else torch.float))\n",
    "    targets_val = torch.tensor(yy_val, device=device, dtype=torch.int32)\n",
    "    \n",
    "    features_test = torch.tensor(XX_test, device=device, dtype=(torch.int32 if embeddings == 'torch.nn' else torch.float))\n",
    "    targets_test = torch.tensor(yy_test, device=device, dtype=torch.int32)\n",
    "    \n",
    "    trainset = data_utils.TensorDataset(features_train, targets_train)\n",
    "    valset = data_utils.TensorDataset(features_val, targets_val)\n",
    "    testset = data_utils.TensorDataset(features_test, targets_test)\n",
    "    \n",
    "    train_loader = data_utils.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = data_utils.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_loader = data_utils.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        \n",
    "        for X, Y in train_loader:\n",
    "            output = net(X)\n",
    "            loss = F.cross_entropy(output, Y.long())\n",
    "            \n",
    "            net.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "    \n",
    "    train_f1 = 0\n",
    "    val_f1 = 0\n",
    "    test_f1 = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        \n",
    "        # evaluate the model on train\n",
    "        targets = torch.tensor([], device=device)\n",
    "        predictions = torch.tensor([], device=device)\n",
    "\n",
    "        for X, Y in train_loader:\n",
    "            output = net(X)\n",
    "            \n",
    "            targets = torch.cat((targets, Y))\n",
    "            predictions = torch.cat((predictions, output.argmax(dim=-1)))\n",
    "        \n",
    "        train_f1 = f1_criterion(predictions, targets).item()\n",
    "\n",
    "        # evaluate the model on validation\n",
    "        targets = torch.tensor([], device=device)\n",
    "        predictions = torch.tensor([], device=device)\n",
    "\n",
    "        for X, Y in val_loader:\n",
    "            output = net(X)\n",
    "            \n",
    "            targets = torch.cat((targets, Y))\n",
    "            predictions = torch.cat((predictions, output.argmax(dim=-1)))\n",
    "        \n",
    "        val_f1 = f1_criterion(predictions, targets).item()\n",
    "\n",
    "        # evaluate the model on test\n",
    "        targets = torch.tensor([], device=device) \n",
    "        predictions = torch.tensor([], device=device)\n",
    "\n",
    "        for X, Y in test_loader:\n",
    "            output = net(X)\n",
    "            \n",
    "            targets = torch.cat((targets, Y))\n",
    "            predictions = torch.cat((predictions, output.argmax(dim=-1)))\n",
    "        \n",
    "        test_f1 = f1_criterion(predictions, targets).item()\n",
    "            \n",
    "        \n",
    "    \n",
    "    total.append({\n",
    "        'Модель': embeddings,\n",
    "        'Размер ядра': kernel_size,\n",
    "        \"Отступ\": stride,\n",
    "        'Количество слоев': layers_count,\n",
    "        'Инициализация': initialization.__name__ if initialization else None,\n",
    "        'Регуляризация': regularization,\n",
    "        'Нормализация': normalization.__name__ if normalization else None,\n",
    "        'Планировщик': type(scheduler).__name__ if scheduler else None,\n",
    "        'Количество эпох': epochs,\n",
    "        'F1-train': round(train_f1, 2),\n",
    "        'F1-val': round(val_f1, 2),\n",
    "        'F1-test': round(test_f1, 2)\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T07:42:19.497741Z",
     "iopub.status.busy": "2023-04-26T07:42:19.497296Z",
     "iopub.status.idle": "2023-04-26T07:42:19.503942Z",
     "shell.execute_reply": "2023-04-26T07:42:19.502757Z",
     "shell.execute_reply.started": "2023-04-26T07:42:19.497705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26-May-2023 18:37:53\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now().strftime('%d-%B-%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сводная таблица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T07:42:53.251780Z",
     "iopub.status.busy": "2023-04-26T07:42:53.251374Z",
     "iopub.status.idle": "2023-04-26T07:42:53.327593Z",
     "shell.execute_reply": "2023-04-26T07:42:53.326674Z",
     "shell.execute_reply.started": "2023-04-26T07:42:53.251743Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Размер ядра</th>\n",
       "      <th>Отступ</th>\n",
       "      <th>Количество слоев</th>\n",
       "      <th>Инициализация</th>\n",
       "      <th>Регуляризация</th>\n",
       "      <th>Нормализация</th>\n",
       "      <th>Планировщик</th>\n",
       "      <th>Количество эпох</th>\n",
       "      <th>F1-train</th>\n",
       "      <th>F1-val</th>\n",
       "      <th>F1-test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>torch.nn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Модель  Размер ядра  Отступ  Количество слоев     Инициализация  \\\n",
       "543   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "624   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "525   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "540   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "597   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "584   ft_selftrained            3       1                 3              None   \n",
       "491   ft_selftrained            3       1                 3              None   \n",
       "380  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "489   ft_selftrained            3       1                 3              None   \n",
       "552   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "582   ft_selftrained            3       1                 3              None   \n",
       "557   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "594   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "581   ft_selftrained            3       1                 3              None   \n",
       "626   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "611   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "578   ft_selftrained            3       1                 3              None   \n",
       "621   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "495   ft_selftrained            3       1                 3              None   \n",
       "497   ft_selftrained            3       1                 3              None   \n",
       "500   ft_selftrained            3       1                 3              None   \n",
       "528   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "324  w2v_selftrained            3       1                 3              None   \n",
       "327  w2v_selftrained            3       1                 3              None   \n",
       "518   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "516   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "336  w2v_selftrained            3       1                 3              None   \n",
       "339  w2v_selftrained            3       1                 3              None   \n",
       "572   ft_selftrained            3       1                 3              None   \n",
       "503   ft_selftrained            3       1                 3              None   \n",
       "542   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "501   ft_selftrained            3       1                 3              None   \n",
       "545   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "446  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "459  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "462  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "449  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "444  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "579   ft_selftrained            3       1                 3              None   \n",
       "447  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "596   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "461  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "486   ft_selftrained            3       1                 3              None   \n",
       "570   ft_selftrained            3       1                 3              None   \n",
       "569   ft_selftrained            3       1                 3              None   \n",
       "464  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "567   ft_selftrained            3       1                 3              None   \n",
       "468  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "473  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "555   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "554   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "599   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "488   ft_selftrained            3       1                 3              None   \n",
       "551   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "498   ft_selftrained            3       1                 3              None   \n",
       "515   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "527   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "519   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "474  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "437  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "438  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "366  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "630   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "632   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "633   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "392  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "636   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "387  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "383  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "363  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "408  w2v_selftrained            3       1                 3              None   \n",
       "357  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "356  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "353  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "338  w2v_selftrained            3       1                 3              None   \n",
       "333  w2v_selftrained            3       1                 3              None   \n",
       "329  w2v_selftrained            3       1                 3              None   \n",
       "326  w2v_selftrained            3       1                 3              None   \n",
       "407  w2v_selftrained            3       1                 3              None   \n",
       "395  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "623   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "419  w2v_selftrained            3       1                 3              None   \n",
       "600   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "522   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "435  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "434  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "432  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "603   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "420  w2v_selftrained            3       1                 3              None   \n",
       "410  w2v_selftrained            3       1                 3              None   \n",
       "606   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "605   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "608   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "609   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "414  w2v_selftrained            3       1                 3              None   \n",
       "417  w2v_selftrained            3       1                 3              None   \n",
       "524   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "513   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "381  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "416  w2v_selftrained            3       1                 3              None   \n",
       "443  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "335  w2v_selftrained            3       1                 3              None   \n",
       "470  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "341  w2v_selftrained            3       1                 3              None   \n",
       "351  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "368  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "390  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "354  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "389  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "441  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "360  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "362  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "378  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "365  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "471  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "405  w2v_selftrained            3       1                 3              None   \n",
       "635   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "638   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "576   ft_selftrained            3       1                 3              None   \n",
       "530   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "352  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "393  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "347  w2v_selftrained            3       1                 3              None   \n",
       "549   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "508   ft_selftrained            3       1                 3              None   \n",
       "355  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "340  w2v_selftrained            3       1                 3              None   \n",
       "422  w2v_selftrained            3       1                 3              None   \n",
       "427  w2v_selftrained            3       1                 3              None   \n",
       "300    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "476  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "165    ft_pretrained            3       1                 3              None   \n",
       "81    w2v_pretrained            3       1                 3              None   \n",
       "391  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "463  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "394  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "32    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "299    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "460  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "39    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "273    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "90    w2v_pretrained            3       1                 3              None   \n",
       "272    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "173    ft_pretrained            3       1                 3              None   \n",
       "66    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "622   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "615   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "59    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "436  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "29    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "433  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "218    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "93    w2v_pretrained            3       1                 3              None   \n",
       "14    w2v_pretrained            3       1                 3              None   \n",
       "550   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "228    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "379  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "138   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "514   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "140   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "255    ft_pretrained            3       1                 3              None   \n",
       "644   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "144   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "517   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "17    w2v_pretrained            3       1                 3              None   \n",
       "111   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "246    ft_pretrained            3       1                 3              None   \n",
       "194    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "361  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "245    ft_pretrained            3       1                 3              None   \n",
       "610   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "364  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "192    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "191    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "201    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "260    ft_pretrained            3       1                 3              None   \n",
       "113   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "248    ft_pretrained            3       1                 3              None   \n",
       "54    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "11    w2v_pretrained            3       1                 3              None   \n",
       "625   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "254    ft_pretrained            3       1                 3              None   \n",
       "382  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "221    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "30    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "219    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "388  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "258    ft_pretrained            3       1                 3              None   \n",
       "257    ft_pretrained            3       1                 3              None   \n",
       "179    ft_pretrained            3       1                 3              None   \n",
       "86    w2v_pretrained            3       1                 3              None   \n",
       "469  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "563   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "312    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "5     w2v_pretrained            3       1                 3              None   \n",
       "309    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "147   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "146   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "297    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "92    w2v_pretrained            3       1                 3              None   \n",
       "282    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "96    w2v_pretrained            3       1                 3              None   \n",
       "137   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "135   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "306    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "544   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "541   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "108   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "285    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "110   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "120   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "84    w2v_pretrained            3       1                 3              None   \n",
       "359  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "83    w2v_pretrained            3       1                 3              None   \n",
       "598   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "595   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "270    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "57    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "243    ft_pretrained            3       1                 3              None   \n",
       "3     w2v_pretrained            3       1                 3              None   \n",
       "177    ft_pretrained            3       1                 3              None   \n",
       "176    ft_pretrained            3       1                 3              None   \n",
       "174    ft_pretrained            3       1                 3              None   \n",
       "448  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "2     w2v_pretrained            3       1                 3              None   \n",
       "275    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "167    ft_pretrained            3       1                 3              None   \n",
       "164    ft_pretrained            3       1                 3              None   \n",
       "56    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "15    w2v_pretrained            3       1                 3              None   \n",
       "302    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "287    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "337  w2v_selftrained            3       1                 3              None   \n",
       "308    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "732         torch.nn            3       1                 3              None   \n",
       "252    ft_pretrained            3       1                 3              None   \n",
       "12    w2v_pretrained            3       1                 3              None   \n",
       "314    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "281    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "311    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "276    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "783         torch.nn            3       1                 3   xavier_uniform_   \n",
       "203    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "206    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "41    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "69    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "171    ft_pretrained            3       1                 3              None   \n",
       "68    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "65    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "440  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "162    ft_pretrained            3       1                 3              None   \n",
       "152   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "150   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "189    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "195    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "149   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "95    w2v_pretrained            3       1                 3              None   \n",
       "607   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "71    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "98    w2v_pretrained            3       1                 3              None   \n",
       "119   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "637   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "496   ft_selftrained            3       1                 3              None   \n",
       "225    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "227    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "651         torch.nn            3       1                 3              None   \n",
       "230    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "216    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "678         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "125   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "123   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "233    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "122   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "583   ft_selftrained            3       1                 3              None   \n",
       "472  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "705         torch.nn            3       1                 3   xavier_uniform_   \n",
       "785         torch.nn            3       1                 3   xavier_uniform_   \n",
       "795         torch.nn            3       1                 3   xavier_uniform_   \n",
       "602   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "786         torch.nn            3       1                 3   xavier_uniform_   \n",
       "702         torch.nn            3       1                 3   xavier_uniform_   \n",
       "604   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "731         torch.nn            3       1                 3              None   \n",
       "648         torch.nn            3       1                 3              None   \n",
       "657         torch.nn            3       1                 3              None   \n",
       "729         torch.nn            3       1                 3              None   \n",
       "367  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "660         torch.nn            3       1                 3              None   \n",
       "675         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "521   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "0     w2v_pretrained            3       1                 3              None   \n",
       "38    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "114   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "204    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "36    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "279    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "44    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "198    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "27    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "117   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "284    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "740         torch.nn            3       1                 3              None   \n",
       "741         torch.nn            3       1                 3              None   \n",
       "747         torch.nn            3       1                 3              None   \n",
       "750         torch.nn            3       1                 3              None   \n",
       "753         torch.nn            3       1                 3              None   \n",
       "653         torch.nn            3       1                 3              None   \n",
       "734         torch.nn            3       1                 3              None   \n",
       "756         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "28    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "634   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "442  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "738         torch.nn            3       1                 3              None   \n",
       "650         torch.nn            3       1                 3              None   \n",
       "725         torch.nn            3       1                 3   xavier_uniform_   \n",
       "445  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "723         torch.nn            3       1                 3   xavier_uniform_   \n",
       "717         torch.nn            3       1                 3   xavier_uniform_   \n",
       "714         torch.nn            3       1                 3   xavier_uniform_   \n",
       "666         torch.nn            3       1                 3              None   \n",
       "421  w2v_selftrained            3       1                 3              None   \n",
       "669         torch.nn            3       1                 3              None   \n",
       "200    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "415  w2v_selftrained            3       1                 3              None   \n",
       "704         torch.nn            3       1                 3   xavier_uniform_   \n",
       "671         torch.nn            3       1                 3              None   \n",
       "699         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "696         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "231    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "687         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "42    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "529   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "271    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "580   ft_selftrained            3       1                 3              None   \n",
       "553   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "556   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "590   ft_selftrained            3       1                 3              None   \n",
       "804         torch.nn            3       1                 3   xavier_uniform_   \n",
       "662         torch.nn            3       1                 3              None   \n",
       "665         torch.nn            3       1                 3              None   \n",
       "112   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "716         torch.nn            3       1                 3   xavier_uniform_   \n",
       "663         torch.nn            3       1                 3              None   \n",
       "374  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "426  w2v_selftrained            3       1                 3              None   \n",
       "280    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "109   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "668         torch.nn            3       1                 3              None   \n",
       "301    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "475  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "13    w2v_pretrained            3       1                 3              None   \n",
       "801         torch.nn            3       1                 3   xavier_uniform_   \n",
       "708         torch.nn            3       1                 3   xavier_uniform_   \n",
       "707         torch.nn            3       1                 3   xavier_uniform_   \n",
       "298    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "499   ft_selftrained            3       1                 3              None   \n",
       "136   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "672         torch.nn            3       1                 3              None   \n",
       "807         torch.nn            3       1                 3   xavier_uniform_   \n",
       "673         torch.nn            3       1                 3              None   \n",
       "690         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "19    w2v_pretrained            3       1                 3              None   \n",
       "770         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "490   ft_selftrained            3       1                 3              None   \n",
       "9     w2v_pretrained            3       1                 3              None   \n",
       "746         torch.nn            3       1                 3              None   \n",
       "768         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "762         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "759         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "63    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "755         torch.nn            3       1                 3              None   \n",
       "754         torch.nn            3       1                 3              None   \n",
       "593   ft_selftrained            3       1                 3              None   \n",
       "749         torch.nn            3       1                 3              None   \n",
       "748         torch.nn            3       1                 3              None   \n",
       "752         torch.nn            3       1                 3              None   \n",
       "739         torch.nn            3       1                 3              None   \n",
       "659         torch.nn            3       1                 3              None   \n",
       "743         torch.nn            3       1                 3              None   \n",
       "190    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "737         torch.nn            3       1                 3              None   \n",
       "94    w2v_pretrained            3       1                 3              None   \n",
       "684         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "681         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "99    w2v_pretrained            3       1                 3              None   \n",
       "631   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "677         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "674         torch.nn            3       1                 3              None   \n",
       "139   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "55    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "526   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "58    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "658         torch.nn            3       1                 3              None   \n",
       "64    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "121   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "664         torch.nn            3       1                 3              None   \n",
       "67    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "661         torch.nn            3       1                 3              None   \n",
       "402  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "193    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "523   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "175    ft_pretrained            3       1                 3              None   \n",
       "809         torch.nn            3       1                 3   xavier_uniform_   \n",
       "226    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "742         torch.nn            3       1                 3              None   \n",
       "797         torch.nn            3       1                 3   xavier_uniform_   \n",
       "771         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "720         torch.nn            3       1                 3   xavier_uniform_   \n",
       "371  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "792         torch.nn            3       1                 3   xavier_uniform_   \n",
       "789         torch.nn            3       1                 3   xavier_uniform_   \n",
       "780         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "711         torch.nn            3       1                 3   xavier_uniform_   \n",
       "745         torch.nn            3       1                 3              None   \n",
       "751         torch.nn            3       1                 3              None   \n",
       "777         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "758         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "765         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "774         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "798         torch.nn            3       1                 3   xavier_uniform_   \n",
       "773         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "695         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "806         torch.nn            3       1                 3   xavier_uniform_   \n",
       "800         torch.nn            3       1                 3   xavier_uniform_   \n",
       "16    w2v_pretrained            3       1                 3              None   \n",
       "145   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "689         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "398  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "693         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "779         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "43    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "274    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "776         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "803         torch.nn            3       1                 3   xavier_uniform_   \n",
       "155   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "124   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "307    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "148   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "788         torch.nn            3       1                 3   xavier_uniform_   \n",
       "286    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "151   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "794         torch.nn            3       1                 3   xavier_uniform_   \n",
       "310    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "799         torch.nn            3       1                 3   xavier_uniform_   \n",
       "686         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "217    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "698         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "719         torch.nn            3       1                 3   xavier_uniform_   \n",
       "713         torch.nn            3       1                 3   xavier_uniform_   \n",
       "722         torch.nn            3       1                 3   xavier_uniform_   \n",
       "710         torch.nn            3       1                 3   xavier_uniform_   \n",
       "670         torch.nn            3       1                 3              None   \n",
       "199    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "202    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "728         torch.nn            3       1                 3   xavier_uniform_   \n",
       "667         torch.nn            3       1                 3              None   \n",
       "256    ft_pretrained            3       1                 3              None   \n",
       "259    ft_pretrained            3       1                 3              None   \n",
       "31    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "694         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "701         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "802         torch.nn            3       1                 3   xavier_uniform_   \n",
       "692         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "688         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "712         torch.nn            3       1                 3   xavier_uniform_   \n",
       "808         torch.nn            3       1                 3   xavier_uniform_   \n",
       "772         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "793         torch.nn            3       1                 3   xavier_uniform_   \n",
       "796         torch.nn            3       1                 3   xavier_uniform_   \n",
       "721         torch.nn            3       1                 3   xavier_uniform_   \n",
       "37    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "791         torch.nn            3       1                 3   xavier_uniform_   \n",
       "577   ft_selftrained            3       1                 3              None   \n",
       "727         torch.nn            3       1                 3   xavier_uniform_   \n",
       "74    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "781         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "744         torch.nn            3       1                 3              None   \n",
       "766         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "775         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "767         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "685         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "40    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "769         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "97    w2v_pretrained            3       1                 3              None   \n",
       "348  w2v_selftrained            3       1                 3              None   \n",
       "232    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "267    ft_pretrained            3       1                 3              None   \n",
       "205    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "283    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "220    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "313    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "239    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "718         torch.nn            3       1                 3   xavier_uniform_   \n",
       "118   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "782         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "724         torch.nn            3       1                 3   xavier_uniform_   \n",
       "70    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "613   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "764         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "700         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "683         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "715         torch.nn            3       1                 3   xavier_uniform_   \n",
       "656         torch.nn            3       1                 3              None   \n",
       "805         torch.nn            3       1                 3   xavier_uniform_   \n",
       "430  w2v_selftrained            3       1                 3              None   \n",
       "510   ft_selftrained            3       1                 3              None   \n",
       "726         torch.nn            3       1                 3   xavier_uniform_   \n",
       "761         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "616   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "691         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "290    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "697         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "376  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "680         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "229    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "321    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "241    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "487   ft_selftrained            3       1                 3              None   \n",
       "295    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "778         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "178    ft_pretrained            3       1                 3              None   \n",
       "292    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "24    w2v_pretrained            3       1                 3              None   \n",
       "345  w2v_selftrained            3       1                 3              None   \n",
       "18    w2v_pretrained            3       1                 3              None   \n",
       "91    w2v_pretrained            3       1                 3              None   \n",
       "82    w2v_pretrained            3       1                 3              None   \n",
       "787         torch.nn            3       1                 3   xavier_uniform_   \n",
       "318    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "186    ft_pretrained            3       1                 3              None   \n",
       "316    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "172    ft_pretrained            3       1                 3              None   \n",
       "247    ft_pretrained            3       1                 3              None   \n",
       "538   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "25    w2v_pretrained            3       1                 3              None   \n",
       "253    ft_pretrained            3       1                 3              None   \n",
       "757         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "10    w2v_pretrained            3       1                 3              None   \n",
       "397  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "244    ft_pretrained            3       1                 3              None   \n",
       "51    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "763         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "452  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "154   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "409  w2v_selftrained            3       1                 3              None   \n",
       "502   ft_selftrained            3       1                 3              None   \n",
       "240    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "703         torch.nn            3       1                 3   xavier_uniform_   \n",
       "709         torch.nn            3       1                 3   xavier_uniform_   \n",
       "406  w2v_selftrained            3       1                 3              None   \n",
       "294    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "325  w2v_selftrained            3       1                 3              None   \n",
       "334  w2v_selftrained            3       1                 3              None   \n",
       "533   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "539   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "730         torch.nn            3       1                 3              None   \n",
       "706         torch.nn            3       1                 3   xavier_uniform_   \n",
       "682         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "183    ft_pretrained            3       1                 3              None   \n",
       "676         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "784         torch.nn            3       1                 3   xavier_uniform_   \n",
       "76    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "328  w2v_selftrained            3       1                 3              None   \n",
       "564   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "100   w2v_pretrained            3       1                 3              None   \n",
       "614   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "617   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "46    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "512   ft_selftrained            3       1                 3              None   \n",
       "451  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "679         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "262    ft_pretrained            3       1                 3              None   \n",
       "760         torch.nn            3       1                 3  kaiming_uniform_   \n",
       "320    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "242    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "619   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "181    ft_pretrained            3       1                 3              None   \n",
       "266    ft_pretrained            3       1                 3              None   \n",
       "116   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "50    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "160   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "647   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "237    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "101   w2v_pretrained            3       1                 3              None   \n",
       "77    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "85    w2v_pretrained            3       1                 3              None   \n",
       "343  w2v_selftrained            3       1                 3              None   \n",
       "620   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "399  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "642   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "423  w2v_selftrained            3       1                 3              None   \n",
       "78    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "790         torch.nn            3       1                 3   xavier_uniform_   \n",
       "536   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "537   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "53    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "215    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "649         torch.nn            3       1                 3              None   \n",
       "344  w2v_selftrained            3       1                 3              None   \n",
       "315    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "375  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "424  w2v_selftrained            3       1                 3              None   \n",
       "418  w2v_selftrained            3       1                 3              None   \n",
       "26    w2v_pretrained            3       1                 3              None   \n",
       "293    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "612   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "180    ft_pretrained            3       1                 3              None   \n",
       "330  w2v_selftrained            3       1                 3              None   \n",
       "277    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "269    ft_pretrained            3       1                 3              None   \n",
       "8     w2v_pretrained            3       1                 3              None   \n",
       "331  w2v_selftrained            3       1                 3              None   \n",
       "7     w2v_pretrained            3       1                 3              None   \n",
       "6     w2v_pretrained            3       1                 3              None   \n",
       "412  w2v_selftrained            3       1                 3              None   \n",
       "4     w2v_pretrained            3       1                 3              None   \n",
       "411  w2v_selftrained            3       1                 3              None   \n",
       "278    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "1     w2v_pretrained            3       1                 3              None   \n",
       "413  w2v_selftrained            3       1                 3              None   \n",
       "305    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "197    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "196    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "304    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "303    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "428  w2v_selftrained            3       1                 3              None   \n",
       "289    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "429  w2v_selftrained            3       1                 3              None   \n",
       "332  w2v_selftrained            3       1                 3              None   \n",
       "222    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "404  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "263    ft_pretrained            3       1                 3              None   \n",
       "224    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "384  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "385  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "377  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "386  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "370  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "234    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "214    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "235    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "21    w2v_pretrained            3       1                 3              None   \n",
       "733         torch.nn            3       1                 3              None   \n",
       "213    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "238    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "735         torch.nn            3       1                 3              None   \n",
       "211    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "736         torch.nn            3       1                 3              None   \n",
       "358  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "249    ft_pretrained            3       1                 3              None   \n",
       "250    ft_pretrained            3       1                 3              None   \n",
       "251    ft_pretrained            3       1                 3              None   \n",
       "209    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "349  w2v_selftrained            3       1                 3              None   \n",
       "346  w2v_selftrained            3       1                 3              None   \n",
       "208    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "396  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "342  w2v_selftrained            3       1                 3              None   \n",
       "223    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "431  w2v_selftrained            3       1                 3              None   \n",
       "484  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "568   ft_selftrained            3       1                 3              None   \n",
       "87    w2v_pretrained            3       1                 3              None   \n",
       "531   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "532   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "535   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "104   w2v_pretrained            3       1                 3              None   \n",
       "546   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "547   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "548   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "465  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "89    w2v_pretrained            3       1                 3              None   \n",
       "88    w2v_pretrained            3       1                 3              None   \n",
       "161   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "559   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "588   ft_selftrained            3       1                 3              None   \n",
       "562   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "80    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "79    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "571   ft_selftrained            3       1                 3              None   \n",
       "573   ft_selftrained            3       1                 3              None   \n",
       "574   ft_selftrained            3       1                 3              None   \n",
       "575   ft_selftrained            3       1                 3              None   \n",
       "163    ft_pretrained            3       1                 3              None   \n",
       "166    ft_pretrained            3       1                 3              None   \n",
       "168    ft_pretrained            3       1                 3              None   \n",
       "72    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "106   w2v_pretrained            3       1                 3              None   \n",
       "466  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "107   w2v_pretrained            3       1                 3              None   \n",
       "467  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "483  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "143   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "142   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "141   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "492   ft_selftrained            3       1                 3              None   \n",
       "493   ft_selftrained            3       1                 3              None   \n",
       "494   ft_selftrained            3       1                 3              None   \n",
       "481  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "480  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "131   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "130   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "504   ft_selftrained            3       1                 3              None   \n",
       "506   ft_selftrained            3       1                 3              None   \n",
       "507   ft_selftrained            3       1                 3              None   \n",
       "129   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "509   ft_selftrained            3       1                 3              None   \n",
       "511   ft_selftrained            3       1                 3              None   \n",
       "128   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "127   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "126   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "520   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "115   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "158   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "585   ft_selftrained            3       1                 3              None   \n",
       "291    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "628   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "618   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "450  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "601   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "169    ft_pretrained            3       1                 3              None   \n",
       "170    ft_pretrained            3       1                 3              None   \n",
       "453  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "627   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "629   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "35    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "60    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "61    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "62    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "34    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "33    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "439  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "456  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "641   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "645   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "592   ft_selftrained            3       1                 3              None   \n",
       "591   ft_selftrained            3       1                 3              None   \n",
       "646   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "485  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "652         torch.nn            3       1                 3              None   \n",
       "654         torch.nn            3       1                 3              None   \n",
       "655         torch.nn            3       1                 3              None   \n",
       "22    w2v_pretrained            3       1                 3              None   \n",
       "52    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "587   ft_selftrained            3       1                 3              None   \n",
       "482  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "212    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "103   w2v_pretrained            3       1                 3              None   \n",
       "322    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "261    ft_pretrained            3       1                 3              None   \n",
       "323    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "403  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "187    ft_pretrained            3       1                 3              None   \n",
       "640   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "105   w2v_pretrained            3       1                 3              None   \n",
       "23    w2v_pretrained            3       1                 3              None   \n",
       "643   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "132   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "268    ft_pretrained            3       1                 3              None   \n",
       "425  w2v_selftrained            3       1                 3              None   \n",
       "45    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "182    ft_pretrained            3       1                 3              None   \n",
       "455  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "159   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "350  w2v_selftrained            3       1                 3              None   \n",
       "156   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "265    ft_pretrained            3       1                 3              None   \n",
       "288    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "372  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "639   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "20    w2v_pretrained            3       1                 3              None   \n",
       "505   ft_selftrained            3       1                 3              None   \n",
       "317    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "458  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "373  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "457  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "134   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "133   w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "185    ft_pretrained            3       1                 3              None   \n",
       "75    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "73    w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "369  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "589   ft_selftrained            3       1                 3              None   \n",
       "296    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "479  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "48    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "207    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "184    ft_pretrained            3       1                 3              None   \n",
       "47    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "210    ft_pretrained            3       1                 3  kaiming_uniform_   \n",
       "49    w2v_pretrained            3       1                 3  kaiming_uniform_   \n",
       "102   w2v_pretrained            3       1                 3              None   \n",
       "558   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "560   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "534   ft_selftrained            3       1                 3  kaiming_uniform_   \n",
       "561   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "565   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "264    ft_pretrained            3       1                 3              None   \n",
       "586   ft_selftrained            3       1                 3              None   \n",
       "400  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "401  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "566   ft_selftrained            3       1                 3   xavier_uniform_   \n",
       "157   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "454  w2v_selftrained            3       1                 3  kaiming_uniform_   \n",
       "153   w2v_pretrained            3       1                 3   xavier_uniform_   \n",
       "477  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "478  w2v_selftrained            3       1                 3   xavier_uniform_   \n",
       "319    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "236    ft_pretrained            3       1                 3   xavier_uniform_   \n",
       "188    ft_pretrained            3       1                 3              None   \n",
       "\n",
       "    Регуляризация Нормализация    Планировщик  Количество эпох  F1-train  \\\n",
       "543       dropout         None           None               20      0.83   \n",
       "624       dropout         None           None               10      0.75   \n",
       "525       dropout    LayerNorm           None               20      0.75   \n",
       "540          None         None           None               20      0.81   \n",
       "597       dropout         None           None               10      0.75   \n",
       "584        l2_reg    LayerNorm    MultiStepLR               10      0.71   \n",
       "491       dropout         None    MultiStepLR               20      0.72   \n",
       "380          None         None    MultiStepLR               20      0.73   \n",
       "489       dropout         None           None               20      0.78   \n",
       "552       dropout    LayerNorm           None               20      0.74   \n",
       "582        l2_reg    LayerNorm           None               10      0.72   \n",
       "557        l2_reg    LayerNorm    MultiStepLR               20      0.72   \n",
       "594          None         None           None               10      0.74   \n",
       "581       dropout    LayerNorm    MultiStepLR               10      0.72   \n",
       "626       dropout         None    MultiStepLR               10      0.72   \n",
       "611        l2_reg    LayerNorm    MultiStepLR               10      0.72   \n",
       "578          None    LayerNorm    MultiStepLR               10      0.72   \n",
       "621          None         None           None               10      0.74   \n",
       "495          None    LayerNorm           None               20      0.73   \n",
       "497          None    LayerNorm    MultiStepLR               20      0.74   \n",
       "500       dropout    LayerNorm    MultiStepLR               20      0.73   \n",
       "528        l2_reg    LayerNorm           None               20      0.79   \n",
       "324          None         None           None               20      0.80   \n",
       "327       dropout         None           None               20      0.83   \n",
       "518       dropout         None    MultiStepLR               20      0.73   \n",
       "516       dropout         None           None               20      0.84   \n",
       "336       dropout    LayerNorm           None               20      0.74   \n",
       "339        l2_reg    LayerNorm           None               20      0.73   \n",
       "572       dropout         None    MultiStepLR               10      0.72   \n",
       "503        l2_reg    LayerNorm    MultiStepLR               20      0.72   \n",
       "542          None         None    MultiStepLR               20      0.73   \n",
       "501        l2_reg    LayerNorm           None               20      0.73   \n",
       "545       dropout         None    MultiStepLR               20      0.72   \n",
       "446       dropout    LayerNorm    MultiStepLR               10      0.72   \n",
       "459          None         None           None               10      0.77   \n",
       "462       dropout         None           None               10      0.76   \n",
       "449        l2_reg    LayerNorm    MultiStepLR               10      0.75   \n",
       "444       dropout    LayerNorm           None               10      0.72   \n",
       "579       dropout    LayerNorm           None               10      0.72   \n",
       "447        l2_reg    LayerNorm           None               10      0.78   \n",
       "596          None         None    MultiStepLR               10      0.71   \n",
       "461          None         None    MultiStepLR               10      0.72   \n",
       "486          None         None           None               20      0.77   \n",
       "570       dropout         None           None               10      0.72   \n",
       "569          None         None    MultiStepLR               10      0.72   \n",
       "464       dropout         None    MultiStepLR               10      0.72   \n",
       "567          None         None           None               10      0.73   \n",
       "468          None    LayerNorm           None               10      0.73   \n",
       "473       dropout    LayerNorm    MultiStepLR               10      0.72   \n",
       "555        l2_reg    LayerNorm           None               20      0.72   \n",
       "554       dropout    LayerNorm    MultiStepLR               20      0.71   \n",
       "599       dropout         None    MultiStepLR               10      0.73   \n",
       "488          None         None    MultiStepLR               20      0.72   \n",
       "551          None    LayerNorm    MultiStepLR               20      0.71   \n",
       "498       dropout    LayerNorm           None               20      0.76   \n",
       "515          None         None    MultiStepLR               20      0.73   \n",
       "527       dropout    LayerNorm    MultiStepLR               20      0.72   \n",
       "519        l2_reg         None           None               20      0.71   \n",
       "474        l2_reg    LayerNorm           None               10      0.72   \n",
       "437       dropout         None    MultiStepLR               10      0.73   \n",
       "438        l2_reg         None           None               10      0.71   \n",
       "366        l2_reg    LayerNorm           None               20      0.78   \n",
       "630          None    LayerNorm           None               10      0.72   \n",
       "632          None    LayerNorm    MultiStepLR               10      0.72   \n",
       "633       dropout    LayerNorm           None               10      0.72   \n",
       "392       dropout    LayerNorm    MultiStepLR               20      0.73   \n",
       "636        l2_reg    LayerNorm           None               10      0.72   \n",
       "387          None    LayerNorm           None               20      0.82   \n",
       "383       dropout         None    MultiStepLR               20      0.72   \n",
       "363       dropout    LayerNorm           None               20      0.77   \n",
       "408       dropout         None           None               10      0.74   \n",
       "357        l2_reg         None           None               20      0.72   \n",
       "356       dropout         None    MultiStepLR               20      0.72   \n",
       "353          None         None    MultiStepLR               20      0.73   \n",
       "338       dropout    LayerNorm    MultiStepLR               20      0.73   \n",
       "333          None    LayerNorm           None               20      0.75   \n",
       "329       dropout         None    MultiStepLR               20      0.72   \n",
       "326          None         None    MultiStepLR               20      0.72   \n",
       "407          None         None    MultiStepLR               10      0.71   \n",
       "395        l2_reg    LayerNorm    MultiStepLR               20      0.73   \n",
       "623          None         None    MultiStepLR               10      0.73   \n",
       "419       dropout    LayerNorm    MultiStepLR               10      0.72   \n",
       "600        l2_reg         None           None               10      0.71   \n",
       "522          None    LayerNorm           None               20      0.79   \n",
       "435       dropout         None           None               10      0.75   \n",
       "434          None         None    MultiStepLR               10      0.73   \n",
       "432          None         None           None               10      0.76   \n",
       "603          None    LayerNorm           None               10      0.74   \n",
       "420        l2_reg    LayerNorm           None               10      0.71   \n",
       "410       dropout         None    MultiStepLR               10      0.71   \n",
       "606       dropout    LayerNorm           None               10      0.72   \n",
       "605          None    LayerNorm    MultiStepLR               10      0.73   \n",
       "608       dropout    LayerNorm    MultiStepLR               10      0.72   \n",
       "609        l2_reg    LayerNorm           None               10      0.74   \n",
       "414          None    LayerNorm           None               10      0.71   \n",
       "417       dropout    LayerNorm           None               10      0.71   \n",
       "524          None    LayerNorm    MultiStepLR               20      0.75   \n",
       "513          None         None           None               20      0.84   \n",
       "381       dropout         None           None               20      0.84   \n",
       "416          None    LayerNorm    MultiStepLR               10      0.71   \n",
       "443          None    LayerNorm    MultiStepLR               10      0.74   \n",
       "335          None    LayerNorm    MultiStepLR               20      0.73   \n",
       "470          None    LayerNorm    MultiStepLR               10      0.72   \n",
       "341        l2_reg    LayerNorm    MultiStepLR               20      0.72   \n",
       "351          None         None           None               20      0.87   \n",
       "368        l2_reg    LayerNorm    MultiStepLR               20      0.74   \n",
       "390       dropout    LayerNorm           None               20      0.78   \n",
       "354       dropout         None           None               20      0.86   \n",
       "389          None    LayerNorm    MultiStepLR               20      0.74   \n",
       "441          None    LayerNorm           None               10      0.74   \n",
       "360          None    LayerNorm           None               20      0.85   \n",
       "362          None    LayerNorm    MultiStepLR               20      0.75   \n",
       "378          None         None           None               20      0.82   \n",
       "365       dropout    LayerNorm    MultiStepLR               20      0.71   \n",
       "471       dropout    LayerNorm           None               10      0.71   \n",
       "405          None         None           None               10      0.72   \n",
       "635       dropout    LayerNorm    MultiStepLR               10      0.70   \n",
       "638        l2_reg    LayerNorm    MultiStepLR               10      0.71   \n",
       "576          None    LayerNorm           None               10      0.71   \n",
       "530        l2_reg    LayerNorm    MultiStepLR               20      0.74   \n",
       "352          None         None  ExponentialLR               20      0.69   \n",
       "393        l2_reg    LayerNorm           None               20      0.71   \n",
       "347       dropout  BatchNorm1d    MultiStepLR               20      0.72   \n",
       "549          None    LayerNorm           None               20      0.84   \n",
       "508       dropout  BatchNorm1d  ExponentialLR               20      0.69   \n",
       "355       dropout         None  ExponentialLR               20      0.69   \n",
       "340        l2_reg    LayerNorm  ExponentialLR               20      0.69   \n",
       "422        l2_reg    LayerNorm    MultiStepLR               10      0.70   \n",
       "427       dropout  BatchNorm1d  ExponentialLR               10      0.70   \n",
       "300       dropout         None           None               10      0.76   \n",
       "476        l2_reg    LayerNorm    MultiStepLR               10      0.71   \n",
       "165       dropout         None           None               20      0.82   \n",
       "81           None         None           None               10      0.71   \n",
       "391       dropout    LayerNorm  ExponentialLR               20      0.67   \n",
       "463       dropout         None  ExponentialLR               10      0.68   \n",
       "394        l2_reg    LayerNorm  ExponentialLR               20      0.68   \n",
       "32        dropout         None    MultiStepLR               20      0.69   \n",
       "299          None         None    MultiStepLR               10      0.70   \n",
       "460          None         None  ExponentialLR               10      0.68   \n",
       "39        dropout    LayerNorm           None               20      0.79   \n",
       "273       dropout         None           None               10      0.74   \n",
       "90           None    LayerNorm           None               10      0.69   \n",
       "272          None         None    MultiStepLR               10      0.70   \n",
       "173          None    LayerNorm    MultiStepLR               20      0.73   \n",
       "66        dropout    LayerNorm           None               20      0.77   \n",
       "622          None         None  ExponentialLR               10      0.68   \n",
       "615       dropout  BatchNorm1d           None               10      0.69   \n",
       "59        dropout         None    MultiStepLR               20      0.69   \n",
       "436       dropout         None  ExponentialLR               10      0.67   \n",
       "29           None         None    MultiStepLR               20      0.70   \n",
       "433          None         None  ExponentialLR               10      0.69   \n",
       "218          None         None    MultiStepLR               20      0.70   \n",
       "93        dropout    LayerNorm           None               10      0.71   \n",
       "14        dropout    LayerNorm    MultiStepLR               20      0.71   \n",
       "550          None    LayerNorm  ExponentialLR               20      0.67   \n",
       "228       dropout    LayerNorm           None               20      0.75   \n",
       "379          None         None  ExponentialLR               20      0.68   \n",
       "138       dropout         None           None               10      0.75   \n",
       "514          None         None  ExponentialLR               20      0.68   \n",
       "140       dropout         None    MultiStepLR               10      0.70   \n",
       "255       dropout    LayerNorm           None               10      0.69   \n",
       "644       dropout  BatchNorm1d    MultiStepLR               10      0.68   \n",
       "144          None    LayerNorm           None               10      0.78   \n",
       "517       dropout         None  ExponentialLR               20      0.68   \n",
       "17         l2_reg    LayerNorm    MultiStepLR               20      0.71   \n",
       "111       dropout         None           None               10      0.75   \n",
       "246       dropout         None           None               10      0.72   \n",
       "194       dropout         None    MultiStepLR               20      0.70   \n",
       "361          None    LayerNorm  ExponentialLR               20      0.69   \n",
       "245          None         None    MultiStepLR               10      0.68   \n",
       "610        l2_reg    LayerNorm  ExponentialLR               10      0.67   \n",
       "364       dropout    LayerNorm  ExponentialLR               20      0.67   \n",
       "192       dropout         None           None               20      0.88   \n",
       "191          None         None    MultiStepLR               20      0.70   \n",
       "201       dropout    LayerNorm           None               20      0.81   \n",
       "260        l2_reg    LayerNorm    MultiStepLR               10      0.69   \n",
       "113       dropout         None    MultiStepLR               10      0.69   \n",
       "248       dropout         None    MultiStepLR               10      0.68   \n",
       "54           None         None           None               20      0.90   \n",
       "11           None    LayerNorm    MultiStepLR               20      0.72   \n",
       "625       dropout         None  ExponentialLR               10      0.66   \n",
       "254          None    LayerNorm    MultiStepLR               10      0.68   \n",
       "382       dropout         None  ExponentialLR               20      0.67   \n",
       "221       dropout         None    MultiStepLR               20      0.69   \n",
       "30        dropout         None           None               20      0.87   \n",
       "219       dropout         None           None               20      0.89   \n",
       "388          None    LayerNorm  ExponentialLR               20      0.66   \n",
       "258        l2_reg    LayerNorm           None               10      0.69   \n",
       "257       dropout    LayerNorm    MultiStepLR               10      0.68   \n",
       "179        l2_reg    LayerNorm    MultiStepLR               20      0.71   \n",
       "86        dropout         None    MultiStepLR               10      0.68   \n",
       "469          None    LayerNorm  ExponentialLR               10      0.67   \n",
       "563       dropout  BatchNorm1d    MultiStepLR               20      0.69   \n",
       "312        l2_reg    LayerNorm           None               10      0.71   \n",
       "5         dropout         None    MultiStepLR               20      0.68   \n",
       "309       dropout    LayerNorm           None               10      0.72   \n",
       "147       dropout    LayerNorm           None               10      0.70   \n",
       "146          None    LayerNorm    MultiStepLR               10      0.72   \n",
       "297          None         None           None               10      0.75   \n",
       "92           None    LayerNorm    MultiStepLR               10      0.69   \n",
       "282       dropout    LayerNorm           None               10      0.73   \n",
       "96         l2_reg    LayerNorm           None               10      0.69   \n",
       "137          None         None    MultiStepLR               10      0.70   \n",
       "135          None         None           None               10      0.76   \n",
       "306          None    LayerNorm           None               10      0.72   \n",
       "544       dropout         None  ExponentialLR               20      0.67   \n",
       "541          None         None  ExponentialLR               20      0.67   \n",
       "108          None         None           None               10      0.77   \n",
       "285        l2_reg    LayerNorm           None               10      0.80   \n",
       "110          None         None    MultiStepLR               10      0.70   \n",
       "120       dropout    LayerNorm           None               10      0.72   \n",
       "84        dropout         None           None               10      0.71   \n",
       "359        l2_reg         None    MultiStepLR               20      0.66   \n",
       "83           None         None    MultiStepLR               10      0.69   \n",
       "598       dropout         None  ExponentialLR               10      0.66   \n",
       "595          None         None  ExponentialLR               10      0.67   \n",
       "270          None         None           None               10      0.76   \n",
       "57        dropout         None           None               20      0.88   \n",
       "243          None         None           None               10      0.70   \n",
       "3         dropout         None           None               20      0.84   \n",
       "177        l2_reg    LayerNorm           None               20      0.70   \n",
       "176       dropout    LayerNorm    MultiStepLR               20      0.70   \n",
       "174       dropout    LayerNorm           None               20      0.74   \n",
       "448        l2_reg    LayerNorm  ExponentialLR               10      0.67   \n",
       "2            None         None    MultiStepLR               20      0.68   \n",
       "275       dropout         None    MultiStepLR               10      0.70   \n",
       "167       dropout         None    MultiStepLR               20      0.68   \n",
       "164          None         None    MultiStepLR               20      0.68   \n",
       "56           None         None    MultiStepLR               20      0.70   \n",
       "15         l2_reg    LayerNorm           None               20      0.74   \n",
       "302       dropout         None    MultiStepLR               10      0.69   \n",
       "287        l2_reg    LayerNorm    MultiStepLR               10      0.77   \n",
       "337       dropout    LayerNorm  ExponentialLR               20      0.66   \n",
       "308          None    LayerNorm    MultiStepLR               10      0.73   \n",
       "732       dropout         None           None               10      1.00   \n",
       "252          None    LayerNorm           None               10      0.68   \n",
       "12        dropout    LayerNorm           None               20      0.77   \n",
       "314        l2_reg    LayerNorm    MultiStepLR               10      0.72   \n",
       "281          None    LayerNorm    MultiStepLR               10      0.75   \n",
       "311       dropout    LayerNorm    MultiStepLR               10      0.68   \n",
       "276        l2_reg         None           None               10      0.67   \n",
       "783          None         None           None               10      0.99   \n",
       "203       dropout    LayerNorm    MultiStepLR               20      0.69   \n",
       "206        l2_reg    LayerNorm    MultiStepLR               20      0.76   \n",
       "41        dropout    LayerNorm    MultiStepLR               20      0.70   \n",
       "69         l2_reg    LayerNorm           None               20      0.91   \n",
       "171          None    LayerNorm           None               20      0.76   \n",
       "68        dropout    LayerNorm    MultiStepLR               20      0.69   \n",
       "65           None    LayerNorm    MultiStepLR               20      0.74   \n",
       "440        l2_reg         None    MultiStepLR               10      0.65   \n",
       "162          None         None           None               20      0.84   \n",
       "152        l2_reg    LayerNorm    MultiStepLR               10      0.72   \n",
       "150        l2_reg    LayerNorm           None               10      0.70   \n",
       "189          None         None           None               20      0.87   \n",
       "195        l2_reg         None           None               20      0.68   \n",
       "149       dropout    LayerNorm    MultiStepLR               10      0.69   \n",
       "95        dropout    LayerNorm    MultiStepLR               10      0.69   \n",
       "607       dropout    LayerNorm  ExponentialLR               10      0.67   \n",
       "71         l2_reg    LayerNorm    MultiStepLR               20      0.73   \n",
       "98         l2_reg    LayerNorm    MultiStepLR               10      0.68   \n",
       "119          None    LayerNorm    MultiStepLR               10      0.74   \n",
       "637        l2_reg    LayerNorm  ExponentialLR               10      0.66   \n",
       "496          None    LayerNorm  ExponentialLR               20      0.65   \n",
       "225          None    LayerNorm           None               20      0.85   \n",
       "227          None    LayerNorm    MultiStepLR               20      0.74   \n",
       "651       dropout         None           None               20      1.00   \n",
       "230       dropout    LayerNorm    MultiStepLR               20      0.70   \n",
       "216          None         None           None               20      0.90   \n",
       "678       dropout         None           None               20      1.00   \n",
       "125        l2_reg    LayerNorm    MultiStepLR               10      0.75   \n",
       "123        l2_reg    LayerNorm           None               10      0.81   \n",
       "233        l2_reg    LayerNorm    MultiStepLR               20      0.74   \n",
       "122       dropout    LayerNorm    MultiStepLR               10      0.69   \n",
       "583        l2_reg    LayerNorm  ExponentialLR               10      0.65   \n",
       "472       dropout    LayerNorm  ExponentialLR               10      0.66   \n",
       "705       dropout         None           None               20      1.00   \n",
       "785          None         None    MultiStepLR               10      0.84   \n",
       "795       dropout    LayerNorm           None               10      1.00   \n",
       "602        l2_reg         None    MultiStepLR               10      0.65   \n",
       "786       dropout         None           None               10      0.91   \n",
       "702          None         None           None               20      1.00   \n",
       "604          None    LayerNorm  ExponentialLR               10      0.65   \n",
       "731          None         None    MultiStepLR               10      0.95   \n",
       "648          None         None           None               20      1.00   \n",
       "657          None    LayerNorm           None               20      1.00   \n",
       "729          None         None           None               10      1.00   \n",
       "367        l2_reg    LayerNorm  ExponentialLR               20      0.65   \n",
       "660       dropout    LayerNorm           None               20      1.00   \n",
       "675          None         None           None               20      1.00   \n",
       "521        l2_reg         None    MultiStepLR               20      0.64   \n",
       "0            None         None           None               20      0.83   \n",
       "38           None    LayerNorm    MultiStepLR               20      0.77   \n",
       "114        l2_reg         None           None               10      0.66   \n",
       "204        l2_reg    LayerNorm           None               20      0.98   \n",
       "36           None    LayerNorm           None               20      1.00   \n",
       "279          None    LayerNorm           None               10      0.79   \n",
       "44         l2_reg    LayerNorm    MultiStepLR               20      0.78   \n",
       "198          None    LayerNorm           None               20      0.98   \n",
       "27           None         None           None               20      0.91   \n",
       "117          None    LayerNorm           None               10      0.82   \n",
       "284       dropout    LayerNorm    MultiStepLR               10      0.70   \n",
       "740          None    LayerNorm    MultiStepLR               10      1.00   \n",
       "741       dropout    LayerNorm           None               10      1.00   \n",
       "747          None  BatchNorm1d           None               10      1.00   \n",
       "750       dropout  BatchNorm1d           None               10      1.00   \n",
       "753        l2_reg  BatchNorm1d           None               10      1.00   \n",
       "653       dropout         None    MultiStepLR               20      0.92   \n",
       "734       dropout         None    MultiStepLR               10      0.90   \n",
       "756          None         None           None               10      0.96   \n",
       "28           None         None  ExponentialLR               20      0.64   \n",
       "634       dropout    LayerNorm  ExponentialLR               10      0.64   \n",
       "442          None    LayerNorm  ExponentialLR               10      0.65   \n",
       "738          None    LayerNorm           None               10      1.00   \n",
       "650          None         None    MultiStepLR               20      0.93   \n",
       "725       dropout  BatchNorm1d    MultiStepLR               20      0.93   \n",
       "445       dropout    LayerNorm  ExponentialLR               10      0.64   \n",
       "723       dropout  BatchNorm1d           None               20      1.00   \n",
       "717        l2_reg    LayerNorm           None               20      1.00   \n",
       "714       dropout    LayerNorm           None               20      1.00   \n",
       "666          None  BatchNorm1d           None               20      1.00   \n",
       "421        l2_reg    LayerNorm  ExponentialLR               10      0.63   \n",
       "669       dropout  BatchNorm1d           None               20      1.00   \n",
       "200          None    LayerNorm    MultiStepLR               20      0.76   \n",
       "415          None    LayerNorm  ExponentialLR               10      0.64   \n",
       "704          None         None    MultiStepLR               20      0.93   \n",
       "671       dropout  BatchNorm1d    MultiStepLR               20      0.99   \n",
       "699        l2_reg  BatchNorm1d           None               20      1.00   \n",
       "696       dropout  BatchNorm1d           None               20      1.00   \n",
       "231        l2_reg    LayerNorm           None               20      0.94   \n",
       "687       dropout    LayerNorm           None               20      1.00   \n",
       "42         l2_reg    LayerNorm           None               20      0.97   \n",
       "529        l2_reg    LayerNorm  ExponentialLR               20      0.66   \n",
       "271          None         None  ExponentialLR               10      0.64   \n",
       "580       dropout    LayerNorm  ExponentialLR               10      0.64   \n",
       "553       dropout    LayerNorm  ExponentialLR               20      0.64   \n",
       "556        l2_reg    LayerNorm  ExponentialLR               20      0.63   \n",
       "590       dropout  BatchNorm1d    MultiStepLR               10      0.66   \n",
       "804       dropout  BatchNorm1d           None               10      1.00   \n",
       "662       dropout    LayerNorm    MultiStepLR               20      1.00   \n",
       "665        l2_reg    LayerNorm    MultiStepLR               20      1.00   \n",
       "112       dropout         None  ExponentialLR               10      0.63   \n",
       "716       dropout    LayerNorm    MultiStepLR               20      0.98   \n",
       "663        l2_reg    LayerNorm           None               20      1.00   \n",
       "374       dropout  BatchNorm1d    MultiStepLR               20      0.64   \n",
       "426       dropout  BatchNorm1d           None               10      0.66   \n",
       "280          None    LayerNorm  ExponentialLR               10      0.66   \n",
       "109          None         None  ExponentialLR               10      0.64   \n",
       "668          None  BatchNorm1d    MultiStepLR               20      1.00   \n",
       "301       dropout         None  ExponentialLR               10      0.64   \n",
       "475        l2_reg    LayerNorm  ExponentialLR               10      0.62   \n",
       "13        dropout    LayerNorm  ExponentialLR               20      0.63   \n",
       "801          None  BatchNorm1d           None               10      1.00   \n",
       "708        l2_reg         None           None               20      1.00   \n",
       "707       dropout         None    MultiStepLR               20      0.76   \n",
       "298          None         None  ExponentialLR               10      0.64   \n",
       "499       dropout    LayerNorm  ExponentialLR               20      0.64   \n",
       "136          None         None  ExponentialLR               10      0.63   \n",
       "672        l2_reg  BatchNorm1d           None               20      1.00   \n",
       "807        l2_reg  BatchNorm1d           None               10      1.00   \n",
       "673        l2_reg  BatchNorm1d  ExponentialLR               20      0.93   \n",
       "690        l2_reg    LayerNorm           None               20      1.00   \n",
       "19           None  BatchNorm1d  ExponentialLR               20      0.64   \n",
       "770       dropout    LayerNorm    MultiStepLR               10      0.96   \n",
       "490       dropout         None  ExponentialLR               20      0.62   \n",
       "9            None    LayerNorm           None               20      0.70   \n",
       "746        l2_reg    LayerNorm    MultiStepLR               10      1.00   \n",
       "768       dropout    LayerNorm           None               10      1.00   \n",
       "762        l2_reg         None           None               10      0.77   \n",
       "759       dropout         None           None               10      0.79   \n",
       "63           None    LayerNorm           None               20      0.98   \n",
       "755        l2_reg  BatchNorm1d    MultiStepLR               10      1.00   \n",
       "754        l2_reg  BatchNorm1d  ExponentialLR               10      0.93   \n",
       "593        l2_reg  BatchNorm1d    MultiStepLR               10      0.67   \n",
       "749          None  BatchNorm1d    MultiStepLR               10      1.00   \n",
       "748          None  BatchNorm1d  ExponentialLR               10      0.94   \n",
       "752       dropout  BatchNorm1d    MultiStepLR               10      0.99   \n",
       "739          None    LayerNorm  ExponentialLR               10      0.98   \n",
       "659          None    LayerNorm    MultiStepLR               20      1.00   \n",
       "743       dropout    LayerNorm    MultiStepLR               10      1.00   \n",
       "190          None         None  ExponentialLR               20      0.64   \n",
       "737        l2_reg         None    MultiStepLR               10      0.70   \n",
       "94        dropout    LayerNorm  ExponentialLR               10      0.63   \n",
       "684          None    LayerNorm           None               20      1.00   \n",
       "681        l2_reg         None           None               20      1.00   \n",
       "99           None  BatchNorm1d           None               10      0.65   \n",
       "631          None    LayerNorm  ExponentialLR               10      0.63   \n",
       "677          None         None    MultiStepLR               20      0.86   \n",
       "674        l2_reg  BatchNorm1d    MultiStepLR               20      1.00   \n",
       "139       dropout         None  ExponentialLR               10      0.63   \n",
       "55           None         None  ExponentialLR               20      0.62   \n",
       "526       dropout    LayerNorm  ExponentialLR               20      0.63   \n",
       "58        dropout         None  ExponentialLR               20      0.63   \n",
       "658          None    LayerNorm  ExponentialLR               20      0.97   \n",
       "64           None    LayerNorm  ExponentialLR               20      0.63   \n",
       "121       dropout    LayerNorm  ExponentialLR               10      0.65   \n",
       "664        l2_reg    LayerNorm  ExponentialLR               20      0.98   \n",
       "67        dropout    LayerNorm  ExponentialLR               20      0.64   \n",
       "661       dropout    LayerNorm  ExponentialLR               20      0.86   \n",
       "402        l2_reg  BatchNorm1d           None               20      0.65   \n",
       "193       dropout         None  ExponentialLR               20      0.63   \n",
       "523          None    LayerNorm  ExponentialLR               20      0.63   \n",
       "175       dropout    LayerNorm  ExponentialLR               20      0.62   \n",
       "809        l2_reg  BatchNorm1d    MultiStepLR               10      1.00   \n",
       "226          None    LayerNorm  ExponentialLR               20      0.64   \n",
       "742       dropout    LayerNorm  ExponentialLR               10      0.86   \n",
       "797       dropout    LayerNorm    MultiStepLR               10      0.99   \n",
       "771        l2_reg    LayerNorm           None               10      1.00   \n",
       "720          None  BatchNorm1d           None               20      1.00   \n",
       "371          None  BatchNorm1d    MultiStepLR               20      0.63   \n",
       "792          None    LayerNorm           None               10      1.00   \n",
       "789        l2_reg         None           None               10      0.84   \n",
       "780        l2_reg  BatchNorm1d           None               10      1.00   \n",
       "711          None    LayerNorm           None               20      1.00   \n",
       "745        l2_reg    LayerNorm  ExponentialLR               10      0.97   \n",
       "751       dropout  BatchNorm1d  ExponentialLR               10      0.83   \n",
       "777       dropout  BatchNorm1d           None               10      0.99   \n",
       "758          None         None    MultiStepLR               10      0.83   \n",
       "765          None    LayerNorm           None               10      1.00   \n",
       "774          None  BatchNorm1d           None               10      1.00   \n",
       "798        l2_reg    LayerNorm           None               10      1.00   \n",
       "773        l2_reg    LayerNorm    MultiStepLR               10      1.00   \n",
       "695          None  BatchNorm1d    MultiStepLR               20      1.00   \n",
       "806       dropout  BatchNorm1d    MultiStepLR               10      0.95   \n",
       "800        l2_reg    LayerNorm    MultiStepLR               10      1.00   \n",
       "16         l2_reg    LayerNorm  ExponentialLR               20      0.63   \n",
       "145          None    LayerNorm  ExponentialLR               10      0.63   \n",
       "689       dropout    LayerNorm    MultiStepLR               20      0.95   \n",
       "398          None  BatchNorm1d    MultiStepLR               20      0.63   \n",
       "693          None  BatchNorm1d           None               20      1.00   \n",
       "779       dropout  BatchNorm1d    MultiStepLR               10      0.91   \n",
       "43         l2_reg    LayerNorm  ExponentialLR               20      0.63   \n",
       "274       dropout         None  ExponentialLR               10      0.63   \n",
       "776          None  BatchNorm1d    MultiStepLR               10      1.00   \n",
       "803          None  BatchNorm1d    MultiStepLR               10      1.00   \n",
       "155          None  BatchNorm1d    MultiStepLR               10      0.63   \n",
       "124        l2_reg    LayerNorm  ExponentialLR               10      0.64   \n",
       "307          None    LayerNorm  ExponentialLR               10      0.62   \n",
       "148       dropout    LayerNorm  ExponentialLR               10      0.62   \n",
       "788       dropout         None    MultiStepLR               10      0.71   \n",
       "286        l2_reg    LayerNorm  ExponentialLR               10      0.64   \n",
       "151        l2_reg    LayerNorm  ExponentialLR               10      0.62   \n",
       "794          None    LayerNorm    MultiStepLR               10      1.00   \n",
       "310       dropout    LayerNorm  ExponentialLR               10      0.62   \n",
       "799        l2_reg    LayerNorm  ExponentialLR               10      0.94   \n",
       "686          None    LayerNorm    MultiStepLR               20      1.00   \n",
       "217          None         None  ExponentialLR               20      0.62   \n",
       "698       dropout  BatchNorm1d    MultiStepLR               20      0.89   \n",
       "719        l2_reg    LayerNorm    MultiStepLR               20      1.00   \n",
       "713          None    LayerNorm    MultiStepLR               20      1.00   \n",
       "722          None  BatchNorm1d    MultiStepLR               20      1.00   \n",
       "710        l2_reg         None    MultiStepLR               20      0.69   \n",
       "670       dropout  BatchNorm1d  ExponentialLR               20      0.83   \n",
       "199          None    LayerNorm  ExponentialLR               20      0.64   \n",
       "202       dropout    LayerNorm  ExponentialLR               20      0.62   \n",
       "728        l2_reg  BatchNorm1d    MultiStepLR               20      1.00   \n",
       "667          None  BatchNorm1d  ExponentialLR               20      0.94   \n",
       "256       dropout    LayerNorm  ExponentialLR               10      0.62   \n",
       "259        l2_reg    LayerNorm  ExponentialLR               10      0.62   \n",
       "31        dropout         None  ExponentialLR               20      0.62   \n",
       "694          None  BatchNorm1d  ExponentialLR               20      0.88   \n",
       "701        l2_reg  BatchNorm1d    MultiStepLR               20      1.00   \n",
       "802          None  BatchNorm1d  ExponentialLR               10      0.92   \n",
       "692        l2_reg    LayerNorm    MultiStepLR               20      1.00   \n",
       "688       dropout    LayerNorm  ExponentialLR               20      0.75   \n",
       "712          None    LayerNorm  ExponentialLR               20      0.96   \n",
       "808        l2_reg  BatchNorm1d  ExponentialLR               10      0.91   \n",
       "772        l2_reg    LayerNorm  ExponentialLR               10      0.90   \n",
       "793          None    LayerNorm  ExponentialLR               10      0.97   \n",
       "796       dropout    LayerNorm  ExponentialLR               10      0.80   \n",
       "721          None  BatchNorm1d  ExponentialLR               20      0.91   \n",
       "37           None    LayerNorm  ExponentialLR               20      0.63   \n",
       "791        l2_reg         None    MultiStepLR               10      0.68   \n",
       "577          None    LayerNorm  ExponentialLR               10      0.59   \n",
       "727        l2_reg  BatchNorm1d  ExponentialLR               20      0.90   \n",
       "74           None  BatchNorm1d    MultiStepLR               20      0.61   \n",
       "781        l2_reg  BatchNorm1d  ExponentialLR               10      0.88   \n",
       "744        l2_reg    LayerNorm           None               10      0.98   \n",
       "766          None    LayerNorm  ExponentialLR               10      0.93   \n",
       "775          None  BatchNorm1d  ExponentialLR               10      0.88   \n",
       "767          None    LayerNorm    MultiStepLR               10      1.00   \n",
       "685          None    LayerNorm  ExponentialLR               20      0.93   \n",
       "40        dropout    LayerNorm  ExponentialLR               20      0.62   \n",
       "769       dropout    LayerNorm  ExponentialLR               10      0.76   \n",
       "97         l2_reg    LayerNorm  ExponentialLR               10      0.59   \n",
       "348        l2_reg  BatchNorm1d           None               20      0.67   \n",
       "232        l2_reg    LayerNorm  ExponentialLR               20      0.61   \n",
       "267        l2_reg  BatchNorm1d           None               10      0.64   \n",
       "205        l2_reg    LayerNorm  ExponentialLR               20      0.63   \n",
       "283       dropout    LayerNorm  ExponentialLR               10      0.63   \n",
       "220       dropout         None  ExponentialLR               20      0.61   \n",
       "313        l2_reg    LayerNorm  ExponentialLR               10      0.63   \n",
       "239       dropout  BatchNorm1d    MultiStepLR               20      0.61   \n",
       "718        l2_reg    LayerNorm  ExponentialLR               20      0.96   \n",
       "118          None    LayerNorm  ExponentialLR               10      0.63   \n",
       "782        l2_reg  BatchNorm1d    MultiStepLR               10      1.00   \n",
       "724       dropout  BatchNorm1d  ExponentialLR               20      0.76   \n",
       "70         l2_reg    LayerNorm  ExponentialLR               20      0.63   \n",
       "613          None  BatchNorm1d  ExponentialLR               10      0.60   \n",
       "764        l2_reg         None    MultiStepLR               10      0.74   \n",
       "700        l2_reg  BatchNorm1d  ExponentialLR               20      0.84   \n",
       "683        l2_reg         None    MultiStepLR               20      0.76   \n",
       "715       dropout    LayerNorm  ExponentialLR               20      0.80   \n",
       "656        l2_reg         None    MultiStepLR               20      0.63   \n",
       "805       dropout  BatchNorm1d  ExponentialLR               10      0.77   \n",
       "430        l2_reg  BatchNorm1d  ExponentialLR               10      0.60   \n",
       "510        l2_reg  BatchNorm1d           None               20      0.62   \n",
       "726        l2_reg  BatchNorm1d           None               20      0.82   \n",
       "761       dropout         None    MultiStepLR               10      0.73   \n",
       "616       dropout  BatchNorm1d  ExponentialLR               10      0.59   \n",
       "691        l2_reg    LayerNorm  ExponentialLR               20      0.88   \n",
       "290          None  BatchNorm1d    MultiStepLR               10      0.60   \n",
       "697       dropout  BatchNorm1d  ExponentialLR               20      0.73   \n",
       "376        l2_reg  BatchNorm1d  ExponentialLR               20      0.58   \n",
       "680       dropout         None    MultiStepLR               20      0.74   \n",
       "229       dropout    LayerNorm  ExponentialLR               20      0.60   \n",
       "321        l2_reg  BatchNorm1d           None               10      0.60   \n",
       "241        l2_reg  BatchNorm1d  ExponentialLR               20      0.59   \n",
       "487          None         None  ExponentialLR               20      0.56   \n",
       "295        l2_reg  BatchNorm1d  ExponentialLR               10      0.57   \n",
       "778       dropout  BatchNorm1d  ExponentialLR               10      0.73   \n",
       "178        l2_reg    LayerNorm  ExponentialLR               20      0.58   \n",
       "292       dropout  BatchNorm1d  ExponentialLR               10      0.57   \n",
       "24         l2_reg  BatchNorm1d           None               20      0.61   \n",
       "345       dropout  BatchNorm1d           None               20      0.59   \n",
       "18           None  BatchNorm1d           None               20      0.60   \n",
       "91           None    LayerNorm  ExponentialLR               10      0.56   \n",
       "82           None         None  ExponentialLR               10      0.56   \n",
       "787       dropout         None  ExponentialLR               10      0.62   \n",
       "318       dropout  BatchNorm1d           None               10      0.56   \n",
       "186        l2_reg  BatchNorm1d           None               20      0.58   \n",
       "316          None  BatchNorm1d  ExponentialLR               10      0.57   \n",
       "172          None    LayerNorm  ExponentialLR               20      0.57   \n",
       "247       dropout         None  ExponentialLR               10      0.55   \n",
       "538        l2_reg  BatchNorm1d  ExponentialLR               20      0.57   \n",
       "25         l2_reg  BatchNorm1d  ExponentialLR               20      0.55   \n",
       "253          None    LayerNorm  ExponentialLR               10      0.56   \n",
       "757          None         None  ExponentialLR               10      0.59   \n",
       "10           None    LayerNorm  ExponentialLR               20      0.54   \n",
       "397          None  BatchNorm1d  ExponentialLR               20      0.54   \n",
       "244          None         None  ExponentialLR               10      0.55   \n",
       "51         l2_reg  BatchNorm1d           None               20      0.59   \n",
       "763        l2_reg         None  ExponentialLR               10      0.58   \n",
       "452          None  BatchNorm1d    MultiStepLR               10      0.56   \n",
       "154          None  BatchNorm1d  ExponentialLR               10      0.55   \n",
       "409       dropout         None  ExponentialLR               10      0.53   \n",
       "502        l2_reg    LayerNorm  ExponentialLR               20      0.52   \n",
       "240        l2_reg  BatchNorm1d           None               20      0.54   \n",
       "703          None         None  ExponentialLR               20      0.58   \n",
       "709        l2_reg         None  ExponentialLR               20      0.55   \n",
       "406          None         None  ExponentialLR               10      0.51   \n",
       "294        l2_reg  BatchNorm1d           None               10      0.53   \n",
       "325          None         None  ExponentialLR               20      0.50   \n",
       "334          None    LayerNorm  ExponentialLR               20      0.52   \n",
       "533          None  BatchNorm1d    MultiStepLR               20      0.52   \n",
       "539        l2_reg  BatchNorm1d    MultiStepLR               20      0.52   \n",
       "730          None         None  ExponentialLR               10      0.55   \n",
       "706       dropout         None  ExponentialLR               20      0.56   \n",
       "682        l2_reg         None  ExponentialLR               20      0.53   \n",
       "183       dropout  BatchNorm1d           None               20      0.54   \n",
       "676          None         None  ExponentialLR               20      0.56   \n",
       "784          None         None  ExponentialLR               10      0.55   \n",
       "76        dropout  BatchNorm1d  ExponentialLR               20      0.49   \n",
       "328       dropout         None  ExponentialLR               20      0.48   \n",
       "564        l2_reg  BatchNorm1d           None               20      0.49   \n",
       "100          None  BatchNorm1d  ExponentialLR               10      0.48   \n",
       "614          None  BatchNorm1d    MultiStepLR               10      0.47   \n",
       "617       dropout  BatchNorm1d    MultiStepLR               10      0.48   \n",
       "46           None  BatchNorm1d  ExponentialLR               20      0.49   \n",
       "512        l2_reg  BatchNorm1d    MultiStepLR               20      0.48   \n",
       "451          None  BatchNorm1d  ExponentialLR               10      0.47   \n",
       "679       dropout         None  ExponentialLR               20      0.49   \n",
       "262          None  BatchNorm1d  ExponentialLR               10      0.47   \n",
       "760       dropout         None  ExponentialLR               10      0.51   \n",
       "320       dropout  BatchNorm1d    MultiStepLR               10      0.47   \n",
       "242        l2_reg  BatchNorm1d    MultiStepLR               20      0.46   \n",
       "619        l2_reg  BatchNorm1d  ExponentialLR               10      0.46   \n",
       "181          None  BatchNorm1d  ExponentialLR               20      0.45   \n",
       "266       dropout  BatchNorm1d    MultiStepLR               10      0.46   \n",
       "116        l2_reg         None    MultiStepLR               10      0.43   \n",
       "50        dropout  BatchNorm1d    MultiStepLR               20      0.44   \n",
       "160        l2_reg  BatchNorm1d  ExponentialLR               10      0.44   \n",
       "647        l2_reg  BatchNorm1d    MultiStepLR               10      0.44   \n",
       "237       dropout  BatchNorm1d           None               20      0.47   \n",
       "101          None  BatchNorm1d    MultiStepLR               10      0.43   \n",
       "77        dropout  BatchNorm1d    MultiStepLR               20      0.43   \n",
       "85        dropout         None  ExponentialLR               10      0.42   \n",
       "343          None  BatchNorm1d  ExponentialLR               20      0.42   \n",
       "620        l2_reg  BatchNorm1d    MultiStepLR               10      0.41   \n",
       "399       dropout  BatchNorm1d           None               20      0.42   \n",
       "642       dropout  BatchNorm1d           None               10      0.42   \n",
       "423          None  BatchNorm1d           None               10      0.42   \n",
       "78         l2_reg  BatchNorm1d           None               20      0.42   \n",
       "790        l2_reg         None  ExponentialLR               10      0.43   \n",
       "536       dropout  BatchNorm1d    MultiStepLR               20      0.42   \n",
       "537        l2_reg  BatchNorm1d           None               20      0.42   \n",
       "53         l2_reg  BatchNorm1d    MultiStepLR               20      0.41   \n",
       "215        l2_reg  BatchNorm1d    MultiStepLR               20      0.39   \n",
       "649          None         None  ExponentialLR               20      0.40   \n",
       "344          None  BatchNorm1d    MultiStepLR               20      0.40   \n",
       "315          None  BatchNorm1d           None               10      0.40   \n",
       "375        l2_reg  BatchNorm1d           None               20      0.40   \n",
       "424          None  BatchNorm1d  ExponentialLR               10      0.39   \n",
       "418       dropout    LayerNorm  ExponentialLR               10      0.38   \n",
       "26         l2_reg  BatchNorm1d    MultiStepLR               20      0.39   \n",
       "293       dropout  BatchNorm1d    MultiStepLR               10      0.39   \n",
       "612          None  BatchNorm1d           None               10      0.39   \n",
       "180          None  BatchNorm1d           None               20      0.38   \n",
       "330        l2_reg         None           None               20      0.37   \n",
       "277        l2_reg         None  ExponentialLR               10      0.37   \n",
       "269        l2_reg  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "8          l2_reg         None    MultiStepLR               20      0.37   \n",
       "331        l2_reg         None  ExponentialLR               20      0.37   \n",
       "7          l2_reg         None  ExponentialLR               20      0.37   \n",
       "6          l2_reg         None           None               20      0.37   \n",
       "412        l2_reg         None  ExponentialLR               10      0.37   \n",
       "4         dropout         None  ExponentialLR               20      0.37   \n",
       "411        l2_reg         None           None               10      0.37   \n",
       "278        l2_reg         None    MultiStepLR               10      0.37   \n",
       "1            None         None  ExponentialLR               20      0.39   \n",
       "413        l2_reg         None    MultiStepLR               10      0.37   \n",
       "305        l2_reg         None    MultiStepLR               10      0.37   \n",
       "197        l2_reg         None    MultiStepLR               20      0.37   \n",
       "196        l2_reg         None  ExponentialLR               20      0.37   \n",
       "304        l2_reg         None  ExponentialLR               10      0.37   \n",
       "303        l2_reg         None           None               10      0.37   \n",
       "428       dropout  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "289          None  BatchNorm1d  ExponentialLR               10      0.37   \n",
       "429        l2_reg  BatchNorm1d           None               10      0.37   \n",
       "332        l2_reg         None    MultiStepLR               20      0.37   \n",
       "222        l2_reg         None           None               20      0.37   \n",
       "404        l2_reg  BatchNorm1d    MultiStepLR               20      0.37   \n",
       "263          None  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "224        l2_reg         None    MultiStepLR               20      0.37   \n",
       "384        l2_reg         None           None               20      0.37   \n",
       "385        l2_reg         None  ExponentialLR               20      0.37   \n",
       "377        l2_reg  BatchNorm1d    MultiStepLR               20      0.37   \n",
       "386        l2_reg         None    MultiStepLR               20      0.37   \n",
       "370          None  BatchNorm1d  ExponentialLR               20      0.38   \n",
       "234          None  BatchNorm1d           None               20      0.37   \n",
       "214        l2_reg  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "235          None  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "21        dropout  BatchNorm1d           None               20      0.37   \n",
       "733       dropout         None  ExponentialLR               10      0.37   \n",
       "213        l2_reg  BatchNorm1d           None               20      0.37   \n",
       "238       dropout  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "735        l2_reg         None           None               10      0.37   \n",
       "211       dropout  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "736        l2_reg         None  ExponentialLR               10      0.37   \n",
       "358        l2_reg         None  ExponentialLR               20      0.37   \n",
       "249        l2_reg         None           None               10      0.37   \n",
       "250        l2_reg         None  ExponentialLR               10      0.37   \n",
       "251        l2_reg         None    MultiStepLR               10      0.37   \n",
       "209          None  BatchNorm1d    MultiStepLR               20      0.37   \n",
       "349        l2_reg  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "346       dropout  BatchNorm1d  ExponentialLR               20      0.39   \n",
       "208          None  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "396          None  BatchNorm1d           None               20      0.38   \n",
       "342          None  BatchNorm1d           None               20      0.38   \n",
       "223        l2_reg         None  ExponentialLR               20      0.37   \n",
       "431        l2_reg  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "484        l2_reg  BatchNorm1d  ExponentialLR               10      0.37   \n",
       "568          None         None  ExponentialLR               10      0.38   \n",
       "87         l2_reg         None           None               10      0.37   \n",
       "531          None  BatchNorm1d           None               20      0.37   \n",
       "532          None  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "535       dropout  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "104       dropout  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "546        l2_reg         None           None               20      0.37   \n",
       "547        l2_reg         None  ExponentialLR               20      0.37   \n",
       "548        l2_reg         None    MultiStepLR               20      0.37   \n",
       "465        l2_reg         None           None               10      0.37   \n",
       "89         l2_reg         None    MultiStepLR               10      0.37   \n",
       "88         l2_reg         None  ExponentialLR               10      0.37   \n",
       "161        l2_reg  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "559          None  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "588       dropout  BatchNorm1d           None               10      0.37   \n",
       "562       dropout  BatchNorm1d  ExponentialLR               20      0.38   \n",
       "80         l2_reg  BatchNorm1d    MultiStepLR               20      0.37   \n",
       "79         l2_reg  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "571       dropout         None  ExponentialLR               10      0.37   \n",
       "573        l2_reg         None           None               10      0.37   \n",
       "574        l2_reg         None  ExponentialLR               10      0.37   \n",
       "575        l2_reg         None    MultiStepLR               10      0.37   \n",
       "163          None         None  ExponentialLR               20      0.37   \n",
       "166       dropout         None  ExponentialLR               20      0.37   \n",
       "168        l2_reg         None           None               20      0.37   \n",
       "72           None  BatchNorm1d           None               20      0.37   \n",
       "106        l2_reg  BatchNorm1d  ExponentialLR               10      0.37   \n",
       "466        l2_reg         None  ExponentialLR               10      0.37   \n",
       "107        l2_reg  BatchNorm1d    MultiStepLR               10      0.40   \n",
       "467        l2_reg         None    MultiStepLR               10      0.37   \n",
       "483        l2_reg  BatchNorm1d           None               10      0.37   \n",
       "143        l2_reg         None    MultiStepLR               10      0.37   \n",
       "142        l2_reg         None  ExponentialLR               10      0.37   \n",
       "141        l2_reg         None           None               10      0.37   \n",
       "492        l2_reg         None           None               20      0.37   \n",
       "493        l2_reg         None  ExponentialLR               20      0.37   \n",
       "494        l2_reg         None    MultiStepLR               20      0.37   \n",
       "481       dropout  BatchNorm1d  ExponentialLR               10      0.37   \n",
       "480       dropout  BatchNorm1d           None               10      0.37   \n",
       "131       dropout  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "130       dropout  BatchNorm1d  ExponentialLR               10      0.37   \n",
       "504          None  BatchNorm1d           None               20      0.37   \n",
       "506          None  BatchNorm1d    MultiStepLR               20      0.37   \n",
       "507       dropout  BatchNorm1d           None               20      0.37   \n",
       "129       dropout  BatchNorm1d           None               10      0.37   \n",
       "509       dropout  BatchNorm1d    MultiStepLR               20      0.37   \n",
       "511        l2_reg  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "128          None  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "127          None  BatchNorm1d  ExponentialLR               10      0.37   \n",
       "126          None  BatchNorm1d           None               10      0.37   \n",
       "520        l2_reg         None  ExponentialLR               20      0.37   \n",
       "115        l2_reg         None  ExponentialLR               10      0.37   \n",
       "158       dropout  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "585          None  BatchNorm1d           None               10      0.37   \n",
       "291       dropout  BatchNorm1d           None               10      0.37   \n",
       "628        l2_reg         None  ExponentialLR               10      0.37   \n",
       "618        l2_reg  BatchNorm1d           None               10      0.37   \n",
       "450          None  BatchNorm1d           None               10      0.37   \n",
       "601        l2_reg         None  ExponentialLR               10      0.37   \n",
       "169        l2_reg         None  ExponentialLR               20      0.37   \n",
       "170        l2_reg         None    MultiStepLR               20      0.37   \n",
       "453       dropout  BatchNorm1d           None               10      0.37   \n",
       "627        l2_reg         None           None               10      0.37   \n",
       "629        l2_reg         None    MultiStepLR               10      0.37   \n",
       "35         l2_reg         None    MultiStepLR               20      0.37   \n",
       "60         l2_reg         None           None               20      0.37   \n",
       "61         l2_reg         None  ExponentialLR               20      0.37   \n",
       "62         l2_reg         None    MultiStepLR               20      0.37   \n",
       "34         l2_reg         None  ExponentialLR               20      0.37   \n",
       "33         l2_reg         None           None               20      0.37   \n",
       "439        l2_reg         None  ExponentialLR               10      0.37   \n",
       "456        l2_reg  BatchNorm1d           None               10      0.37   \n",
       "641          None  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "645        l2_reg  BatchNorm1d           None               10      0.37   \n",
       "592        l2_reg  BatchNorm1d  ExponentialLR               10      0.38   \n",
       "591        l2_reg  BatchNorm1d           None               10      0.37   \n",
       "646        l2_reg  BatchNorm1d  ExponentialLR               10      0.37   \n",
       "485        l2_reg  BatchNorm1d    MultiStepLR               10      0.37   \n",
       "652       dropout         None  ExponentialLR               20      0.37   \n",
       "654        l2_reg         None           None               20      0.37   \n",
       "655        l2_reg         None  ExponentialLR               20      0.37   \n",
       "22        dropout  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "52         l2_reg  BatchNorm1d  ExponentialLR               20      0.37   \n",
       "587          None  BatchNorm1d    MultiStepLR               10      0.38   \n",
       "482       dropout  BatchNorm1d    MultiStepLR               10      0.36   \n",
       "212       dropout  BatchNorm1d    MultiStepLR               20      0.36   \n",
       "103       dropout  BatchNorm1d  ExponentialLR               10      0.37   \n",
       "322        l2_reg  BatchNorm1d  ExponentialLR               10      0.34   \n",
       "261          None  BatchNorm1d           None               10      0.35   \n",
       "323        l2_reg  BatchNorm1d    MultiStepLR               10      0.35   \n",
       "403        l2_reg  BatchNorm1d  ExponentialLR               20      0.34   \n",
       "187        l2_reg  BatchNorm1d  ExponentialLR               20      0.32   \n",
       "640          None  BatchNorm1d  ExponentialLR               10      0.32   \n",
       "105        l2_reg  BatchNorm1d           None               10      0.31   \n",
       "23        dropout  BatchNorm1d    MultiStepLR               20      0.31   \n",
       "643       dropout  BatchNorm1d  ExponentialLR               10      0.32   \n",
       "132        l2_reg  BatchNorm1d           None               10      0.32   \n",
       "268        l2_reg  BatchNorm1d  ExponentialLR               10      0.31   \n",
       "425          None  BatchNorm1d    MultiStepLR               10      0.31   \n",
       "45           None  BatchNorm1d           None               20      0.30   \n",
       "182          None  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "455       dropout  BatchNorm1d    MultiStepLR               10      0.31   \n",
       "159        l2_reg  BatchNorm1d           None               10      0.30   \n",
       "350        l2_reg  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "156       dropout  BatchNorm1d           None               10      0.30   \n",
       "265       dropout  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "288          None  BatchNorm1d           None               10      0.30   \n",
       "372       dropout  BatchNorm1d           None               20      0.30   \n",
       "639          None  BatchNorm1d           None               10      0.30   \n",
       "20           None  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "505          None  BatchNorm1d  ExponentialLR               20      0.30   \n",
       "317          None  BatchNorm1d    MultiStepLR               10      0.30   \n",
       "458        l2_reg  BatchNorm1d    MultiStepLR               10      0.30   \n",
       "373       dropout  BatchNorm1d  ExponentialLR               20      0.30   \n",
       "457        l2_reg  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "134        l2_reg  BatchNorm1d    MultiStepLR               10      0.30   \n",
       "133        l2_reg  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "185       dropout  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "75        dropout  BatchNorm1d           None               20      0.30   \n",
       "73           None  BatchNorm1d  ExponentialLR               20      0.30   \n",
       "369          None  BatchNorm1d           None               20      0.30   \n",
       "589       dropout  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "296        l2_reg  BatchNorm1d    MultiStepLR               10      0.30   \n",
       "479          None  BatchNorm1d    MultiStepLR               10      0.30   \n",
       "48        dropout  BatchNorm1d           None               20      0.30   \n",
       "207          None  BatchNorm1d           None               20      0.30   \n",
       "184       dropout  BatchNorm1d  ExponentialLR               20      0.30   \n",
       "47           None  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "210       dropout  BatchNorm1d           None               20      0.30   \n",
       "49        dropout  BatchNorm1d  ExponentialLR               20      0.30   \n",
       "102       dropout  BatchNorm1d           None               10      0.30   \n",
       "558          None  BatchNorm1d           None               20      0.30   \n",
       "560          None  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "534       dropout  BatchNorm1d           None               20      0.30   \n",
       "561       dropout  BatchNorm1d           None               20      0.30   \n",
       "565        l2_reg  BatchNorm1d  ExponentialLR               20      0.30   \n",
       "264       dropout  BatchNorm1d           None               10      0.30   \n",
       "586          None  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "400       dropout  BatchNorm1d  ExponentialLR               20      0.30   \n",
       "401       dropout  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "566        l2_reg  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "157       dropout  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "454       dropout  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "153          None  BatchNorm1d           None               10      0.30   \n",
       "477          None  BatchNorm1d           None               10      0.30   \n",
       "478          None  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "319       dropout  BatchNorm1d  ExponentialLR               10      0.30   \n",
       "236          None  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "188        l2_reg  BatchNorm1d    MultiStepLR               20      0.30   \n",
       "\n",
       "     F1-val  F1-test  \n",
       "543    0.73     0.72  \n",
       "624    0.73     0.70  \n",
       "525    0.73     0.70  \n",
       "540    0.73     0.70  \n",
       "597    0.72     0.70  \n",
       "584    0.72     0.84  \n",
       "491    0.72     0.84  \n",
       "380    0.72     0.80  \n",
       "489    0.72     0.74  \n",
       "552    0.72     0.80  \n",
       "582    0.72     0.80  \n",
       "557    0.72     0.78  \n",
       "594    0.72     0.74  \n",
       "581    0.72     0.80  \n",
       "626    0.72     0.80  \n",
       "611    0.72     0.78  \n",
       "578    0.72     0.80  \n",
       "621    0.72     0.74  \n",
       "495    0.72     0.78  \n",
       "497    0.72     0.72  \n",
       "500    0.72     0.78  \n",
       "528    0.72     0.68  \n",
       "324    0.72     0.76  \n",
       "327    0.72     0.76  \n",
       "518    0.72     0.78  \n",
       "516    0.72     0.72  \n",
       "336    0.72     0.78  \n",
       "339    0.72     0.78  \n",
       "572    0.72     0.80  \n",
       "503    0.72     0.76  \n",
       "542    0.72     0.74  \n",
       "501    0.72     0.76  \n",
       "545    0.72     0.78  \n",
       "446    0.71     0.78  \n",
       "459    0.71     0.74  \n",
       "462    0.71     0.80  \n",
       "449    0.71     0.78  \n",
       "444    0.71     0.78  \n",
       "579    0.71     0.82  \n",
       "447    0.71     0.80  \n",
       "596    0.71     0.74  \n",
       "461    0.71     0.78  \n",
       "486    0.71     0.67  \n",
       "570    0.71     0.76  \n",
       "569    0.71     0.78  \n",
       "464    0.71     0.80  \n",
       "567    0.71     0.76  \n",
       "468    0.71     0.78  \n",
       "473    0.71     0.76  \n",
       "555    0.71     0.76  \n",
       "554    0.71     0.76  \n",
       "599    0.71     0.78  \n",
       "488    0.71     0.82  \n",
       "551    0.71     0.82  \n",
       "498    0.71     0.78  \n",
       "515    0.71     0.78  \n",
       "527    0.71     0.86  \n",
       "519    0.71     0.84  \n",
       "474    0.71     0.82  \n",
       "437    0.71     0.74  \n",
       "438    0.71     0.76  \n",
       "366    0.71     0.76  \n",
       "630    0.71     0.78  \n",
       "632    0.71     0.86  \n",
       "633    0.71     0.82  \n",
       "392    0.71     0.76  \n",
       "636    0.71     0.76  \n",
       "387    0.71     0.72  \n",
       "383    0.71     0.78  \n",
       "363    0.71     0.82  \n",
       "408    0.71     0.78  \n",
       "357    0.71     0.80  \n",
       "356    0.71     0.78  \n",
       "353    0.71     0.76  \n",
       "338    0.71     0.76  \n",
       "333    0.71     0.76  \n",
       "329    0.71     0.78  \n",
       "326    0.71     0.80  \n",
       "407    0.71     0.76  \n",
       "395    0.71     0.76  \n",
       "623    0.71     0.78  \n",
       "419    0.71     0.76  \n",
       "600    0.71     0.78  \n",
       "522    0.71     0.72  \n",
       "435    0.71     0.76  \n",
       "434    0.71     0.76  \n",
       "432    0.71     0.78  \n",
       "603    0.71     0.74  \n",
       "420    0.71     0.76  \n",
       "410    0.71     0.76  \n",
       "606    0.71     0.84  \n",
       "605    0.71     0.74  \n",
       "608    0.71     0.84  \n",
       "609    0.71     0.78  \n",
       "414    0.71     0.76  \n",
       "417    0.71     0.76  \n",
       "524    0.71     0.78  \n",
       "513    0.70     0.66  \n",
       "381    0.70     0.67  \n",
       "416    0.70     0.78  \n",
       "443    0.70     0.74  \n",
       "335    0.70     0.73  \n",
       "470    0.70     0.74  \n",
       "341    0.70     0.74  \n",
       "351    0.70     0.70  \n",
       "368    0.70     0.72  \n",
       "390    0.70     0.78  \n",
       "354    0.70     0.76  \n",
       "389    0.70     0.76  \n",
       "441    0.70     0.70  \n",
       "360    0.70     0.74  \n",
       "362    0.70     0.74  \n",
       "378    0.70     0.64  \n",
       "365    0.70     0.82  \n",
       "471    0.70     0.78  \n",
       "405    0.70     0.69  \n",
       "635    0.70     0.88  \n",
       "638    0.70     0.78  \n",
       "576    0.70     0.76  \n",
       "530    0.70     0.80  \n",
       "352    0.69     0.76  \n",
       "393    0.69     0.75  \n",
       "347    0.69     0.72  \n",
       "549    0.69     0.65  \n",
       "508    0.69     0.76  \n",
       "355    0.69     0.74  \n",
       "340    0.69     0.78  \n",
       "422    0.69     0.75  \n",
       "427    0.69     0.74  \n",
       "300    0.69     0.72  \n",
       "476    0.69     0.76  \n",
       "165    0.68     0.74  \n",
       "81     0.68     0.70  \n",
       "391    0.68     0.82  \n",
       "463    0.68     0.76  \n",
       "394    0.68     0.76  \n",
       "32     0.68     0.70  \n",
       "299    0.68     0.76  \n",
       "460    0.68     0.74  \n",
       "39     0.68     0.74  \n",
       "273    0.68     0.72  \n",
       "90     0.68     0.76  \n",
       "272    0.68     0.72  \n",
       "173    0.68     0.74  \n",
       "66     0.68     0.70  \n",
       "622    0.68     0.82  \n",
       "615    0.68     0.75  \n",
       "59     0.68     0.72  \n",
       "436    0.68     0.68  \n",
       "29     0.68     0.76  \n",
       "433    0.68     0.74  \n",
       "218    0.68     0.76  \n",
       "93     0.68     0.74  \n",
       "14     0.68     0.76  \n",
       "550    0.68     0.78  \n",
       "228    0.68     0.72  \n",
       "379    0.68     0.80  \n",
       "138    0.68     0.70  \n",
       "514    0.68     0.76  \n",
       "140    0.68     0.74  \n",
       "255    0.68     0.72  \n",
       "644    0.68     0.78  \n",
       "144    0.68     0.72  \n",
       "517    0.68     0.80  \n",
       "17     0.68     0.70  \n",
       "111    0.68     0.68  \n",
       "246    0.68     0.70  \n",
       "194    0.67     0.74  \n",
       "361    0.67     0.78  \n",
       "245    0.67     0.76  \n",
       "610    0.67     0.84  \n",
       "364    0.67     0.76  \n",
       "192    0.67     0.72  \n",
       "191    0.67     0.78  \n",
       "201    0.67     0.74  \n",
       "260    0.67     0.74  \n",
       "113    0.67     0.69  \n",
       "248    0.67     0.72  \n",
       "54     0.67     0.78  \n",
       "11     0.67     0.72  \n",
       "625    0.67     0.82  \n",
       "254    0.67     0.72  \n",
       "382    0.67     0.74  \n",
       "221    0.67     0.78  \n",
       "30     0.67     0.74  \n",
       "219    0.67     0.74  \n",
       "388    0.67     0.80  \n",
       "258    0.67     0.68  \n",
       "257    0.67     0.74  \n",
       "179    0.67     0.78  \n",
       "86     0.67     0.72  \n",
       "469    0.67     0.68  \n",
       "563    0.67     0.82  \n",
       "312    0.67     0.74  \n",
       "5      0.67     0.74  \n",
       "309    0.67     0.68  \n",
       "147    0.67     0.74  \n",
       "146    0.67     0.66  \n",
       "297    0.67     0.68  \n",
       "92     0.67     0.78  \n",
       "282    0.67     0.74  \n",
       "96     0.67     0.72  \n",
       "137    0.67     0.76  \n",
       "135    0.67     0.72  \n",
       "306    0.67     0.72  \n",
       "544    0.67     0.80  \n",
       "541    0.67     0.82  \n",
       "108    0.67     0.72  \n",
       "285    0.67     0.76  \n",
       "110    0.67     0.72  \n",
       "120    0.67     0.78  \n",
       "84     0.67     0.68  \n",
       "359    0.67     0.75  \n",
       "83     0.67     0.74  \n",
       "598    0.67     0.80  \n",
       "595    0.67     0.84  \n",
       "270    0.67     0.70  \n",
       "57     0.67     0.68  \n",
       "243    0.67     0.74  \n",
       "3      0.67     0.68  \n",
       "177    0.67     0.74  \n",
       "176    0.67     0.76  \n",
       "174    0.67     0.68  \n",
       "448    0.67     0.72  \n",
       "2      0.67     0.74  \n",
       "275    0.67     0.72  \n",
       "167    0.67     0.74  \n",
       "164    0.67     0.74  \n",
       "56     0.67     0.76  \n",
       "15     0.66     0.70  \n",
       "302    0.66     0.72  \n",
       "287    0.66     0.74  \n",
       "337    0.66     0.80  \n",
       "308    0.66     0.76  \n",
       "732    0.66     0.60  \n",
       "252    0.66     0.69  \n",
       "12     0.66     0.71  \n",
       "314    0.66     0.80  \n",
       "281    0.66     0.70  \n",
       "311    0.66     0.76  \n",
       "276    0.66     0.70  \n",
       "783    0.66     0.70  \n",
       "203    0.66     0.74  \n",
       "206    0.66     0.72  \n",
       "41     0.66     0.80  \n",
       "69     0.66     0.78  \n",
       "171    0.66     0.68  \n",
       "68     0.66     0.78  \n",
       "65     0.66     0.70  \n",
       "440    0.66     0.73  \n",
       "162    0.66     0.66  \n",
       "152    0.66     0.68  \n",
       "150    0.66     0.74  \n",
       "189    0.66     0.67  \n",
       "195    0.66     0.68  \n",
       "149    0.66     0.70  \n",
       "95     0.66     0.70  \n",
       "607    0.66     0.82  \n",
       "71     0.66     0.78  \n",
       "98     0.66     0.74  \n",
       "119    0.66     0.68  \n",
       "637    0.66     0.74  \n",
       "496    0.66     0.80  \n",
       "225    0.66     0.74  \n",
       "227    0.66     0.68  \n",
       "651    0.66     0.70  \n",
       "230    0.66     0.76  \n",
       "216    0.66     0.66  \n",
       "678    0.66     0.80  \n",
       "125    0.66     0.68  \n",
       "123    0.66     0.72  \n",
       "233    0.66     0.74  \n",
       "122    0.66     0.72  \n",
       "583    0.65     0.82  \n",
       "472    0.65     0.78  \n",
       "705    0.65     0.76  \n",
       "785    0.65     0.68  \n",
       "795    0.65     0.68  \n",
       "602    0.65     0.82  \n",
       "786    0.65     0.73  \n",
       "702    0.65     0.70  \n",
       "604    0.65     0.78  \n",
       "731    0.65     0.64  \n",
       "648    0.65     0.58  \n",
       "657    0.65     0.66  \n",
       "729    0.65     0.68  \n",
       "367    0.65     0.78  \n",
       "660    0.65     0.82  \n",
       "675    0.65     0.70  \n",
       "521    0.65     0.79  \n",
       "0      0.65     0.76  \n",
       "38     0.65     0.69  \n",
       "114    0.65     0.68  \n",
       "204    0.65     0.64  \n",
       "36     0.65     0.76  \n",
       "279    0.65     0.70  \n",
       "44     0.65     0.68  \n",
       "198    0.65     0.65  \n",
       "27     0.65     0.64  \n",
       "117    0.65     0.78  \n",
       "284    0.65     0.76  \n",
       "740    0.64     0.72  \n",
       "741    0.64     0.60  \n",
       "747    0.64     0.74  \n",
       "750    0.64     0.66  \n",
       "753    0.64     0.74  \n",
       "653    0.64     0.66  \n",
       "734    0.64     0.72  \n",
       "756    0.64     0.70  \n",
       "28     0.64     0.72  \n",
       "634    0.64     0.72  \n",
       "442    0.64     0.78  \n",
       "738    0.64     0.70  \n",
       "650    0.64     0.74  \n",
       "725    0.64     0.65  \n",
       "445    0.64     0.64  \n",
       "723    0.64     0.76  \n",
       "717    0.64     0.62  \n",
       "714    0.64     0.68  \n",
       "666    0.64     0.64  \n",
       "421    0.64     0.69  \n",
       "669    0.64     0.64  \n",
       "200    0.64     0.72  \n",
       "415    0.64     0.76  \n",
       "704    0.64     0.58  \n",
       "671    0.64     0.78  \n",
       "699    0.64     0.62  \n",
       "696    0.64     0.70  \n",
       "231    0.64     0.76  \n",
       "687    0.64     0.72  \n",
       "42     0.64     0.64  \n",
       "529    0.64     0.74  \n",
       "271    0.64     0.70  \n",
       "580    0.64     0.79  \n",
       "553    0.64     0.82  \n",
       "556    0.64     0.77  \n",
       "590    0.64     0.75  \n",
       "804    0.64     0.61  \n",
       "662    0.63     0.68  \n",
       "665    0.63     0.72  \n",
       "112    0.63     0.72  \n",
       "716    0.63     0.68  \n",
       "663    0.63     0.60  \n",
       "374    0.63     0.73  \n",
       "426    0.63     0.62  \n",
       "280    0.63     0.66  \n",
       "109    0.63     0.74  \n",
       "668    0.63     0.76  \n",
       "301    0.63     0.72  \n",
       "475    0.63     0.74  \n",
       "13     0.63     0.76  \n",
       "801    0.63     0.68  \n",
       "708    0.63     0.72  \n",
       "707    0.63     0.70  \n",
       "298    0.63     0.76  \n",
       "499    0.63     0.86  \n",
       "136    0.63     0.72  \n",
       "672    0.63     0.66  \n",
       "807    0.63     0.66  \n",
       "673    0.63     0.82  \n",
       "690    0.63     0.70  \n",
       "19     0.63     0.80  \n",
       "770    0.63     0.70  \n",
       "490    0.63     0.81  \n",
       "9      0.63     0.67  \n",
       "746    0.63     0.72  \n",
       "768    0.63     0.68  \n",
       "762    0.63     0.74  \n",
       "759    0.63     0.66  \n",
       "63     0.63     0.64  \n",
       "755    0.63     0.72  \n",
       "754    0.63     0.74  \n",
       "593    0.63     0.75  \n",
       "749    0.63     0.51  \n",
       "748    0.63     0.66  \n",
       "752    0.63     0.74  \n",
       "739    0.63     0.64  \n",
       "659    0.63     0.68  \n",
       "743    0.63     0.66  \n",
       "190    0.63     0.72  \n",
       "737    0.63     0.72  \n",
       "94     0.62     0.70  \n",
       "684    0.62     0.72  \n",
       "681    0.62     0.68  \n",
       "99     0.62     0.67  \n",
       "631    0.62     0.75  \n",
       "677    0.62     0.63  \n",
       "674    0.62     0.68  \n",
       "139    0.62     0.72  \n",
       "55     0.62     0.74  \n",
       "526    0.62     0.74  \n",
       "58     0.62     0.70  \n",
       "658    0.62     0.60  \n",
       "64     0.62     0.67  \n",
       "121    0.62     0.72  \n",
       "664    0.62     0.62  \n",
       "67     0.62     0.58  \n",
       "661    0.62     0.56  \n",
       "402    0.62     0.74  \n",
       "193    0.62     0.70  \n",
       "523    0.62     0.78  \n",
       "175    0.62     0.68  \n",
       "809    0.62     0.62  \n",
       "226    0.62     0.72  \n",
       "742    0.62     0.70  \n",
       "797    0.62     0.66  \n",
       "771    0.62     0.68  \n",
       "720    0.62     0.70  \n",
       "371    0.62     0.64  \n",
       "792    0.62     0.68  \n",
       "789    0.62     0.66  \n",
       "780    0.62     0.70  \n",
       "711    0.62     0.70  \n",
       "745    0.62     0.72  \n",
       "751    0.62     0.72  \n",
       "777    0.62     0.72  \n",
       "758    0.62     0.66  \n",
       "765    0.62     0.62  \n",
       "774    0.62     0.70  \n",
       "798    0.62     0.70  \n",
       "773    0.62     0.60  \n",
       "695    0.62     0.59  \n",
       "806    0.62     0.78  \n",
       "800    0.62     0.68  \n",
       "16     0.62     0.70  \n",
       "145    0.62     0.68  \n",
       "689    0.62     0.76  \n",
       "398    0.62     0.63  \n",
       "693    0.62     0.60  \n",
       "779    0.61     0.64  \n",
       "43     0.61     0.70  \n",
       "274    0.61     0.68  \n",
       "776    0.61     0.62  \n",
       "803    0.61     0.68  \n",
       "155    0.61     0.64  \n",
       "124    0.61     0.74  \n",
       "307    0.61     0.66  \n",
       "148    0.61     0.68  \n",
       "788    0.61     0.74  \n",
       "286    0.61     0.78  \n",
       "151    0.61     0.61  \n",
       "794    0.61     0.62  \n",
       "310    0.61     0.62  \n",
       "799    0.61     0.68  \n",
       "686    0.61     0.66  \n",
       "217    0.61     0.70  \n",
       "698    0.61     0.70  \n",
       "719    0.61     0.64  \n",
       "713    0.61     0.72  \n",
       "722    0.61     0.70  \n",
       "710    0.61     0.70  \n",
       "670    0.61     0.72  \n",
       "199    0.61     0.66  \n",
       "202    0.61     0.59  \n",
       "728    0.61     0.70  \n",
       "667    0.61     0.62  \n",
       "256    0.61     0.68  \n",
       "259    0.61     0.62  \n",
       "31     0.61     0.74  \n",
       "694    0.61     0.66  \n",
       "701    0.60     0.60  \n",
       "802    0.60     0.58  \n",
       "692    0.60     0.60  \n",
       "688    0.60     0.68  \n",
       "712    0.60     0.58  \n",
       "808    0.60     0.68  \n",
       "772    0.60     0.52  \n",
       "793    0.60     0.76  \n",
       "796    0.60     0.64  \n",
       "721    0.60     0.66  \n",
       "37     0.60     0.72  \n",
       "791    0.60     0.66  \n",
       "577    0.60     0.67  \n",
       "727    0.60     0.62  \n",
       "74     0.60     0.76  \n",
       "781    0.60     0.70  \n",
       "744    0.60     0.72  \n",
       "766    0.60     0.74  \n",
       "775    0.60     0.68  \n",
       "767    0.60     0.64  \n",
       "685    0.60     0.70  \n",
       "40     0.60     0.70  \n",
       "769    0.60     0.76  \n",
       "97     0.60     0.69  \n",
       "348    0.60     0.76  \n",
       "232    0.60     0.68  \n",
       "267    0.60     0.59  \n",
       "205    0.60     0.66  \n",
       "283    0.60     0.64  \n",
       "220    0.60     0.68  \n",
       "313    0.60     0.72  \n",
       "239    0.59     0.50  \n",
       "718    0.59     0.66  \n",
       "118    0.59     0.62  \n",
       "782    0.59     0.62  \n",
       "724    0.59     0.66  \n",
       "70     0.59     0.59  \n",
       "613    0.59     0.72  \n",
       "764    0.59     0.64  \n",
       "700    0.59     0.62  \n",
       "683    0.59     0.70  \n",
       "715    0.59     0.66  \n",
       "656    0.59     0.65  \n",
       "805    0.59     0.62  \n",
       "430    0.59     0.58  \n",
       "510    0.58     0.52  \n",
       "726    0.58     0.61  \n",
       "761    0.58     0.67  \n",
       "616    0.58     0.62  \n",
       "691    0.58     0.56  \n",
       "290    0.58     0.55  \n",
       "697    0.58     0.62  \n",
       "376    0.58     0.63  \n",
       "680    0.58     0.64  \n",
       "229    0.58     0.64  \n",
       "321    0.58     0.67  \n",
       "241    0.57     0.64  \n",
       "487    0.57     0.69  \n",
       "295    0.57     0.50  \n",
       "778    0.57     0.62  \n",
       "178    0.56     0.61  \n",
       "292    0.56     0.66  \n",
       "24     0.56     0.66  \n",
       "345    0.55     0.70  \n",
       "18     0.55     0.65  \n",
       "91     0.55     0.65  \n",
       "82     0.55     0.72  \n",
       "787    0.55     0.54  \n",
       "318    0.55     0.52  \n",
       "186    0.55     0.61  \n",
       "316    0.55     0.71  \n",
       "172    0.55     0.67  \n",
       "247    0.55     0.72  \n",
       "538    0.55     0.48  \n",
       "25     0.54     0.65  \n",
       "253    0.54     0.60  \n",
       "757    0.54     0.54  \n",
       "10     0.54     0.65  \n",
       "397    0.54     0.53  \n",
       "244    0.54     0.70  \n",
       "51     0.54     0.58  \n",
       "763    0.54     0.59  \n",
       "452    0.54     0.60  \n",
       "154    0.54     0.56  \n",
       "409    0.54     0.57  \n",
       "502    0.53     0.63  \n",
       "240    0.52     0.55  \n",
       "703    0.52     0.49  \n",
       "709    0.52     0.51  \n",
       "406    0.52     0.57  \n",
       "294    0.52     0.54  \n",
       "325    0.52     0.54  \n",
       "334    0.52     0.69  \n",
       "533    0.51     0.44  \n",
       "539    0.51     0.60  \n",
       "730    0.51     0.61  \n",
       "706    0.51     0.56  \n",
       "682    0.50     0.58  \n",
       "183    0.50     0.48  \n",
       "676    0.50     0.58  \n",
       "784    0.50     0.51  \n",
       "76     0.49     0.50  \n",
       "328    0.49     0.50  \n",
       "564    0.49     0.54  \n",
       "100    0.48     0.56  \n",
       "614    0.48     0.38  \n",
       "617    0.48     0.54  \n",
       "46     0.48     0.57  \n",
       "512    0.47     0.52  \n",
       "451    0.47     0.45  \n",
       "679    0.47     0.52  \n",
       "262    0.47     0.48  \n",
       "760    0.47     0.43  \n",
       "320    0.46     0.52  \n",
       "242    0.46     0.44  \n",
       "619    0.45     0.57  \n",
       "181    0.45     0.57  \n",
       "266    0.45     0.41  \n",
       "116    0.44     0.42  \n",
       "50     0.44     0.42  \n",
       "160    0.44     0.45  \n",
       "647    0.44     0.42  \n",
       "237    0.43     0.47  \n",
       "101    0.43     0.50  \n",
       "77     0.42     0.51  \n",
       "85     0.42     0.42  \n",
       "343    0.42     0.51  \n",
       "620    0.41     0.38  \n",
       "399    0.41     0.41  \n",
       "642    0.41     0.37  \n",
       "423    0.41     0.47  \n",
       "78     0.41     0.45  \n",
       "790    0.41     0.38  \n",
       "536    0.41     0.48  \n",
       "537    0.41     0.50  \n",
       "53     0.40     0.38  \n",
       "215    0.40     0.42  \n",
       "649    0.40     0.42  \n",
       "344    0.40     0.45  \n",
       "315    0.40     0.37  \n",
       "375    0.39     0.43  \n",
       "424    0.39     0.38  \n",
       "418    0.39     0.42  \n",
       "26     0.39     0.42  \n",
       "293    0.39     0.38  \n",
       "612    0.39     0.46  \n",
       "180    0.39     0.38  \n",
       "330    0.38     0.38  \n",
       "277    0.38     0.38  \n",
       "269    0.38     0.38  \n",
       "8      0.38     0.38  \n",
       "331    0.38     0.38  \n",
       "7      0.38     0.38  \n",
       "6      0.38     0.38  \n",
       "412    0.38     0.38  \n",
       "4      0.38     0.38  \n",
       "411    0.38     0.38  \n",
       "278    0.38     0.38  \n",
       "1      0.38     0.38  \n",
       "413    0.38     0.38  \n",
       "305    0.38     0.38  \n",
       "197    0.38     0.38  \n",
       "196    0.38     0.38  \n",
       "304    0.38     0.38  \n",
       "303    0.38     0.38  \n",
       "428    0.38     0.38  \n",
       "289    0.38     0.38  \n",
       "429    0.38     0.38  \n",
       "332    0.38     0.38  \n",
       "222    0.38     0.38  \n",
       "404    0.38     0.38  \n",
       "263    0.38     0.38  \n",
       "224    0.38     0.38  \n",
       "384    0.38     0.38  \n",
       "385    0.38     0.38  \n",
       "377    0.38     0.38  \n",
       "386    0.38     0.38  \n",
       "370    0.38     0.38  \n",
       "234    0.38     0.38  \n",
       "214    0.38     0.38  \n",
       "235    0.38     0.38  \n",
       "21     0.38     0.38  \n",
       "733    0.38     0.38  \n",
       "213    0.38     0.38  \n",
       "238    0.38     0.38  \n",
       "735    0.38     0.38  \n",
       "211    0.38     0.38  \n",
       "736    0.38     0.38  \n",
       "358    0.38     0.38  \n",
       "249    0.38     0.38  \n",
       "250    0.38     0.38  \n",
       "251    0.38     0.38  \n",
       "209    0.38     0.37  \n",
       "349    0.38     0.38  \n",
       "346    0.38     0.48  \n",
       "208    0.38     0.38  \n",
       "396    0.38     0.50  \n",
       "342    0.38     0.38  \n",
       "223    0.38     0.38  \n",
       "431    0.38     0.38  \n",
       "484    0.38     0.38  \n",
       "568    0.38     0.38  \n",
       "87     0.38     0.38  \n",
       "531    0.38     0.38  \n",
       "532    0.38     0.38  \n",
       "535    0.38     0.38  \n",
       "104    0.38     0.38  \n",
       "546    0.38     0.38  \n",
       "547    0.38     0.38  \n",
       "548    0.38     0.38  \n",
       "465    0.38     0.38  \n",
       "89     0.38     0.38  \n",
       "88     0.38     0.38  \n",
       "161    0.38     0.38  \n",
       "559    0.38     0.38  \n",
       "588    0.38     0.38  \n",
       "562    0.38     0.38  \n",
       "80     0.38     0.38  \n",
       "79     0.38     0.38  \n",
       "571    0.38     0.38  \n",
       "573    0.38     0.38  \n",
       "574    0.38     0.38  \n",
       "575    0.38     0.38  \n",
       "163    0.38     0.38  \n",
       "166    0.38     0.38  \n",
       "168    0.38     0.38  \n",
       "72     0.38     0.38  \n",
       "106    0.38     0.38  \n",
       "466    0.38     0.38  \n",
       "107    0.38     0.36  \n",
       "467    0.38     0.38  \n",
       "483    0.38     0.38  \n",
       "143    0.38     0.38  \n",
       "142    0.38     0.38  \n",
       "141    0.38     0.38  \n",
       "492    0.38     0.38  \n",
       "493    0.38     0.38  \n",
       "494    0.38     0.38  \n",
       "481    0.38     0.38  \n",
       "480    0.38     0.38  \n",
       "131    0.38     0.38  \n",
       "130    0.38     0.38  \n",
       "504    0.38     0.38  \n",
       "506    0.38     0.38  \n",
       "507    0.38     0.38  \n",
       "129    0.38     0.38  \n",
       "509    0.38     0.38  \n",
       "511    0.38     0.38  \n",
       "128    0.38     0.38  \n",
       "127    0.38     0.38  \n",
       "126    0.38     0.38  \n",
       "520    0.38     0.38  \n",
       "115    0.38     0.38  \n",
       "158    0.38     0.38  \n",
       "585    0.38     0.38  \n",
       "291    0.38     0.38  \n",
       "628    0.38     0.38  \n",
       "618    0.38     0.38  \n",
       "450    0.38     0.38  \n",
       "601    0.38     0.38  \n",
       "169    0.38     0.38  \n",
       "170    0.38     0.38  \n",
       "453    0.38     0.38  \n",
       "627    0.38     0.38  \n",
       "629    0.38     0.38  \n",
       "35     0.38     0.38  \n",
       "60     0.38     0.38  \n",
       "61     0.38     0.38  \n",
       "62     0.38     0.38  \n",
       "34     0.38     0.38  \n",
       "33     0.38     0.38  \n",
       "439    0.38     0.38  \n",
       "456    0.38     0.38  \n",
       "641    0.38     0.38  \n",
       "645    0.38     0.38  \n",
       "592    0.38     0.38  \n",
       "591    0.38     0.38  \n",
       "646    0.38     0.38  \n",
       "485    0.38     0.38  \n",
       "652    0.38     0.38  \n",
       "654    0.38     0.38  \n",
       "655    0.38     0.38  \n",
       "22     0.38     0.38  \n",
       "52     0.38     0.38  \n",
       "587    0.37     0.37  \n",
       "482    0.36     0.41  \n",
       "212    0.36     0.37  \n",
       "103    0.36     0.41  \n",
       "322    0.35     0.33  \n",
       "261    0.35     0.29  \n",
       "323    0.33     0.33  \n",
       "403    0.33     0.29  \n",
       "187    0.32     0.29  \n",
       "640    0.32     0.33  \n",
       "105    0.31     0.29  \n",
       "23     0.31     0.29  \n",
       "643    0.31     0.33  \n",
       "132    0.31     0.29  \n",
       "268    0.31     0.29  \n",
       "425    0.30     0.29  \n",
       "45     0.30     0.29  \n",
       "182    0.30     0.29  \n",
       "455    0.30     0.29  \n",
       "159    0.30     0.29  \n",
       "350    0.30     0.29  \n",
       "156    0.30     0.29  \n",
       "265    0.30     0.29  \n",
       "288    0.30     0.29  \n",
       "372    0.30     0.29  \n",
       "639    0.30     0.29  \n",
       "20     0.29     0.29  \n",
       "505    0.29     0.29  \n",
       "317    0.29     0.29  \n",
       "458    0.29     0.29  \n",
       "373    0.29     0.29  \n",
       "457    0.29     0.29  \n",
       "134    0.29     0.29  \n",
       "133    0.29     0.29  \n",
       "185    0.29     0.29  \n",
       "75     0.29     0.29  \n",
       "73     0.29     0.29  \n",
       "369    0.29     0.29  \n",
       "589    0.29     0.29  \n",
       "296    0.29     0.29  \n",
       "479    0.29     0.29  \n",
       "48     0.29     0.29  \n",
       "207    0.29     0.29  \n",
       "184    0.29     0.29  \n",
       "47     0.29     0.29  \n",
       "210    0.29     0.29  \n",
       "49     0.29     0.29  \n",
       "102    0.29     0.29  \n",
       "558    0.29     0.29  \n",
       "560    0.29     0.29  \n",
       "534    0.29     0.29  \n",
       "561    0.29     0.29  \n",
       "565    0.29     0.29  \n",
       "264    0.29     0.29  \n",
       "586    0.29     0.29  \n",
       "400    0.29     0.29  \n",
       "401    0.29     0.29  \n",
       "566    0.29     0.29  \n",
       "157    0.29     0.29  \n",
       "454    0.29     0.29  \n",
       "153    0.29     0.29  \n",
       "477    0.29     0.29  \n",
       "478    0.29     0.29  \n",
       "319    0.29     0.29  \n",
       "236    0.29     0.29  \n",
       "188    0.29     0.29  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "summary = pd.DataFrame.from_dict(total)\n",
    "summary_sort = summary.sort_values(by='F1-val', ascending=False)\n",
    "summary_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно увидеть по таблице - самого лучшего результата (0.84) достигла непредеробученная модель на признаках fastText с оптимизатором AdamW, функцией активации LeakyReLU, Dropout регуляризацией, \"планировщиком\" MultiStepLR с начальной скоростью 0.01 с LayerNorm нормализацией."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
