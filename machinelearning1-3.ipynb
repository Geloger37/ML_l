{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ee2a29",
   "metadata": {
    "id": "P75gWMshhfv_",
    "papermill": {
     "duration": 0.016976,
     "end_time": "2023-03-20T13:02:42.315302",
     "exception": false,
     "start_time": "2023-03-20T13:02:42.298326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Начальная инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5b8332",
   "metadata": {
    "id": "65078f9a",
    "outputId": "0b40f77d-a829-4f88-8e9d-83f02bf0e4b5",
    "papermill": {
     "duration": 3.889611,
     "end_time": "2023-03-20T13:02:46.309004",
     "exception": false,
     "start_time": "2023-03-20T13:02:42.419393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightning\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn.model_selection\n",
    "import torchmetrics\n",
    "import IPython.display\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397f0e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightning.seed_everything(random_state, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c6d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'dumps/'\n",
    "with open(PATH + 'X_train_ft_pre_trained.pkl', mode='rb') as file:\n",
    "    X_train_ft_pre_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_train_w2v_pre_trained.pkl', mode='rb') as file:\n",
    "    X_train_w2v_pre_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_test_w2v_pre_trained.pkl', mode='rb') as file:\n",
    "    X_test_w2v_pre_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_test_w2v_self_trained.pkl', mode='rb') as file:\n",
    "    X_test_w2v_self_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_test_ft_pre_trained.pkl', mode='rb') as file:\n",
    "    X_test_ft_pre_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_train_ft_self_trained.pkl', mode='rb') as file:\n",
    "    X_train_ft_self_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_test_ft_self_trained.pkl', mode='rb') as file:\n",
    "    X_test_ft_self_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'X_train_w2v_self_trained.pkl', mode='rb') as file:\n",
    "    X_train_w2v_self_trained = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'y_train.pkl', mode='rb') as file:\n",
    "    y_train = pickle.load(file)\n",
    "\n",
    "with open(PATH + 'y_test.pkl', mode='rb') as file:\n",
    "    y_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7f7a2",
   "metadata": {},
   "source": [
    "Сетка перебираемых гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0e1617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'embeddings': ['w2v_pretrained', 'ft_pretrained', 'w2v_selftrained', 'ft_selftrained'],\n",
    "    'layers_count': [2, 3],\n",
    "    'learning_rate': [0.001],\n",
    "    'layers_type': ['different', 'equal'],\n",
    "    'batch_size': [64],\n",
    "    'optimizer': [torch.optim.Adam],\n",
    "    'epochs': [10],\n",
    "    'activation_function': [torch.nn.functional.relu],\n",
    "    \"initialization\": [None, torch.nn.init.kaiming_uniform_, torch.nn.init.xavier_uniform_],\n",
    "    \"regularization\": ['None', 'dropout', 'l2_reg'],\n",
    "    \"normalization\": [None, torch.nn.LayerNorm, torch.nn.BatchNorm1d],\n",
    "    \"scheduler\": [None, torch.optim.lr_scheduler.ExponentialLR, torch.optim.lr_scheduler.MultiStepLR]\n",
    "}\n",
    "\n",
    "params_list = sklearn.model_selection.ParameterGrid(param_grid)\n",
    "len(params_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95761cea",
   "metadata": {},
   "source": [
    "Класс для работы с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072cdb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetData(lightning.LightningDataModule):\n",
    "    def __init__(self, train_features=None, test_features=None, train_targets=None, test_targets=None, batch_size=None, random_state=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = sklearn.model_selection.train_test_split(train_features, train_targets, random_state=random_state)\n",
    "        self.X_test, self.y_test = test_features, test_targets\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        features_train = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        targets_train = torch.tensor(self.y_train, dtype=torch.int32)\n",
    "    \n",
    "        features_val = torch.tensor(self.X_val, dtype=torch.float32)\n",
    "        targets_val = torch.tensor(self.y_val, dtype=torch.int32)\n",
    "    \n",
    "        features_test = torch.tensor(self.X_test, dtype=torch.float32)\n",
    "        targets_test = torch.tensor(self.y_test, dtype=torch.int32)\n",
    "    \n",
    "        self.trainset = torch.utils.data.TensorDataset(features_train, targets_train)\n",
    "        self.valset = torch.utils.data.TensorDataset(features_val, targets_val)\n",
    "        self.testset = torch.utils.data.TensorDataset(features_test, targets_test)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.trainset, batch_size=self.batch_size)\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.valset, batch_size=self.batch_size)\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.testset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46685544",
   "metadata": {},
   "source": [
    "Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d661dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Архитектура нейронной сети\n",
    "class Net(lightning.LightningModule):\n",
    "    def __init__(self,\n",
    "                 learning_rate=None,\n",
    "                 layers_count=None,\n",
    "                 layers_type=None,\n",
    "                 optimizer=None,\n",
    "                 activation=None,\n",
    "                 initialization=None,\n",
    "                 regularization=None,\n",
    "                 normalization=None,\n",
    "                 scheduler=None\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        input_dim = 2**(2 + layers_count)\n",
    "        \n",
    "        self.layers.append( self.add_linear_layer(input=300,\n",
    "                                                  output=input_dim,\n",
    "                                                  normalization=normalization,\n",
    "                                                  regularization=regularization) )\n",
    "        for _ in range(layers_count):\n",
    "            if layers_type == 'equal':\n",
    "                self.layers.append( self.add_linear_layer(input=input_dim, \n",
    "                                                          output=input_dim, \n",
    "                                                          normalization=normalization, \n",
    "                                                          regularization=regularization) )\n",
    "            elif layers_type == \"different\":\n",
    "                self.layers.append( self.add_linear_layer(input=input_dim, \n",
    "                                                          output=input_dim // 2, \n",
    "                                                          normalization=normalization, \n",
    "                                                          regularization=regularization) )\n",
    "                input_dim //= 2\n",
    "        self.layers.append( self.add_linear_layer(input=input_dim,\n",
    "                                                  output=2,\n",
    "                                                  normalization=normalization,\n",
    "                                                  regularization=regularization) )\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = optimizer\n",
    "        self.f1 = torchmetrics.classification.F1Score(task='multiclass', num_classes=2, multidim_average='global', average='weighted')\n",
    "        if initialization:\n",
    "            self.iw(torch.nn.Linear, initialization)\n",
    "        self.regularization = regularization\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def iw(self, ModuleClass, weights_initializator):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, ModuleClass):\n",
    "                weights_initializator(module.weight)\n",
    "    \n",
    "    def add_linear_layer(self, input=None, output=None, normalization=None, regularization=None) -> torch.nn.Sequential:\n",
    "        layer = torch.nn.Sequential()\n",
    "        layer.append(torch.nn.Linear(in_features=input, out_features=output))\n",
    "        if normalization:\n",
    "            layer.append( normalization(output) )\n",
    "        if regularization == 'dropout':\n",
    "            layer.append( torch.nn.Dropout1d(p=0.2) )\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.layers[-1](x)\n",
    "        return torch.nn.functional.log_softmax(x, dim=-1)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer(self.parameters(), lr=self.learning_rate, weight_decay=(0.01 if self.regularization == 'l2_reg' else 0))\n",
    "        if self.scheduler is None:\n",
    "            return optimizer\n",
    "        else:\n",
    "            if self.scheduler.__name__ == 'ExponentialLR':\n",
    "                scheduler = self.scheduler(optimizer, gamma=0.9)\n",
    "            elif self.scheduler.__name__ == 'MultiStepLR':\n",
    "                scheduler = self.scheduler(optimizer, milestones=list(range(1, 15, 3)), gamma=0.9)\n",
    "            return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_hat, y.long())\n",
    "        self.log('loss', loss, on_epoch=True)\n",
    "        self.log(\"train_f1\", self.f1(y_hat, y), on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self(x)\n",
    "        self.log(\"val_f1\", self.f1(pred, y), on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self(x)\n",
    "        self.log(\"test_f1\", self.f1(pred, y), on_epoch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378ef22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 1296/1296 [9:38:22<00:00, 26.78s/it]\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "\n",
    "for params in tqdm(params_list): \n",
    "\n",
    "    embeddings = params['embeddings']\n",
    "    learningRate = params['learning_rate']\n",
    "    optimizer_type = params['optimizer']\n",
    "    layers_count = params['layers_count']\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    activation_function = params['activation_function']\n",
    "    layers_type = params['layers_type']\n",
    "    initialization = params['initialization']\n",
    "    regularization = params['regularization']\n",
    "    normalization = params['normalization']\n",
    "    scheduler = params['scheduler']\n",
    "\n",
    "\n",
    "    net = Net(learning_rate=learningRate,\n",
    "          layers_count=layers_count,\n",
    "          layers_type=layers_type,\n",
    "          optimizer=optimizer_type,\n",
    "          activation=activation_function,\n",
    "          initialization=initialization,\n",
    "          regularization=regularization,\n",
    "          normalization=normalization,\n",
    "          scheduler=scheduler,\n",
    "        )\n",
    "    \n",
    "    dm = None\n",
    "    if embeddings == 'w2v_pretrained':\n",
    "        dm = NetData(\n",
    "            train_features=X_train_w2v_pre_trained,\n",
    "            test_features=X_test_w2v_pre_trained,\n",
    "            train_targets=y_train,\n",
    "            test_targets=y_test,\n",
    "            batch_size=batch_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif embeddings == 'w2v_selftrained':\n",
    "        dm = NetData(\n",
    "            train_features=X_train_w2v_self_trained,\n",
    "            test_features=X_test_w2v_self_trained,\n",
    "            train_targets=y_train,\n",
    "            test_targets=y_test,\n",
    "            batch_size=batch_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif embeddings == 'ft_pretrained':\n",
    "        dm = NetData(\n",
    "            train_features=X_train_ft_pre_trained,\n",
    "            test_features=X_test_ft_pre_trained,\n",
    "            train_targets=y_train,\n",
    "            test_targets=y_test,\n",
    "            batch_size=batch_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif embeddings == 'ft_selftrained':\n",
    "        dm = NetData(\n",
    "            train_features=X_train_ft_self_trained,\n",
    "            test_features=X_test_ft_self_trained,\n",
    "            train_targets=y_train,\n",
    "            test_targets=y_test,\n",
    "            batch_size=batch_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    \n",
    "\n",
    "    # CPU is better for FCNN than GPU\n",
    "    trainer = lightning.Trainer(logger=False, \n",
    "                                max_epochs=epochs, \n",
    "                                enable_progress_bar=True, \n",
    "                                deterministic=True, \n",
    "                                inference_mode=True, \n",
    "                                enable_checkpointing=False, \n",
    "                                accelerator='cpu')\n",
    "\n",
    "    trainer.fit(net, datamodule=dm)\n",
    "    f1_train = trainer.logged_metrics['train_f1_epoch'].item()\n",
    "    f1_val = trainer.logged_metrics['val_f1'].item()\n",
    "    f1_test = trainer.test(net, datamodule=dm)[-1]['test_f1']    \n",
    "    \n",
    "    \n",
    "    total.append({\n",
    "        'embeddings': embeddings,\n",
    "        'Layers type': layers_type,\n",
    "        'Optimizer': optimizer_type.__name__,\n",
    "        'Batch': batch_size,\n",
    "        'Count of layers': layers_count,\n",
    "        'Epochs': epochs,\n",
    "        'Learning rate': learningRate,\n",
    "        'Activation function': activation_function.__name__,\n",
    "        'Initialization': initialization.__name__ if initialization else None,\n",
    "        'Regularization': regularization,\n",
    "        'Normalization': normalization.__name__ if normalization else None,\n",
    "        'Scheduler': scheduler.__name__ if scheduler else None,\n",
    "        'F1-train': round(f1_train, 4),\n",
    "        'F1-val': round(f1_val, 4),\n",
    "        'F1-test': round(f1_test, 4)\n",
    "    })\n",
    "    \n",
    "    IPython.display.clear_output(wait=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b193d",
   "metadata": {
    "papermill": {
     "duration": 0.236035,
     "end_time": "2023-03-20T22:23:17.978505",
     "exception": false,
     "start_time": "2023-03-20T22:23:17.742470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Сводная таблица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3277c16",
   "metadata": {
    "papermill": {
     "duration": 0.320113,
     "end_time": "2023-03-20T22:23:18.531197",
     "exception": false,
     "start_time": "2023-03-20T22:23:18.211084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>Layers type</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Count of layers</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Activation function</th>\n",
       "      <th>Initialization</th>\n",
       "      <th>Regularization</th>\n",
       "      <th>Normalization</th>\n",
       "      <th>Scheduler</th>\n",
       "      <th>F1-train</th>\n",
       "      <th>F1-val</th>\n",
       "      <th>F1-test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7235</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7027</td>\n",
       "      <td>0.6914</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.6914</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7007</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7139</td>\n",
       "      <td>0.6890</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.5314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>0.6874</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.6868</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.6865</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.6863</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5676</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5762</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5754</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6816</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.5391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6817</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7423</td>\n",
       "      <td>0.6834</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6775</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6941</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5592</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5797</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5743</td>\n",
       "      <td>0.6826</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>0.6826</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.6816</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6743</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7604</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6767</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7575</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6761</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.6793</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7192</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5762</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5613</td>\n",
       "      <td>0.6784</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6983</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7434</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5887</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7519</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5796</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7394</td>\n",
       "      <td>0.6758</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>0.6754</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.6754</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7195</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6987</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.6751</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5886</td>\n",
       "      <td>0.6749</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5721</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.6490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>0.6743</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6783</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.5490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.7588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7377</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.6736</td>\n",
       "      <td>0.7130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.6734</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6879</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.6729</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>0.6728</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.6728</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5807</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7719</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7159</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5842</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>0.5361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5768</td>\n",
       "      <td>0.6713</td>\n",
       "      <td>0.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.6712</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6753</td>\n",
       "      <td>0.6710</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>0.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.6708</td>\n",
       "      <td>0.7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5821</td>\n",
       "      <td>0.6704</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5671</td>\n",
       "      <td>0.6703</td>\n",
       "      <td>0.7130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5834</td>\n",
       "      <td>0.6702</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5854</td>\n",
       "      <td>0.6701</td>\n",
       "      <td>0.6490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.6701</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7079</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.5208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6748</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.6695</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5781</td>\n",
       "      <td>0.6693</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.6691</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7538</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.6682</td>\n",
       "      <td>0.7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.6677</td>\n",
       "      <td>0.6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.6676</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7646</td>\n",
       "      <td>0.6676</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5651</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5855</td>\n",
       "      <td>0.6672</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.6668</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6707</td>\n",
       "      <td>0.6666</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.6666</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5660</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5872</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7573</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5831</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5814</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7646</td>\n",
       "      <td>0.6654</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>0.7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5728</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6986</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.6649</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5824</td>\n",
       "      <td>0.6647</td>\n",
       "      <td>0.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5816</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.7395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7637</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.6644</td>\n",
       "      <td>0.7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7094</td>\n",
       "      <td>0.6644</td>\n",
       "      <td>0.6168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.6644</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5941</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>0.6639</td>\n",
       "      <td>0.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>0.6639</td>\n",
       "      <td>0.6310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.6636</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>0.6636</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>0.6636</td>\n",
       "      <td>0.5722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6934</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5808</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>0.6383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5957</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5659</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.6429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7611</td>\n",
       "      <td>0.6631</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5594</td>\n",
       "      <td>0.6630</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7041</td>\n",
       "      <td>0.6628</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5729</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7105</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5929</td>\n",
       "      <td>0.6623</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6763</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.6490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.6622</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.6849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7712</td>\n",
       "      <td>0.6619</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7509</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7058</td>\n",
       "      <td>0.6614</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7716</td>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7550</td>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6912</td>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>0.6609</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>0.6609</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7519</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7487</td>\n",
       "      <td>0.6607</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6827</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5753</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7353</td>\n",
       "      <td>0.6603</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5806</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.6849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5633</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.6490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7141</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6913</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7773</td>\n",
       "      <td>0.6599</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5851</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.5837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6997</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5734</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7892</td>\n",
       "      <td>0.6592</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7016</td>\n",
       "      <td>0.6592</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5744</td>\n",
       "      <td>0.6590</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5934</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.5924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7176</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5653</td>\n",
       "      <td>0.6588</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5946</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5844</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7752</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.5208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>0.5406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5986</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.6849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>0.6583</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5813</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>0.7030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.6580</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5476</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5812</td>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>0.5757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5814</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>0.6569</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.6782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7821</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.6567</td>\n",
       "      <td>0.7130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6536</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7434</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>0.6563</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.6562</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7491</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>0.5391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7235</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5569</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7491</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7503</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>0.6253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>0.5757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7749</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.5391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5617</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>0.6785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.5757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5764</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7302</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7169</td>\n",
       "      <td>0.6549</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5699</td>\n",
       "      <td>0.6549</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7491</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.6490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6572</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7383</td>\n",
       "      <td>0.6546</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>0.6545</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7072</td>\n",
       "      <td>0.6545</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5883</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5864</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7662</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5701</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.6849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.6539</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5633</td>\n",
       "      <td>0.6539</td>\n",
       "      <td>0.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7599</td>\n",
       "      <td>0.6537</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.6537</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.5406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5838</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7109</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6575</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5747</td>\n",
       "      <td>0.6530</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5797</td>\n",
       "      <td>0.6530</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5608</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.6528</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5510</td>\n",
       "      <td>0.6528</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.6528</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.6528</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7408</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6493</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5607</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7481</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>0.6524</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.6522</td>\n",
       "      <td>0.6253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>0.5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.6518</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>0.6518</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7092</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.6606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7355</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.6253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7442</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8197</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>0.6092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5834</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7609</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.7568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5826</td>\n",
       "      <td>0.6506</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7661</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7676</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.6495</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>0.6495</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.6495</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.6493</td>\n",
       "      <td>0.6181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7519</td>\n",
       "      <td>0.6492</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.4607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5894</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5648</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6608</td>\n",
       "      <td>0.6488</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7548</td>\n",
       "      <td>0.6487</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.6487</td>\n",
       "      <td>0.8196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7688</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7599</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6651</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>0.6482</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5627</td>\n",
       "      <td>0.6481</td>\n",
       "      <td>0.6782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5721</td>\n",
       "      <td>0.6480</td>\n",
       "      <td>0.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5684</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.6490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7412</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>0.6473</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.6471</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7520</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7595</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5610</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5734</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8037</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7665</td>\n",
       "      <td>0.6458</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.5314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.6454</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7265</td>\n",
       "      <td>0.6454</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.6449</td>\n",
       "      <td>0.6606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.6448</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7547</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7564</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5446</td>\n",
       "      <td>0.6442</td>\n",
       "      <td>0.6759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.6438</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.6437</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>0.7187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.6436</td>\n",
       "      <td>0.5722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8309</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7852</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.5391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7956</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.5490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6549</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5803</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>0.6092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5740</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7288</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5696</td>\n",
       "      <td>0.6426</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.6425</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5784</td>\n",
       "      <td>0.6423</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>0.6420</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.6420</td>\n",
       "      <td>0.7803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.6420</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8101</td>\n",
       "      <td>0.6414</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7593</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8327</td>\n",
       "      <td>0.6411</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5716</td>\n",
       "      <td>0.6409</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.6408</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5811</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.7395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5705</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.5722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7190</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.7352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7259</td>\n",
       "      <td>0.6401</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.6401</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.6490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7968</td>\n",
       "      <td>0.6398</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5787</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7192</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8336</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8022</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8368</td>\n",
       "      <td>0.6384</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5760</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7203</td>\n",
       "      <td>0.6379</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7584</td>\n",
       "      <td>0.6378</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.7187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.6310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5847</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.6181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8498</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8287</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>0.5333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6906</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>0.6361</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7177</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>0.6357</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7408</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5843</td>\n",
       "      <td>0.6354</td>\n",
       "      <td>0.5537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.6354</td>\n",
       "      <td>0.7086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.6352</td>\n",
       "      <td>0.7759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5606</td>\n",
       "      <td>0.6352</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>0.6352</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7195</td>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8391</td>\n",
       "      <td>0.6351</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7461</td>\n",
       "      <td>0.6350</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5876</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.5924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.7130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.6346</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.6345</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7922</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7437</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8282</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5727</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7884</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>0.6330</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5757</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>0.6313</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7204</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8031</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5660</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>0.7086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7786</td>\n",
       "      <td>0.6303</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7643</td>\n",
       "      <td>0.6303</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.7186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.6298</td>\n",
       "      <td>0.7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>0.7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7438</td>\n",
       "      <td>0.6285</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.6284</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5591</td>\n",
       "      <td>0.6279</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7968</td>\n",
       "      <td>0.6278</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7992</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5672</td>\n",
       "      <td>0.6271</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.6270</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7571</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.6262</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7425</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.6253</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.6251</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5703</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5545</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>0.6785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7934</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5553</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.7086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.6241</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.6236</td>\n",
       "      <td>0.6593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5581</td>\n",
       "      <td>0.6234</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7160</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>0.6994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>0.7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6224</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>0.5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.6220</td>\n",
       "      <td>0.6429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5797</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>0.6974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5618</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8026</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.6212</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>0.6209</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8518</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5578</td>\n",
       "      <td>0.6190</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>0.6606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.6186</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5781</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.6185</td>\n",
       "      <td>0.6253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.6177</td>\n",
       "      <td>0.7086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8302</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8207</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5704</td>\n",
       "      <td>0.6171</td>\n",
       "      <td>0.5837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8105</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.6165</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8224</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5727</td>\n",
       "      <td>0.6157</td>\n",
       "      <td>0.7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.6151</td>\n",
       "      <td>0.5722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5567</td>\n",
       "      <td>0.6132</td>\n",
       "      <td>0.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8003</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>0.7588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7584</td>\n",
       "      <td>0.6114</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5678</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>0.5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5786</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>0.6310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.6075</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>0.6758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5415</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>0.5138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.6020</td>\n",
       "      <td>0.6260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>0.5988</td>\n",
       "      <td>0.5380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>0.5984</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.5971</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5557</td>\n",
       "      <td>0.5959</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6028</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.5080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5668</td>\n",
       "      <td>0.5953</td>\n",
       "      <td>0.6353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6651</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.6782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.6526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.5919</td>\n",
       "      <td>0.5607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6080</td>\n",
       "      <td>0.5916</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6069</td>\n",
       "      <td>0.5913</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.5757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.4907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.4670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6060</td>\n",
       "      <td>0.5908</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7359</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6069</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.5391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>0.5903</td>\n",
       "      <td>0.6167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.5901</td>\n",
       "      <td>0.4907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>0.5899</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.5899</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.5898</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6073</td>\n",
       "      <td>0.5897</td>\n",
       "      <td>0.5837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>0.5896</td>\n",
       "      <td>0.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.5896</td>\n",
       "      <td>0.5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6088</td>\n",
       "      <td>0.5891</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.5887</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.4908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.5884</td>\n",
       "      <td>0.5607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6352</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>0.6526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6101</td>\n",
       "      <td>0.5880</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.5490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.5878</td>\n",
       "      <td>0.6406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.5874</td>\n",
       "      <td>0.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.5873</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7086</td>\n",
       "      <td>0.5872</td>\n",
       "      <td>0.5200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5991</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6193</td>\n",
       "      <td>0.5868</td>\n",
       "      <td>0.5314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.5867</td>\n",
       "      <td>0.5314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.5137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>0.5860</td>\n",
       "      <td>0.4957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>0.5856</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>0.5854</td>\n",
       "      <td>0.5177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7910</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.5006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5707</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>0.5847</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.5843</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.5841</td>\n",
       "      <td>0.5589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>0.5080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.5834</td>\n",
       "      <td>0.6429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.5658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5947</td>\n",
       "      <td>0.5823</td>\n",
       "      <td>0.6606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.5823</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6116</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>0.5333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.5200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7319</td>\n",
       "      <td>0.5811</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.5807</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.5801</td>\n",
       "      <td>0.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.5801</td>\n",
       "      <td>0.4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.5799</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>0.5793</td>\n",
       "      <td>0.5947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.5793</td>\n",
       "      <td>0.6009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.5791</td>\n",
       "      <td>0.4908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5901</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>0.5080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>0.5786</td>\n",
       "      <td>0.5137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7318</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>0.5837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6626</td>\n",
       "      <td>0.5785</td>\n",
       "      <td>0.5837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.5792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5732</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5583</td>\n",
       "      <td>0.5774</td>\n",
       "      <td>0.6805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6937</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>0.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>0.5406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0.5762</td>\n",
       "      <td>0.5004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8178</td>\n",
       "      <td>0.5762</td>\n",
       "      <td>0.5837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5563</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>0.5761</td>\n",
       "      <td>0.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5496</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>0.6429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.5757</td>\n",
       "      <td>0.5361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5289</td>\n",
       "      <td>0.5753</td>\n",
       "      <td>0.4749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.5751</td>\n",
       "      <td>0.5607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7615</td>\n",
       "      <td>0.5751</td>\n",
       "      <td>0.5361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7207</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5358</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.5734</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8016</td>\n",
       "      <td>0.5732</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6047</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>0.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8038</td>\n",
       "      <td>0.5728</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>0.5724</td>\n",
       "      <td>0.6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.5723</td>\n",
       "      <td>0.7130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7373</td>\n",
       "      <td>0.5723</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.6077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.5718</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5287</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>0.5081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6884</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>0.5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7551</td>\n",
       "      <td>0.5708</td>\n",
       "      <td>0.5314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5312</td>\n",
       "      <td>0.5707</td>\n",
       "      <td>0.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7529</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.5697</td>\n",
       "      <td>0.6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.5694</td>\n",
       "      <td>0.5589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5961</td>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5348</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.5684</td>\n",
       "      <td>0.6537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>0.4838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6956</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7974</td>\n",
       "      <td>0.5682</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5535</td>\n",
       "      <td>0.5682</td>\n",
       "      <td>0.4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>0.5681</td>\n",
       "      <td>0.4749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.5722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7163</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>0.7588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5673</td>\n",
       "      <td>0.5671</td>\n",
       "      <td>0.5333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5376</td>\n",
       "      <td>0.5668</td>\n",
       "      <td>0.4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>0.5668</td>\n",
       "      <td>0.6312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.6822</td>\n",
       "      <td>0.5665</td>\n",
       "      <td>0.5177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>0.5658</td>\n",
       "      <td>0.4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5139</td>\n",
       "      <td>0.5646</td>\n",
       "      <td>0.4355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.5495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>0.6312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>0.5722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5546</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.5629</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5674</td>\n",
       "      <td>0.5621</td>\n",
       "      <td>0.4329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5316</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>0.4908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.4637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5336</td>\n",
       "      <td>0.5604</td>\n",
       "      <td>0.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8165</td>\n",
       "      <td>0.5601</td>\n",
       "      <td>0.5006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5383</td>\n",
       "      <td>0.5589</td>\n",
       "      <td>0.4909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.8191</td>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.4957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>0.6604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>0.5579</td>\n",
       "      <td>0.5361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.7796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5618</td>\n",
       "      <td>0.5564</td>\n",
       "      <td>0.4908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.5564</td>\n",
       "      <td>0.5924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.5090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>0.5090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>0.4644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5320</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5610</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.4908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>0.5479</td>\n",
       "      <td>0.5837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>0.5837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5353</td>\n",
       "      <td>0.5464</td>\n",
       "      <td>0.4469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5476</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5387</td>\n",
       "      <td>0.5454</td>\n",
       "      <td>0.5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.5392</td>\n",
       "      <td>0.4469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.4193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5553</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.4787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>0.5363</td>\n",
       "      <td>0.4787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5357</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>0.5292</td>\n",
       "      <td>0.5090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.5284</td>\n",
       "      <td>0.4930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.4930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5253</td>\n",
       "      <td>0.5164</td>\n",
       "      <td>0.5658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.5693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5168</td>\n",
       "      <td>0.5123</td>\n",
       "      <td>0.4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.5390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5281</td>\n",
       "      <td>0.5069</td>\n",
       "      <td>0.5674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.4502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>0.4602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.4602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.5402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.5562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.4855</td>\n",
       "      <td>0.5390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5301</td>\n",
       "      <td>0.4849</td>\n",
       "      <td>0.4257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.4818</td>\n",
       "      <td>0.4002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5674</td>\n",
       "      <td>0.4813</td>\n",
       "      <td>0.4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5204</td>\n",
       "      <td>0.4691</td>\n",
       "      <td>0.4657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5291</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>0.4002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4382</td>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.4624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5309</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.4736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5253</td>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.4502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5589</td>\n",
       "      <td>0.4552</td>\n",
       "      <td>0.4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>0.5541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.4487</td>\n",
       "      <td>0.4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4048</td>\n",
       "      <td>0.4457</td>\n",
       "      <td>0.4380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4119</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>0.4112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.4352</td>\n",
       "      <td>0.4112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4985</td>\n",
       "      <td>0.4276</td>\n",
       "      <td>0.4624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3927</td>\n",
       "      <td>0.4164</td>\n",
       "      <td>0.4624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5240</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4211</td>\n",
       "      <td>0.4051</td>\n",
       "      <td>0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.3926</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3822</td>\n",
       "      <td>0.3843</td>\n",
       "      <td>0.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3787</td>\n",
       "      <td>0.3841</td>\n",
       "      <td>0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4705</td>\n",
       "      <td>0.3822</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3806</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3786</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>0.3772</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3817</td>\n",
       "      <td>0.3767</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3768</td>\n",
       "      <td>0.3759</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4717</td>\n",
       "      <td>0.3749</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.3749</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.3746</td>\n",
       "      <td>0.3695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.3743</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3743</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5020</td>\n",
       "      <td>0.3743</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>0.3743</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3749</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.3741</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3748</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3746</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3741</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5047</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4973</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3741</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3764</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5043</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4783</td>\n",
       "      <td>0.3734</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3734</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3744</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4768</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4672</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5569</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4783</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4686</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3743</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4764</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4675</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4905</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4737</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4710</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4743</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4709</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4934</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4777</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4681</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4697</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5049</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4831</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5084</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4768</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4745</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4716</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4964</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4675</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3822</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5715</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4639</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4672</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4696</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4751</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4776</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4682</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4726</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4722</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4709</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4697</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3737</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4752</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4789</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4757</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4723</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3734</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4738</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.5579</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4738</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4783</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4685</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4682</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4664</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4757</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4771</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4710</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4942</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>None</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4819</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3749</td>\n",
       "      <td>0.3731</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>None</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.3731</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>w2v_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>ExponentialLR</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.3731</td>\n",
       "      <td>0.3787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5449</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.3120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>ft_pretrained</td>\n",
       "      <td>equal</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>xavier_uniform_</td>\n",
       "      <td>l2_reg</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>0.2899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>w2v_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>kaiming_uniform_</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>0.2899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>ft_selftrained</td>\n",
       "      <td>different</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>relu</td>\n",
       "      <td>None</td>\n",
       "      <td>dropout</td>\n",
       "      <td>LayerNorm</td>\n",
       "      <td>MultiStepLR</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>0.2899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           embeddings Layers type Optimizer  Batch  Count of layers  Epochs  \\\n",
       "1055   ft_selftrained       equal      Adam     64                3      10   \n",
       "1082   ft_selftrained   different      Adam     64                2      10   \n",
       "1054   ft_selftrained       equal      Adam     64                3      10   \n",
       "1028   ft_selftrained   different      Adam     64                3      10   \n",
       "1189   ft_selftrained   different      Adam     64                2      10   \n",
       "1109   ft_selftrained       equal      Adam     64                2      10   \n",
       "1053   ft_selftrained       equal      Adam     64                3      10   \n",
       "999    ft_selftrained       equal      Adam     64                2      10   \n",
       "1271   ft_selftrained       equal      Adam     64                3      10   \n",
       "972    ft_selftrained   different      Adam     64                2      10   \n",
       "1000   ft_selftrained       equal      Adam     64                2      10   \n",
       "1080   ft_selftrained   different      Adam     64                2      10   \n",
       "1188   ft_selftrained   different      Adam     64                2      10   \n",
       "1136   ft_selftrained   different      Adam     64                3      10   \n",
       "1272   ft_selftrained       equal      Adam     64                3      10   \n",
       "973    ft_selftrained   different      Adam     64                2      10   \n",
       "1058   ft_selftrained       equal      Adam     64                3      10   \n",
       "1026   ft_selftrained   different      Adam     64                3      10   \n",
       "1274   ft_selftrained       equal      Adam     64                3      10   \n",
       "1002   ft_selftrained       equal      Adam     64                2      10   \n",
       "982    ft_selftrained   different      Adam     64                2      10   \n",
       "1249   ft_selftrained   different      Adam     64                3      10   \n",
       "1168   ft_selftrained       equal      Adam     64                3      10   \n",
       "1222   ft_selftrained       equal      Adam     64                2      10   \n",
       "1141   ft_selftrained   different      Adam     64                3      10   \n",
       "1166   ft_selftrained       equal      Adam     64                3      10   \n",
       "1108   ft_selftrained       equal      Adam     64                2      10   \n",
       "1114   ft_selftrained       equal      Adam     64                2      10   \n",
       "1135   ft_selftrained   different      Adam     64                3      10   \n",
       "1142   ft_selftrained   different      Adam     64                3      10   \n",
       "1242   ft_selftrained   different      Adam     64                3      10   \n",
       "1169   ft_selftrained       equal      Adam     64                3      10   \n",
       "1215   ft_selftrained       equal      Adam     64                2      10   \n",
       "1140   ft_selftrained   different      Adam     64                3      10   \n",
       "974    ft_selftrained   different      Adam     64                2      10   \n",
       "1273   ft_selftrained       equal      Adam     64                3      10   \n",
       "1003   ft_selftrained       equal      Adam     64                2      10   \n",
       "1084   ft_selftrained   different      Adam     64                2      10   \n",
       "1195   ft_selftrained   different      Adam     64                2      10   \n",
       "1248   ft_selftrained   different      Adam     64                3      10   \n",
       "1165   ft_selftrained       equal      Adam     64                3      10   \n",
       "1190   ft_selftrained   different      Adam     64                2      10   \n",
       "1243   ft_selftrained   different      Adam     64                3      10   \n",
       "1275   ft_selftrained       equal      Adam     64                3      10   \n",
       "1216   ft_selftrained       equal      Adam     64                2      10   \n",
       "1162   ft_selftrained       equal      Adam     64                3      10   \n",
       "1134   ft_selftrained   different      Adam     64                3      10   \n",
       "1115   ft_selftrained       equal      Adam     64                2      10   \n",
       "1192   ft_selftrained   different      Adam     64                2      10   \n",
       "1088   ft_selftrained   different      Adam     64                2      10   \n",
       "1087   ft_selftrained   different      Adam     64                2      10   \n",
       "1081   ft_selftrained   different      Adam     64                2      10   \n",
       "1270   ft_selftrained       equal      Adam     64                3      10   \n",
       "1167   ft_selftrained       equal      Adam     64                3      10   \n",
       "1113   ft_selftrained       equal      Adam     64                2      10   \n",
       "1194   ft_selftrained   different      Adam     64                2      10   \n",
       "1221   ft_selftrained       equal      Adam     64                2      10   \n",
       "978    ft_selftrained   different      Adam     64                2      10   \n",
       "1086   ft_selftrained   different      Adam     64                2      10   \n",
       "1107   ft_selftrained       equal      Adam     64                2      10   \n",
       "1193   ft_selftrained   different      Adam     64                2      10   \n",
       "1247   ft_selftrained   different      Adam     64                3      10   \n",
       "676   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1246   ft_selftrained   different      Adam     64                3      10   \n",
       "1131   ft_selftrained       equal      Adam     64                2      10   \n",
       "1001   ft_selftrained       equal      Adam     64                2      10   \n",
       "1219   ft_selftrained       equal      Adam     64                2      10   \n",
       "729   w2v_selftrained       equal      Adam     64                3      10   \n",
       "976    ft_selftrained   different      Adam     64                2      10   \n",
       "1220   ft_selftrained       equal      Adam     64                2      10   \n",
       "1004   ft_selftrained       equal      Adam     64                2      10   \n",
       "1150   ft_selftrained   different      Adam     64                3      10   \n",
       "1111   ft_selftrained       equal      Adam     64                2      10   \n",
       "1037   ft_selftrained   different      Adam     64                3      10   \n",
       "702   w2v_selftrained   different      Adam     64                3      10   \n",
       "675   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1218   ft_selftrained       equal      Adam     64                2      10   \n",
       "892   w2v_selftrained       equal      Adam     64                2      10   \n",
       "949   w2v_selftrained       equal      Adam     64                3      10   \n",
       "677   w2v_selftrained       equal      Adam     64                2      10   \n",
       "704   w2v_selftrained   different      Adam     64                3      10   \n",
       "757   w2v_selftrained   different      Adam     64                2      10   \n",
       "1110   ft_selftrained       equal      Adam     64                2      10   \n",
       "1244   ft_selftrained   different      Adam     64                3      10   \n",
       "759   w2v_selftrained   different      Adam     64                2      10   \n",
       "866   w2v_selftrained   different      Adam     64                2      10   \n",
       "871   w2v_selftrained   different      Adam     64                2      10   \n",
       "1056   ft_selftrained       equal      Adam     64                3      10   \n",
       "893   w2v_selftrained       equal      Adam     64                2      10   \n",
       "712   w2v_selftrained   different      Adam     64                3      10   \n",
       "891   w2v_selftrained       equal      Adam     64                2      10   \n",
       "790   w2v_selftrained       equal      Adam     64                2      10   \n",
       "811   w2v_selftrained   different      Adam     64                3      10   \n",
       "650   w2v_selftrained   different      Adam     64                2      10   \n",
       "732   w2v_selftrained       equal      Adam     64                3      10   \n",
       "983    ft_selftrained   different      Adam     64                2      10   \n",
       "763   w2v_selftrained   different      Adam     64                2      10   \n",
       "703   w2v_selftrained   different      Adam     64                3      10   \n",
       "783   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1161   ft_selftrained       equal      Adam     64                3      10   \n",
       "653   w2v_selftrained   different      Adam     64                2      10   \n",
       "1017   ft_selftrained       equal      Adam     64                2      10   \n",
       "648   w2v_selftrained   different      Adam     64                2      10   \n",
       "898   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1239   ft_selftrained       equal      Adam     64                2      10   \n",
       "1030   ft_selftrained   different      Adam     64                3      10   \n",
       "758   w2v_selftrained   different      Adam     64                2      10   \n",
       "649   w2v_selftrained   different      Adam     64                2      10   \n",
       "818   w2v_selftrained   different      Adam     64                3      10   \n",
       "1191   ft_selftrained   different      Adam     64                2      10   \n",
       "867   w2v_selftrained   different      Adam     64                2      10   \n",
       "785   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1104   ft_selftrained   different      Adam     64                2      10   \n",
       "945   w2v_selftrained       equal      Adam     64                3      10   \n",
       "844   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1217   ft_selftrained       equal      Adam     64                2      10   \n",
       "840   w2v_selftrained       equal      Adam     64                3      10   \n",
       "996    ft_selftrained   different      Adam     64                2      10   \n",
       "899   w2v_selftrained       equal      Adam     64                2      10   \n",
       "977    ft_selftrained   different      Adam     64                2      10   \n",
       "817   w2v_selftrained   different      Adam     64                3      10   \n",
       "865   w2v_selftrained   different      Adam     64                2      10   \n",
       "1163   ft_selftrained       equal      Adam     64                3      10   \n",
       "752   w2v_selftrained       equal      Adam     64                3      10   \n",
       "841   w2v_selftrained       equal      Adam     64                3      10   \n",
       "679   w2v_selftrained       equal      Adam     64                2      10   \n",
       "787   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1029   ft_selftrained   different      Adam     64                3      10   \n",
       "784   w2v_selftrained       equal      Adam     64                2      10   \n",
       "997    ft_selftrained   different      Adam     64                2      10   \n",
       "762   w2v_selftrained   different      Adam     64                2      10   \n",
       "843   w2v_selftrained       equal      Adam     64                3      10   \n",
       "680   w2v_selftrained       equal      Adam     64                2      10   \n",
       "868   w2v_selftrained   different      Adam     64                2      10   \n",
       "845   w2v_selftrained       equal      Adam     64                3      10   \n",
       "864   w2v_selftrained   different      Adam     64                2      10   \n",
       "731   w2v_selftrained       equal      Adam     64                3      10   \n",
       "791   w2v_selftrained       equal      Adam     64                2      10   \n",
       "919   w2v_selftrained   different      Adam     64                3      10   \n",
       "920   w2v_selftrained   different      Adam     64                3      10   \n",
       "651   w2v_selftrained   different      Adam     64                2      10   \n",
       "789   w2v_selftrained       equal      Adam     64                2      10   \n",
       "664   w2v_selftrained   different      Adam     64                2      10   \n",
       "897   w2v_selftrained       equal      Adam     64                2      10   \n",
       "810   w2v_selftrained   different      Adam     64                3      10   \n",
       "922   w2v_selftrained   different      Adam     64                3      10   \n",
       "993    ft_selftrained   different      Adam     64                2      10   \n",
       "786   w2v_selftrained       equal      Adam     64                2      10   \n",
       "816   w2v_selftrained   different      Adam     64                3      10   \n",
       "756   w2v_selftrained   different      Adam     64                2      10   \n",
       "652   w2v_selftrained   different      Adam     64                2      10   \n",
       "894   w2v_selftrained       equal      Adam     64                2      10   \n",
       "730   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1206   ft_selftrained   different      Adam     64                2      10   \n",
       "869   w2v_selftrained   different      Adam     64                2      10   \n",
       "896   w2v_selftrained       equal      Adam     64                2      10   \n",
       "760   w2v_selftrained   different      Adam     64                2      10   \n",
       "719   w2v_selftrained   different      Adam     64                3      10   \n",
       "27     w2v_pretrained       equal      Adam     64                2      10   \n",
       "1269   ft_selftrained       equal      Adam     64                3      10   \n",
       "665   w2v_selftrained   different      Adam     64                2      10   \n",
       "301    w2v_pretrained       equal      Adam     64                3      10   \n",
       "842   w2v_selftrained       equal      Adam     64                3      10   \n",
       "244    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1105   ft_selftrained   different      Adam     64                2      10   \n",
       "1212   ft_selftrained   different      Adam     64                2      10   \n",
       "1112   ft_selftrained       equal      Adam     64                2      10   \n",
       "110    w2v_pretrained   different      Adam     64                2      10   \n",
       "895   w2v_selftrained       equal      Adam     64                2      10   \n",
       "918   w2v_selftrained   different      Adam     64                3      10   \n",
       "812   w2v_selftrained   different      Adam     64                3      10   \n",
       "1238   ft_selftrained       equal      Adam     64                2      10   \n",
       "981    ft_selftrained   different      Adam     64                2      10   \n",
       "1130   ft_selftrained       equal      Adam     64                2      10   \n",
       "788   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1159   ft_selftrained   different      Adam     64                3      10   \n",
       "1020   ft_selftrained       equal      Adam     64                2      10   \n",
       "54     w2v_pretrained   different      Adam     64                3      10   \n",
       "994    ft_selftrained   different      Adam     64                2      10   \n",
       "879   w2v_selftrained   different      Adam     64                2      10   \n",
       "83     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1046   ft_selftrained   different      Adam     64                3      10   \n",
       "1022   ft_selftrained       equal      Adam     64                2      10   \n",
       "136    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1076   ft_selftrained       equal      Adam     64                3      10   \n",
       "697   w2v_selftrained       equal      Adam     64                2      10   \n",
       "950   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1234   ft_selftrained       equal      Adam     64                2      10   \n",
       "707   w2v_selftrained   different      Adam     64                3      10   \n",
       "243    w2v_pretrained       equal      Adam     64                2      10   \n",
       "948   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1047   ft_selftrained   different      Adam     64                3      10   \n",
       "1051   ft_selftrained   different      Adam     64                3      10   \n",
       "825   w2v_selftrained   different      Adam     64                3      10   \n",
       "696   w2v_selftrained       equal      Adam     64                2      10   \n",
       "17     w2v_pretrained   different      Adam     64                2      10   \n",
       "1101   ft_selftrained   different      Adam     64                2      10   \n",
       "1267   ft_selftrained   different      Adam     64                3      10   \n",
       "108    w2v_pretrained   different      Adam     64                2      10   \n",
       "734   w2v_selftrained       equal      Adam     64                3      10   \n",
       "2      w2v_pretrained   different      Adam     64                2      10   \n",
       "135    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1185   ft_selftrained       equal      Adam     64                3      10   \n",
       "1290   ft_selftrained       equal      Adam     64                3      10   \n",
       "28     w2v_pretrained       equal      Adam     64                2      10   \n",
       "726   w2v_selftrained   different      Adam     64                3      10   \n",
       "137    w2v_pretrained       equal      Adam     64                2      10   \n",
       "946   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1025   ft_selftrained       equal      Adam     64                2      10   \n",
       "218    w2v_pretrained   different      Adam     64                2      10   \n",
       "998    ft_selftrained   different      Adam     64                2      10   \n",
       "1044   ft_selftrained   different      Adam     64                3      10   \n",
       "82     w2v_pretrained       equal      Adam     64                3      10   \n",
       "992    ft_selftrained   different      Adam     64                2      10   \n",
       "1023   ft_selftrained       equal      Adam     64                2      10   \n",
       "29     w2v_pretrained       equal      Adam     64                2      10   \n",
       "750   w2v_selftrained       equal      Adam     64                3      10   \n",
       "995    ft_selftrained   different      Adam     64                2      10   \n",
       "968   w2v_selftrained       equal      Adam     64                3      10   \n",
       "298    w2v_pretrained       equal      Adam     64                3      10   \n",
       "678   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1164   ft_selftrained       equal      Adam     64                3      10   \n",
       "802   w2v_selftrained       equal      Adam     64                2      10   \n",
       "217    w2v_pretrained   different      Adam     64                2      10   \n",
       "1202   ft_selftrained   different      Adam     64                2      10   \n",
       "271    w2v_pretrained   different      Adam     64                3      10   \n",
       "659   w2v_selftrained   different      Adam     64                2      10   \n",
       "163    w2v_pretrained   different      Adam     64                3      10   \n",
       "1208   ft_selftrained   different      Adam     64                2      10   \n",
       "838   w2v_selftrained       equal      Adam     64                3      10   \n",
       "883   w2v_selftrained   different      Adam     64                2      10   \n",
       "915   w2v_selftrained       equal      Adam     64                2      10   \n",
       "670   w2v_selftrained   different      Adam     64                2      10   \n",
       "216    w2v_pretrained   different      Adam     64                2      10   \n",
       "1      w2v_pretrained   different      Adam     64                2      10   \n",
       "245    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1268   ft_selftrained   different      Adam     64                3      10   \n",
       "1207   ft_selftrained   different      Adam     64                2      10   \n",
       "858   w2v_selftrained       equal      Adam     64                3      10   \n",
       "839   w2v_selftrained       equal      Adam     64                3      10   \n",
       "988    ft_selftrained   different      Adam     64                2      10   \n",
       "1098   ft_selftrained   different      Adam     64                2      10   \n",
       "55     w2v_pretrained   different      Adam     64                3      10   \n",
       "1103   ft_selftrained   different      Adam     64                2      10   \n",
       "111    w2v_pretrained   different      Adam     64                2      10   \n",
       "1075   ft_selftrained       equal      Adam     64                3      10   \n",
       "1145   ft_selftrained   different      Adam     64                3      10   \n",
       "672   w2v_selftrained   different      Adam     64                2      10   \n",
       "274    w2v_pretrained   different      Adam     64                3      10   \n",
       "1050   ft_selftrained   different      Adam     64                3      10   \n",
       "1236   ft_selftrained       equal      Adam     64                2      10   \n",
       "1074   ft_selftrained       equal      Adam     64                3      10   \n",
       "1293   ft_selftrained       equal      Adam     64                3      10   \n",
       "1213   ft_selftrained   different      Adam     64                2      10   \n",
       "1021   ft_selftrained       equal      Adam     64                2      10   \n",
       "733   w2v_selftrained       equal      Adam     64                3      10   \n",
       "56     w2v_pretrained   different      Adam     64                3      10   \n",
       "991    ft_selftrained   different      Adam     64                2      10   \n",
       "1100   ft_selftrained   different      Adam     64                2      10   \n",
       "273    w2v_pretrained   different      Adam     64                3      10   \n",
       "21     w2v_pretrained   different      Adam     64                2      10   \n",
       "246    w2v_pretrained       equal      Adam     64                2      10   \n",
       "233    w2v_pretrained   different      Adam     64                2      10   \n",
       "771   w2v_selftrained   different      Adam     64                2      10   \n",
       "706   w2v_selftrained   different      Adam     64                3      10   \n",
       "882   w2v_selftrained   different      Adam     64                2      10   \n",
       "807   w2v_selftrained       equal      Adam     64                2      10   \n",
       "813   w2v_selftrained   different      Adam     64                3      10   \n",
       "885   w2v_selftrained   different      Adam     64                2      10   \n",
       "1291   ft_selftrained       equal      Adam     64                3      10   \n",
       "1152   ft_selftrained   different      Adam     64                3      10   \n",
       "1266   ft_selftrained   different      Adam     64                3      10   \n",
       "1127   ft_selftrained       equal      Adam     64                2      10   \n",
       "751   w2v_selftrained       equal      Adam     64                3      10   \n",
       "669   w2v_selftrained   different      Adam     64                2      10   \n",
       "1214   ft_selftrained   different      Adam     64                2      10   \n",
       "804   w2v_selftrained       equal      Adam     64                2      10   \n",
       "190    w2v_pretrained       equal      Adam     64                3      10   \n",
       "1052   ft_selftrained   different      Adam     64                3      10   \n",
       "913   w2v_selftrained       equal      Adam     64                2      10   \n",
       "0      w2v_pretrained   different      Adam     64                2      10   \n",
       "1133   ft_selftrained       equal      Adam     64                2      10   \n",
       "195    w2v_pretrained       equal      Adam     64                3      10   \n",
       "189    w2v_pretrained       equal      Adam     64                3      10   \n",
       "914   w2v_selftrained       equal      Adam     64                2      10   \n",
       "63     w2v_pretrained   different      Adam     64                3      10   \n",
       "705   w2v_selftrained   different      Adam     64                3      10   \n",
       "162    w2v_pretrained   different      Adam     64                3      10   \n",
       "81     w2v_pretrained       equal      Adam     64                3      10   \n",
       "718   w2v_selftrained   different      Adam     64                3      10   \n",
       "1106   ft_selftrained   different      Adam     64                2      10   \n",
       "1024   ft_selftrained       equal      Adam     64                2      10   \n",
       "1295   ft_selftrained       equal      Adam     64                3      10   \n",
       "164    w2v_pretrained   different      Adam     64                3      10   \n",
       "1128   ft_selftrained       equal      Adam     64                2      10   \n",
       "826   w2v_selftrained   different      Adam     64                3      10   \n",
       "84     w2v_pretrained       equal      Adam     64                3      10   \n",
       "666   w2v_selftrained   different      Adam     64                2      10   \n",
       "196    w2v_pretrained       equal      Adam     64                3      10   \n",
       "910   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1057   ft_selftrained       equal      Adam     64                3      10   \n",
       "170    w2v_pretrained   different      Adam     64                3      10   \n",
       "699   w2v_selftrained       equal      Adam     64                2      10   \n",
       "917   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1077   ft_selftrained       equal      Adam     64                3      10   \n",
       "947   w2v_selftrained       equal      Adam     64                3      10   \n",
       "3      w2v_pretrained   different      Adam     64                2      10   \n",
       "251    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1264   ft_selftrained   different      Adam     64                3      10   \n",
       "140    w2v_pretrained       equal      Adam     64                2      10   \n",
       "780   w2v_selftrained   different      Adam     64                2      10   \n",
       "1019   ft_selftrained       equal      Adam     64                2      10   \n",
       "874   w2v_selftrained   different      Adam     64                2      10   \n",
       "966   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1241   ft_selftrained       equal      Adam     64                2      10   \n",
       "1132   ft_selftrained       equal      Adam     64                2      10   \n",
       "109    w2v_pretrained   different      Adam     64                2      10   \n",
       "1125   ft_selftrained       equal      Adam     64                2      10   \n",
       "831   w2v_selftrained   different      Adam     64                3      10   \n",
       "143    w2v_pretrained       equal      Adam     64                2      10   \n",
       "711   w2v_selftrained   different      Adam     64                3      10   \n",
       "197    w2v_pretrained       equal      Adam     64                3      10   \n",
       "16     w2v_pretrained   different      Adam     64                2      10   \n",
       "671   w2v_selftrained   different      Adam     64                2      10   \n",
       "805   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1160   ft_selftrained   different      Adam     64                3      10   \n",
       "815   w2v_selftrained   different      Adam     64                3      10   \n",
       "222    w2v_pretrained   different      Adam     64                2      10   \n",
       "1155   ft_selftrained   different      Adam     64                3      10   \n",
       "1126   ft_selftrained       equal      Adam     64                2      10   \n",
       "1211   ft_selftrained   different      Adam     64                2      10   \n",
       "1018   ft_selftrained       equal      Adam     64                2      10   \n",
       "1237   ft_selftrained       equal      Adam     64                2      10   \n",
       "1210   ft_selftrained   different      Adam     64                2      10   \n",
       "141    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1043   ft_selftrained   different      Adam     64                3      10   \n",
       "299    w2v_pretrained       equal      Adam     64                3      10   \n",
       "169    w2v_pretrained   different      Adam     64                3      10   \n",
       "278    w2v_pretrained   different      Adam     64                3      10   \n",
       "1158   ft_selftrained   different      Adam     64                3      10   \n",
       "1129   ft_selftrained       equal      Adam     64                2      10   \n",
       "761   w2v_selftrained   different      Adam     64                2      10   \n",
       "221    w2v_pretrained   different      Adam     64                2      10   \n",
       "193    w2v_pretrained       equal      Adam     64                3      10   \n",
       "219    w2v_pretrained   different      Adam     64                2      10   \n",
       "837   w2v_selftrained       equal      Adam     64                3      10   \n",
       "57     w2v_pretrained   different      Adam     64                3      10   \n",
       "755   w2v_selftrained       equal      Adam     64                3      10   \n",
       "116    w2v_pretrained   different      Adam     64                2      10   \n",
       "31     w2v_pretrained       equal      Adam     64                2      10   \n",
       "775   w2v_selftrained   different      Adam     64                2      10   \n",
       "114    w2v_pretrained   different      Adam     64                2      10   \n",
       "168    w2v_pretrained   different      Adam     64                3      10   \n",
       "300    w2v_pretrained       equal      Adam     64                3      10   \n",
       "782   w2v_selftrained   different      Adam     64                2      10   \n",
       "774   w2v_selftrained   different      Adam     64                2      10   \n",
       "927   w2v_selftrained   different      Adam     64                3      10   \n",
       "916   w2v_selftrained       equal      Adam     64                2      10   \n",
       "85     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1182   ft_selftrained       equal      Adam     64                3      10   \n",
       "1184   ft_selftrained       equal      Adam     64                3      10   \n",
       "834   w2v_selftrained   different      Adam     64                3      10   \n",
       "890   w2v_selftrained   different      Adam     64                2      10   \n",
       "819   w2v_selftrained   different      Adam     64                3      10   \n",
       "126    w2v_pretrained   different      Adam     64                2      10   \n",
       "723   w2v_selftrained   different      Adam     64                3      10   \n",
       "809   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1153   ft_selftrained   different      Adam     64                3      10   \n",
       "803   w2v_selftrained       equal      Adam     64                2      10   \n",
       "142    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1048   ft_selftrained   different      Adam     64                3      10   \n",
       "248    w2v_pretrained       equal      Adam     64                2      10   \n",
       "693   w2v_selftrained       equal      Adam     64                2      10   \n",
       "50     w2v_pretrained       equal      Adam     64                2      10   \n",
       "139    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1099   ft_selftrained   different      Adam     64                2      10   \n",
       "990    ft_selftrained   different      Adam     64                2      10   \n",
       "1045   ft_selftrained   different      Adam     64                3      10   \n",
       "1240   ft_selftrained       equal      Adam     64                2      10   \n",
       "969   w2v_selftrained       equal      Adam     64                3      10   \n",
       "220    w2v_pretrained   different      Adam     64                2      10   \n",
       "1260   ft_selftrained   different      Adam     64                3      10   \n",
       "668   w2v_selftrained   different      Adam     64                2      10   \n",
       "115    w2v_pretrained   different      Adam     64                2      10   \n",
       "814   w2v_selftrained   different      Adam     64                3      10   \n",
       "801   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1233   ft_selftrained       equal      Adam     64                2      10   \n",
       "698   w2v_selftrained       equal      Adam     64                2      10   \n",
       "4      w2v_pretrained   different      Adam     64                2      10   \n",
       "5      w2v_pretrained   different      Adam     64                2      10   \n",
       "250    w2v_pretrained       equal      Adam     64                2      10   \n",
       "191    w2v_pretrained       equal      Adam     64                3      10   \n",
       "808   w2v_selftrained       equal      Adam     64                2      10   \n",
       "667   w2v_selftrained   different      Adam     64                2      10   \n",
       "836   w2v_selftrained   different      Adam     64                3      10   \n",
       "1079   ft_selftrained       equal      Adam     64                3      10   \n",
       "69     w2v_pretrained   different      Adam     64                3      10   \n",
       "15     w2v_pretrained   different      Adam     64                2      10   \n",
       "884   w2v_selftrained   different      Adam     64                2      10   \n",
       "291    w2v_pretrained   different      Adam     64                3      10   \n",
       "921   w2v_selftrained   different      Adam     64                3      10   \n",
       "32     w2v_pretrained       equal      Adam     64                2      10   \n",
       "778   w2v_selftrained   different      Adam     64                2      10   \n",
       "724   w2v_selftrained   different      Adam     64                3      10   \n",
       "747   w2v_selftrained       equal      Adam     64                3      10   \n",
       "888   w2v_selftrained   different      Adam     64                2      10   \n",
       "720   w2v_selftrained   different      Adam     64                3      10   \n",
       "909   w2v_selftrained       equal      Adam     64                2      10   \n",
       "25     w2v_pretrained   different      Adam     64                2      10   \n",
       "701   w2v_selftrained       equal      Adam     64                2      10   \n",
       "694   w2v_selftrained       equal      Adam     64                2      10   \n",
       "26     w2v_pretrained   different      Adam     64                2      10   \n",
       "192    w2v_pretrained       equal      Adam     64                3      10   \n",
       "722   w2v_selftrained   different      Adam     64                3      10   \n",
       "674   w2v_selftrained   different      Adam     64                2      10   \n",
       "138    w2v_pretrained       equal      Adam     64                2      10   \n",
       "695   w2v_selftrained       equal      Adam     64                2      10   \n",
       "936   w2v_selftrained   different      Adam     64                3      10   \n",
       "10     w2v_pretrained   different      Adam     64                2      10   \n",
       "700   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1186   ft_selftrained       equal      Adam     64                3      10   \n",
       "911   w2v_selftrained       equal      Adam     64                2      10   \n",
       "272    w2v_pretrained   different      Adam     64                3      10   \n",
       "270    w2v_pretrained   different      Adam     64                3      10   \n",
       "887   w2v_selftrained   different      Adam     64                2      10   \n",
       "860   w2v_selftrained       equal      Adam     64                3      10   \n",
       "781   w2v_selftrained   different      Adam     64                2      10   \n",
       "971   w2v_selftrained       equal      Adam     64                3      10   \n",
       "889   w2v_selftrained   different      Adam     64                2      10   \n",
       "112    w2v_pretrained   different      Adam     64                2      10   \n",
       "1245   ft_selftrained   different      Adam     64                3      10   \n",
       "727   w2v_selftrained   different      Adam     64                3      10   \n",
       "133    w2v_pretrained   different      Adam     64                2      10   \n",
       "1072   ft_selftrained       equal      Adam     64                3      10   \n",
       "663   w2v_selftrained   different      Adam     64                2      10   \n",
       "132    w2v_pretrained   different      Adam     64                2      10   \n",
       "1292   ft_selftrained       equal      Adam     64                3      10   \n",
       "754   w2v_selftrained       equal      Adam     64                3      10   \n",
       "828   w2v_selftrained   different      Adam     64                3      10   \n",
       "1261   ft_selftrained   different      Adam     64                3      10   \n",
       "829   w2v_selftrained   different      Adam     64                3      10   \n",
       "223    w2v_pretrained   different      Adam     64                2      10   \n",
       "1078   ft_selftrained       equal      Adam     64                3      10   \n",
       "975    ft_selftrained   different      Adam     64                2      10   \n",
       "30     w2v_pretrained       equal      Adam     64                2      10   \n",
       "967   w2v_selftrained       equal      Adam     64                3      10   \n",
       "776   w2v_selftrained   different      Adam     64                2      10   \n",
       "102    w2v_pretrained       equal      Adam     64                3      10   \n",
       "320    w2v_pretrained       equal      Adam     64                3      10   \n",
       "156    w2v_pretrained       equal      Adam     64                2      10   \n",
       "22     w2v_pretrained   different      Adam     64                2      10   \n",
       "806   w2v_selftrained       equal      Adam     64                2      10   \n",
       "80     w2v_pretrained   different      Adam     64                3      10   \n",
       "728   w2v_selftrained   different      Adam     64                3      10   \n",
       "103    w2v_pretrained       equal      Adam     64                3      10   \n",
       "1187   ft_selftrained       equal      Adam     64                3      10   \n",
       "19     w2v_pretrained   different      Adam     64                2      10   \n",
       "863   w2v_selftrained       equal      Adam     64                3      10   \n",
       "214    w2v_pretrained       equal      Adam     64                3      10   \n",
       "673   w2v_selftrained   different      Adam     64                2      10   \n",
       "134    w2v_pretrained   different      Adam     64                2      10   \n",
       "1071   ft_selftrained       equal      Adam     64                3      10   \n",
       "835   w2v_selftrained   different      Adam     64                3      10   \n",
       "318    w2v_pretrained       equal      Adam     64                3      10   \n",
       "861   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1289   ft_selftrained       equal      Adam     64                3      10   \n",
       "944   w2v_selftrained   different      Adam     64                3      10   \n",
       "886   w2v_selftrained   different      Adam     64                2      10   \n",
       "753   w2v_selftrained       equal      Adam     64                3      10   \n",
       "237    w2v_pretrained   different      Adam     64                2      10   \n",
       "1049   ft_selftrained   different      Adam     64                3      10   \n",
       "24     w2v_pretrained   different      Adam     64                2      10   \n",
       "127    w2v_pretrained   different      Adam     64                2      10   \n",
       "1262   ft_selftrained   different      Adam     64                3      10   \n",
       "779   w2v_selftrained   different      Adam     64                2      10   \n",
       "73     w2v_pretrained   different      Adam     64                3      10   \n",
       "155    w2v_pretrained       equal      Adam     64                2      10   \n",
       "49     w2v_pretrained       equal      Adam     64                2      10   \n",
       "1183   ft_selftrained       equal      Adam     64                3      10   \n",
       "1235   ft_selftrained       equal      Adam     64                2      10   \n",
       "267    w2v_pretrained       equal      Adam     64                2      10   \n",
       "275    w2v_pretrained   different      Adam     64                3      10   \n",
       "1179   ft_selftrained       equal      Adam     64                3      10   \n",
       "319    w2v_pretrained       equal      Adam     64                3      10   \n",
       "938   w2v_selftrained   different      Adam     64                3      10   \n",
       "1287   ft_selftrained       equal      Adam     64                3      10   \n",
       "266    w2v_pretrained       equal      Adam     64                2      10   \n",
       "154    w2v_pretrained       equal      Adam     64                2      10   \n",
       "75     w2v_pretrained   different      Adam     64                3      10   \n",
       "51     w2v_pretrained       equal      Adam     64                2      10   \n",
       "297    w2v_pretrained       equal      Adam     64                3      10   \n",
       "18     w2v_pretrained   different      Adam     64                2      10   \n",
       "942   w2v_selftrained   different      Adam     64                3      10   \n",
       "859   w2v_selftrained       equal      Adam     64                3      10   \n",
       "912   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1288   ft_selftrained       equal      Adam     64                3      10   \n",
       "970   w2v_selftrained       equal      Adam     64                3      10   \n",
       "264    w2v_pretrained       equal      Adam     64                2      10   \n",
       "53     w2v_pretrained       equal      Adam     64                2      10   \n",
       "212    w2v_pretrained       equal      Adam     64                3      10   \n",
       "1197   ft_selftrained   different      Adam     64                2      10   \n",
       "48     w2v_pretrained       equal      Adam     64                2      10   \n",
       "153    w2v_pretrained       equal      Adam     64                2      10   \n",
       "23     w2v_pretrained   different      Adam     64                2      10   \n",
       "1294   ft_selftrained       equal      Adam     64                3      10   \n",
       "685   w2v_selftrained       equal      Adam     64                2      10   \n",
       "161    w2v_pretrained       equal      Adam     64                2      10   \n",
       "78     w2v_pretrained   different      Adam     64                3      10   \n",
       "159    w2v_pretrained       equal      Adam     64                2      10   \n",
       "240    w2v_pretrained   different      Adam     64                2      10   \n",
       "262    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1085   ft_selftrained   different      Adam     64                2      10   \n",
       "194    w2v_pretrained       equal      Adam     64                3      10   \n",
       "234    w2v_pretrained   different      Adam     64                2      10   \n",
       "167    w2v_pretrained   different      Adam     64                3      10   \n",
       "268    w2v_pretrained       equal      Adam     64                2      10   \n",
       "235    w2v_pretrained   different      Adam     64                2      10   \n",
       "1073   ft_selftrained       equal      Adam     64                3      10   \n",
       "47     w2v_pretrained       equal      Adam     64                2      10   \n",
       "1209   ft_selftrained   different      Adam     64                2      10   \n",
       "279    w2v_pretrained   different      Adam     64                3      10   \n",
       "721   w2v_selftrained   different      Adam     64                3      10   \n",
       "188    w2v_pretrained   different      Adam     64                3      10   \n",
       "105    w2v_pretrained       equal      Adam     64                3      10   \n",
       "943   w2v_selftrained   different      Adam     64                3      10   \n",
       "294    w2v_pretrained   different      Adam     64                3      10   \n",
       "45     w2v_pretrained       equal      Adam     64                2      10   \n",
       "323    w2v_pretrained       equal      Adam     64                3      10   \n",
       "963   w2v_selftrained       equal      Adam     64                3      10   \n",
       "104    w2v_pretrained       equal      Adam     64                3      10   \n",
       "79     w2v_pretrained   different      Adam     64                3      10   \n",
       "1180   ft_selftrained       equal      Adam     64                3      10   \n",
       "777   w2v_selftrained   different      Adam     64                2      10   \n",
       "749   w2v_selftrained       equal      Adam     64                3      10   \n",
       "238    w2v_pretrained   different      Adam     64                2      10   \n",
       "321    w2v_pretrained       equal      Adam     64                3      10   \n",
       "748   w2v_selftrained       equal      Adam     64                3      10   \n",
       "236    w2v_pretrained   different      Adam     64                2      10   \n",
       "242    w2v_pretrained   different      Adam     64                2      10   \n",
       "101    w2v_pretrained       equal      Adam     64                3      10   \n",
       "289    w2v_pretrained   different      Adam     64                3      10   \n",
       "166    w2v_pretrained   different      Adam     64                3      10   \n",
       "269    w2v_pretrained       equal      Adam     64                2      10   \n",
       "295    w2v_pretrained   different      Adam     64                3      10   \n",
       "107    w2v_pretrained       equal      Adam     64                3      10   \n",
       "261    w2v_pretrained       equal      Adam     64                2      10   \n",
       "129    w2v_pretrained   different      Adam     64                2      10   \n",
       "158    w2v_pretrained       equal      Adam     64                2      10   \n",
       "213    w2v_pretrained       equal      Adam     64                3      10   \n",
       "72     w2v_pretrained   different      Adam     64                3      10   \n",
       "106    w2v_pretrained       equal      Adam     64                3      10   \n",
       "856   w2v_selftrained       equal      Adam     64                3      10   \n",
       "263    w2v_pretrained       equal      Adam     64                2      10   \n",
       "239    w2v_pretrained   different      Adam     64                2      10   \n",
       "830   w2v_selftrained   different      Adam     64                3      10   \n",
       "937   w2v_selftrained   different      Adam     64                3      10   \n",
       "862   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1181   ft_selftrained       equal      Adam     64                3      10   \n",
       "210    w2v_pretrained       equal      Adam     64                3      10   \n",
       "157    w2v_pretrained       equal      Adam     64                2      10   \n",
       "52     w2v_pretrained       equal      Adam     64                2      10   \n",
       "288    w2v_pretrained   different      Adam     64                3      10   \n",
       "181    w2v_pretrained   different      Adam     64                3      10   \n",
       "241    w2v_pretrained   different      Adam     64                2      10   \n",
       "20     w2v_pretrained   different      Adam     64                2      10   \n",
       "160    w2v_pretrained       equal      Adam     64                2      10   \n",
       "215    w2v_pretrained       equal      Adam     64                3      10   \n",
       "186    w2v_pretrained   different      Adam     64                3      10   \n",
       "131    w2v_pretrained   different      Adam     64                2      10   \n",
       "183    w2v_pretrained   different      Adam     64                3      10   \n",
       "74     w2v_pretrained   different      Adam     64                3      10   \n",
       "86     w2v_pretrained       equal      Adam     64                3      10   \n",
       "46     w2v_pretrained       equal      Adam     64                2      10   \n",
       "315    w2v_pretrained       equal      Adam     64                3      10   \n",
       "290    w2v_pretrained   different      Adam     64                3      10   \n",
       "322    w2v_pretrained       equal      Adam     64                3      10   \n",
       "165    w2v_pretrained   different      Adam     64                3      10   \n",
       "128    w2v_pretrained   different      Adam     64                2      10   \n",
       "316    w2v_pretrained       equal      Adam     64                3      10   \n",
       "296    w2v_pretrained   different      Adam     64                3      10   \n",
       "857   w2v_selftrained       equal      Adam     64                3      10   \n",
       "692   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1083   ft_selftrained   different      Adam     64                2      10   \n",
       "725   w2v_selftrained   different      Adam     64                3      10   \n",
       "293    w2v_pretrained   different      Adam     64                3      10   \n",
       "265    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1156   ft_selftrained   different      Adam     64                3      10   \n",
       "99     w2v_pretrained       equal      Adam     64                3      10   \n",
       "965   w2v_selftrained       equal      Adam     64                3      10   \n",
       "187    w2v_pretrained   different      Adam     64                3      10   \n",
       "964   w2v_selftrained       equal      Adam     64                3      10   \n",
       "211    w2v_pretrained       equal      Adam     64                3      10   \n",
       "302    w2v_pretrained       equal      Adam     64                3      10   \n",
       "180    w2v_pretrained   different      Adam     64                3      10   \n",
       "247    w2v_pretrained       equal      Adam     64                2      10   \n",
       "941   w2v_selftrained   different      Adam     64                3      10   \n",
       "940   w2v_selftrained   different      Adam     64                3      10   \n",
       "208    w2v_pretrained       equal      Adam     64                3      10   \n",
       "209    w2v_pretrained       equal      Adam     64                3      10   \n",
       "1265   ft_selftrained   different      Adam     64                3      10   \n",
       "207    w2v_pretrained       equal      Adam     64                3      10   \n",
       "100    w2v_pretrained       equal      Adam     64                3      10   \n",
       "855   w2v_selftrained       equal      Adam     64                3      10   \n",
       "113    w2v_pretrained   different      Adam     64                2      10   \n",
       "317    w2v_pretrained       equal      Adam     64                3      10   \n",
       "77     w2v_pretrained   different      Adam     64                3      10   \n",
       "1144   ft_selftrained   different      Adam     64                3      10   \n",
       "1154   ft_selftrained   different      Adam     64                3      10   \n",
       "182    w2v_pretrained   different      Adam     64                3      10   \n",
       "832   w2v_selftrained   different      Adam     64                3      10   \n",
       "1102   ft_selftrained   different      Adam     64                2      10   \n",
       "130    w2v_pretrained   different      Adam     64                2      10   \n",
       "174    w2v_pretrained   different      Adam     64                3      10   \n",
       "833   w2v_selftrained   different      Adam     64                3      10   \n",
       "292    w2v_pretrained   different      Adam     64                3      10   \n",
       "987    ft_selftrained   different      Adam     64                2      10   \n",
       "512     ft_pretrained   different      Adam     64                3      10   \n",
       "43     w2v_pretrained       equal      Adam     64                2      10   \n",
       "1224   ft_selftrained       equal      Adam     64                2      10   \n",
       "939   w2v_selftrained   different      Adam     64                3      10   \n",
       "1157   ft_selftrained   different      Adam     64                3      10   \n",
       "511     ft_pretrained   different      Adam     64                3      10   \n",
       "344     ft_pretrained   different      Adam     64                2      10   \n",
       "428     ft_pretrained       equal      Adam     64                3      10   \n",
       "459     ft_pretrained       equal      Adam     64                2      10   \n",
       "1263   ft_selftrained   different      Adam     64                3      10   \n",
       "377     ft_pretrained       equal      Adam     64                2      10   \n",
       "11     w2v_pretrained   different      Adam     64                2      10   \n",
       "404     ft_pretrained   different      Adam     64                3      10   \n",
       "76     w2v_pretrained   different      Adam     64                3      10   \n",
       "375     ft_pretrained       equal      Adam     64                2      10   \n",
       "353     ft_pretrained       equal      Adam     64                2      10   \n",
       "405     ft_pretrained       equal      Adam     64                3      10   \n",
       "351     ft_pretrained       equal      Adam     64                2      10   \n",
       "456     ft_pretrained   different      Adam     64                2      10   \n",
       "596     ft_pretrained   different      Adam     64                3      10   \n",
       "514     ft_pretrained       equal      Adam     64                3      10   \n",
       "488     ft_pretrained   different      Adam     64                3      10   \n",
       "647     ft_pretrained       equal      Adam     64                3      10   \n",
       "568     ft_pretrained       equal      Adam     64                2      10   \n",
       "565     ft_pretrained   different      Adam     64                2      10   \n",
       "450     ft_pretrained   different      Adam     64                2      10   \n",
       "487     ft_pretrained   different      Adam     64                3      10   \n",
       "587     ft_pretrained       equal      Adam     64                2      10   \n",
       "407     ft_pretrained       equal      Adam     64                3      10   \n",
       "461     ft_pretrained       equal      Adam     64                2      10   \n",
       "621     ft_pretrained       equal      Adam     64                3      10   \n",
       "341     ft_pretrained   different      Adam     64                2      10   \n",
       "380     ft_pretrained   different      Adam     64                3      10   \n",
       "794   w2v_selftrained       equal      Adam     64                2      10   \n",
       "389     ft_pretrained   different      Adam     64                3      10   \n",
       "349     ft_pretrained   different      Adam     64                2      10   \n",
       "713   w2v_selftrained   different      Adam     64                3      10   \n",
       "433     ft_pretrained   different      Adam     64                2      10   \n",
       "406     ft_pretrained       equal      Adam     64                3      10   \n",
       "460     ft_pretrained       equal      Adam     64                2      10   \n",
       "595     ft_pretrained   different      Adam     64                3      10   \n",
       "431     ft_pretrained       equal      Adam     64                3      10   \n",
       "485     ft_pretrained       equal      Adam     64                2      10   \n",
       "646     ft_pretrained       equal      Adam     64                3      10   \n",
       "541     ft_pretrained   different      Adam     64                2      10   \n",
       "622     ft_pretrained       equal      Adam     64                3      10   \n",
       "352     ft_pretrained       equal      Adam     64                2      10   \n",
       "373     ft_pretrained       equal      Adam     64                2      10   \n",
       "402     ft_pretrained   different      Adam     64                3      10   \n",
       "569     ft_pretrained       equal      Adam     64                2      10   \n",
       "457     ft_pretrained   different      Adam     64                2      10   \n",
       "594     ft_pretrained   different      Adam     64                3      10   \n",
       "423     ft_pretrained       equal      Adam     64                3      10   \n",
       "372     ft_pretrained       equal      Adam     64                2      10   \n",
       "397     ft_pretrained   different      Adam     64                3      10   \n",
       "567     ft_pretrained       equal      Adam     64                2      10   \n",
       "425     ft_pretrained       equal      Adam     64                3      10   \n",
       "348     ft_pretrained   different      Adam     64                2      10   \n",
       "346     ft_pretrained   different      Adam     64                2      10   \n",
       "1139   ft_selftrained   different      Adam     64                3      10   \n",
       "374     ft_pretrained       equal      Adam     64                2      10   \n",
       "370     ft_pretrained       equal      Adam     64                2      10   \n",
       "429     ft_pretrained       equal      Adam     64                3      10   \n",
       "426     ft_pretrained       equal      Adam     64                3      10   \n",
       "934   w2v_selftrained   different      Adam     64                3      10   \n",
       "369     ft_pretrained       equal      Adam     64                2      10   \n",
       "623     ft_pretrained       equal      Adam     64                3      10   \n",
       "540     ft_pretrained   different      Adam     64                2      10   \n",
       "343     ft_pretrained   different      Adam     64                2      10   \n",
       "376     ft_pretrained       equal      Adam     64                2      10   \n",
       "398     ft_pretrained   different      Adam     64                3      10   \n",
       "434     ft_pretrained   different      Adam     64                2      10   \n",
       "515     ft_pretrained       equal      Adam     64                3      10   \n",
       "586     ft_pretrained       equal      Adam     64                2      10   \n",
       "345     ft_pretrained   different      Adam     64                2      10   \n",
       "479     ft_pretrained       equal      Adam     64                2      10   \n",
       "458     ft_pretrained   different      Adam     64                2      10   \n",
       "539     ft_pretrained       equal      Adam     64                3      10   \n",
       "642     ft_pretrained       equal      Adam     64                3      10   \n",
       "543     ft_pretrained   different      Adam     64                2      10   \n",
       "326     ft_pretrained   different      Adam     64                2      10   \n",
       "538     ft_pretrained       equal      Adam     64                3      10   \n",
       "371     ft_pretrained       equal      Adam     64                2      10   \n",
       "564     ft_pretrained   different      Adam     64                2      10   \n",
       "480     ft_pretrained       equal      Adam     64                2      10   \n",
       "793   w2v_selftrained       equal      Adam     64                2      10   \n",
       "592     ft_pretrained       equal      Adam     64                2      10   \n",
       "482     ft_pretrained       equal      Adam     64                2      10   \n",
       "566     ft_pretrained   different      Adam     64                2      10   \n",
       "484     ft_pretrained       equal      Adam     64                2      10   \n",
       "408     ft_pretrained       equal      Adam     64                3      10   \n",
       "424     ft_pretrained       equal      Adam     64                3      10   \n",
       "350     ft_pretrained   different      Adam     64                2      10   \n",
       "481     ft_pretrained       equal      Adam     64                2      10   \n",
       "542     ft_pretrained   different      Adam     64                2      10   \n",
       "617     ft_pretrained   different      Adam     64                3      10   \n",
       "618     ft_pretrained   different      Adam     64                3      10   \n",
       "624     ft_pretrained       equal      Adam     64                3      10   \n",
       "591     ft_pretrained       equal      Adam     64                2      10   \n",
       "612     ft_pretrained   different      Adam     64                3      10   \n",
       "342     ft_pretrained   different      Adam     64                2      10   \n",
       "427     ft_pretrained       equal      Adam     64                3      10   \n",
       "437     ft_pretrained   different      Adam     64                2      10   \n",
       "613     ft_pretrained   different      Adam     64                3      10   \n",
       "531     ft_pretrained       equal      Adam     64                3      10   \n",
       "513     ft_pretrained       equal      Adam     64                3      10   \n",
       "478     ft_pretrained       equal      Adam     64                2      10   \n",
       "533     ft_pretrained       equal      Adam     64                3      10   \n",
       "593     ft_pretrained       equal      Adam     64                2      10   \n",
       "537     ft_pretrained       equal      Adam     64                3      10   \n",
       "396     ft_pretrained   different      Adam     64                3      10   \n",
       "534     ft_pretrained       equal      Adam     64                3      10   \n",
       "477     ft_pretrained       equal      Adam     64                2      10   \n",
       "614     ft_pretrained   different      Adam     64                3      10   \n",
       "984    ft_selftrained   different      Adam     64                2      10   \n",
       "560     ft_pretrained   different      Adam     64                2      10   \n",
       "403     ft_pretrained   different      Adam     64                3      10   \n",
       "462     ft_pretrained       equal      Adam     64                2      10   \n",
       "504     ft_pretrained   different      Adam     64                3      10   \n",
       "619     ft_pretrained   different      Adam     64                3      10   \n",
       "451     ft_pretrained   different      Adam     64                2      10   \n",
       "620     ft_pretrained   different      Adam     64                3      10   \n",
       "432     ft_pretrained   different      Adam     64                2      10   \n",
       "464     ft_pretrained       equal      Adam     64                2      10   \n",
       "536     ft_pretrained       equal      Adam     64                3      10   \n",
       "559     ft_pretrained   different      Adam     64                2      10   \n",
       "510     ft_pretrained   different      Adam     64                3      10   \n",
       "430     ft_pretrained       equal      Adam     64                3      10   \n",
       "561     ft_pretrained   different      Adam     64                2      10   \n",
       "599     ft_pretrained   different      Adam     64                3      10   \n",
       "588     ft_pretrained       equal      Adam     64                2      10   \n",
       "452     ft_pretrained   different      Adam     64                2      10   \n",
       "645     ft_pretrained       equal      Adam     64                3      10   \n",
       "589     ft_pretrained       equal      Adam     64                2      10   \n",
       "354     ft_pretrained       equal      Adam     64                2      10   \n",
       "185    w2v_pretrained   different      Adam     64                3      10   \n",
       "483     ft_pretrained       equal      Adam     64                2      10   \n",
       "639     ft_pretrained       equal      Adam     64                3      10   \n",
       "489     ft_pretrained   different      Adam     64                3      10   \n",
       "516     ft_pretrained       equal      Adam     64                3      10   \n",
       "1177   ft_selftrained       equal      Adam     64                3      10   \n",
       "558     ft_pretrained   different      Adam     64                2      10   \n",
       "644     ft_pretrained       equal      Adam     64                3      10   \n",
       "506     ft_pretrained   different      Adam     64                3      10   \n",
       "325     ft_pretrained   different      Adam     64                2      10   \n",
       "616     ft_pretrained   different      Adam     64                3      10   \n",
       "327     ft_pretrained   different      Adam     64                2      10   \n",
       "490     ft_pretrained   different      Adam     64                3      10   \n",
       "640     ft_pretrained       equal      Adam     64                3      10   \n",
       "356     ft_pretrained       equal      Adam     64                2      10   \n",
       "532     ft_pretrained       equal      Adam     64                3      10   \n",
       "505     ft_pretrained   different      Adam     64                3      10   \n",
       "641     ft_pretrained       equal      Adam     64                3      10   \n",
       "453     ft_pretrained   different      Adam     64                2      10   \n",
       "585     ft_pretrained       equal      Adam     64                2      10   \n",
       "455     ft_pretrained   different      Adam     64                2      10   \n",
       "347     ft_pretrained   different      Adam     64                2      10   \n",
       "486     ft_pretrained   different      Adam     64                3      10   \n",
       "355     ft_pretrained       equal      Adam     64                2      10   \n",
       "626     ft_pretrained       equal      Adam     64                3      10   \n",
       "454     ft_pretrained   different      Adam     64                2      10   \n",
       "535     ft_pretrained       equal      Adam     64                3      10   \n",
       "590     ft_pretrained       equal      Adam     64                2      10   \n",
       "625     ft_pretrained       equal      Adam     64                3      10   \n",
       "615     ft_pretrained   different      Adam     64                3      10   \n",
       "562     ft_pretrained   different      Adam     64                2      10   \n",
       "570     ft_pretrained       equal      Adam     64                2      10   \n",
       "643     ft_pretrained       equal      Adam     64                3      10   \n",
       "184    w2v_pretrained   different      Adam     64                3      10   \n",
       "463     ft_pretrained       equal      Adam     64                2      10   \n",
       "571     ft_pretrained       equal      Adam     64                2      10   \n",
       "820   w2v_selftrained   different      Adam     64                3      10   \n",
       "340     ft_pretrained   different      Adam     64                2      10   \n",
       "409     ft_pretrained       equal      Adam     64                3      10   \n",
       "507     ft_pretrained   different      Adam     64                3      10   \n",
       "563     ft_pretrained   different      Adam     64                2      10   \n",
       "382     ft_pretrained   different      Adam     64                3      10   \n",
       "572     ft_pretrained       equal      Adam     64                2      10   \n",
       "401     ft_pretrained   different      Adam     64                3      10   \n",
       "509     ft_pretrained   different      Adam     64                3      10   \n",
       "508     ft_pretrained   different      Adam     64                3      10   \n",
       "935   w2v_selftrained   different      Adam     64                3      10   \n",
       "1259   ft_selftrained   different      Adam     64                3      10   \n",
       "399     ft_pretrained   different      Adam     64                3      10   \n",
       "544     ft_pretrained   different      Adam     64                2      10   \n",
       "502     ft_pretrained   different      Adam     64                3      10   \n",
       "1251   ft_selftrained   different      Adam     64                3      10   \n",
       "284    w2v_pretrained   different      Adam     64                3      10   \n",
       "739   w2v_selftrained       equal      Adam     64                3      10   \n",
       "518     ft_pretrained       equal      Adam     64                3      10   \n",
       "491     ft_pretrained   different      Adam     64                3      10   \n",
       "603     ft_pretrained   different      Adam     64                3      10   \n",
       "152    w2v_pretrained       equal      Adam     64                2      10   \n",
       "410     ft_pretrained       equal      Adam     64                3      10   \n",
       "1151   ft_selftrained   different      Adam     64                3      10   \n",
       "400     ft_pretrained   different      Adam     64                3      10   \n",
       "381     ft_pretrained   different      Adam     64                3      10   \n",
       "333     ft_pretrained   different      Adam     64                2      10   \n",
       "1010   ft_selftrained       equal      Adam     64                2      10   \n",
       "1285   ft_selftrained       equal      Adam     64                3      10   \n",
       "314    w2v_pretrained       equal      Adam     64                3      10   \n",
       "907   w2v_selftrained       equal      Adam     64                2      10   \n",
       "902   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1117   ft_selftrained       equal      Adam     64                2      10   \n",
       "545     ft_pretrained   different      Adam     64                2      10   \n",
       "989    ft_selftrained   different      Adam     64                2      10   \n",
       "906   w2v_selftrained       equal      Adam     64                2      10   \n",
       "517     ft_pretrained       equal      Adam     64                3      10   \n",
       "799   w2v_selftrained       equal      Adam     64                2      10   \n",
       "767   w2v_selftrained   different      Adam     64                2      10   \n",
       "339     ft_pretrained   different      Adam     64                2      10   \n",
       "145    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1149   ft_selftrained   different      Adam     64                3      10   \n",
       "792   w2v_selftrained       equal      Adam     64                2      10   \n",
       "770   w2v_selftrained   different      Adam     64                2      10   \n",
       "1035   ft_selftrained   different      Adam     64                3      10   \n",
       "1143   ft_selftrained   different      Adam     64                3      10   \n",
       "798   w2v_selftrained       equal      Adam     64                2      10   \n",
       "117    w2v_pretrained   different      Adam     64                2      10   \n",
       "1200   ft_selftrained   different      Adam     64                2      10   \n",
       "908   w2v_selftrained       equal      Adam     64                2      10   \n",
       "904   w2v_selftrained       equal      Adam     64                2      10   \n",
       "1123   ft_selftrained       equal      Adam     64                2      10   \n",
       "253    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1119   ft_selftrained       equal      Adam     64                2      10   \n",
       "12     w2v_pretrained   different      Adam     64                2      10   \n",
       "660   w2v_selftrained   different      Adam     64                2      10   \n",
       "556     ft_pretrained   different      Adam     64                2      10   \n",
       "932   w2v_selftrained   different      Adam     64                3      10   \n",
       "1095   ft_selftrained   different      Adam     64                2      10   \n",
       "259    w2v_pretrained       equal      Adam     64                2      10   \n",
       "769   w2v_selftrained   different      Adam     64                2      10   \n",
       "1041   ft_selftrained   different      Adam     64                3      10   \n",
       "1252   ft_selftrained   different      Adam     64                3      10   \n",
       "122    w2v_pretrained   different      Adam     64                2      10   \n",
       "1036   ft_selftrained   different      Adam     64                3      10   \n",
       "854   w2v_selftrained       equal      Adam     64                3      10   \n",
       "119    w2v_pretrained   different      Adam     64                2      10   \n",
       "283    w2v_pretrained   different      Adam     64                3      10   \n",
       "1091   ft_selftrained   different      Adam     64                2      10   \n",
       "1121   ft_selftrained       equal      Adam     64                2      10   \n",
       "1255   ft_selftrained   different      Adam     64                3      10   \n",
       "198    w2v_pretrained       equal      Adam     64                3      10   \n",
       "176    w2v_pretrained   different      Adam     64                3      10   \n",
       "1012   ft_selftrained       equal      Adam     64                2      10   \n",
       "928   w2v_selftrained   different      Adam     64                3      10   \n",
       "847   w2v_selftrained       equal      Adam     64                3      10   \n",
       "958   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1097   ft_selftrained   different      Adam     64                2      10   \n",
       "285    w2v_pretrained   different      Adam     64                3      10   \n",
       "470     ft_pretrained       equal      Adam     64                2      10   \n",
       "1258   ft_selftrained   different      Adam     64                3      10   \n",
       "931   w2v_selftrained   different      Adam     64                3      10   \n",
       "230    w2v_pretrained   different      Adam     64                2      10   \n",
       "280    w2v_pretrained   different      Adam     64                3      10   \n",
       "738   w2v_selftrained       equal      Adam     64                3      10   \n",
       "1089   ft_selftrained   different      Adam     64                2      10   \n",
       "205    w2v_pretrained       equal      Adam     64                3      10   \n",
       "147    w2v_pretrained       equal      Adam     64                2      10   \n",
       "1178   ft_selftrained       equal      Adam     64                3      10   \n",
       "206    w2v_pretrained       equal      Adam     64                3      10   \n",
       "1232   ft_selftrained       equal      Adam     64                2      10   \n",
       "1228   ft_selftrained       equal      Adam     64                2      10   \n",
       "1229   ft_selftrained       equal      Adam     64                2      10   \n",
       "1230   ft_selftrained       equal      Adam     64                2      10   \n",
       "1231   ft_selftrained       equal      Adam     64                2      10   \n",
       "1034   ft_selftrained   different      Adam     64                3      10   \n",
       "97     w2v_pretrained       equal      Adam     64                3      10   \n",
       "287    w2v_pretrained   different      Adam     64                3      10   \n",
       "286    w2v_pretrained   different      Adam     64                3      10   \n",
       "98     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1250   ft_selftrained   different      Adam     64                3      10   \n",
       "1096   ft_selftrained   different      Adam     64                2      10   \n",
       "1227   ft_selftrained       equal      Adam     64                2      10   \n",
       "313    w2v_pretrained       equal      Adam     64                3      10   \n",
       "1254   ft_selftrained   different      Adam     64                3      10   \n",
       "1225   ft_selftrained       equal      Adam     64                2      10   \n",
       "35     w2v_pretrained       equal      Adam     64                2      10   \n",
       "34     w2v_pretrained       equal      Adam     64                2      10   \n",
       "33     w2v_pretrained       equal      Adam     64                2      10   \n",
       "93     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1223   ft_selftrained       equal      Adam     64                2      10   \n",
       "120    w2v_pretrained   different      Adam     64                2      10   \n",
       "121    w2v_pretrained   different      Adam     64                2      10   \n",
       "96     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1226   ft_selftrained       equal      Adam     64                2      10   \n",
       "1042   ft_selftrained   different      Adam     64                3      10   \n",
       "94     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1039   ft_selftrained   different      Adam     64                3      10   \n",
       "95     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1038   ft_selftrained   different      Adam     64                3      10   \n",
       "1253   ft_selftrained   different      Adam     64                3      10   \n",
       "308    w2v_pretrained       equal      Adam     64                3      10   \n",
       "37     w2v_pretrained       equal      Adam     64                2      10   \n",
       "1283   ft_selftrained       equal      Adam     64                3      10   \n",
       "1277   ft_selftrained       equal      Adam     64                3      10   \n",
       "1278   ft_selftrained       equal      Adam     64                3      10   \n",
       "1279   ft_selftrained       equal      Adam     64                3      10   \n",
       "1280   ft_selftrained       equal      Adam     64                3      10   \n",
       "1281   ft_selftrained       equal      Adam     64                3      10   \n",
       "1282   ft_selftrained       equal      Adam     64                3      10   \n",
       "324     ft_pretrained   different      Adam     64                2      10   \n",
       "1033   ft_selftrained   different      Adam     64                3      10   \n",
       "1284   ft_selftrained       equal      Adam     64                3      10   \n",
       "1286   ft_selftrained       equal      Adam     64                3      10   \n",
       "1016   ft_selftrained       equal      Adam     64                2      10   \n",
       "1015   ft_selftrained       equal      Adam     64                2      10   \n",
       "1092   ft_selftrained   different      Adam     64                2      10   \n",
       "1014   ft_selftrained       equal      Adam     64                2      10   \n",
       "1276   ft_selftrained       equal      Adam     64                3      10   \n",
       "6      w2v_pretrained   different      Adam     64                2      10   \n",
       "7      w2v_pretrained   different      Adam     64                2      10   \n",
       "8      w2v_pretrained   different      Adam     64                2      10   \n",
       "9      w2v_pretrained   different      Adam     64                2      10   \n",
       "1093   ft_selftrained   different      Adam     64                2      10   \n",
       "1027   ft_selftrained   different      Adam     64                3      10   \n",
       "13     w2v_pretrained   different      Adam     64                2      10   \n",
       "125    w2v_pretrained   different      Adam     64                2      10   \n",
       "14     w2v_pretrained   different      Adam     64                2      10   \n",
       "124    w2v_pretrained   different      Adam     64                2      10   \n",
       "123    w2v_pretrained   different      Adam     64                2      10   \n",
       "1094   ft_selftrained   different      Adam     64                2      10   \n",
       "1031   ft_selftrained   different      Adam     64                3      10   \n",
       "1257   ft_selftrained   different      Adam     64                3      10   \n",
       "1256   ft_selftrained   different      Adam     64                3      10   \n",
       "1032   ft_selftrained   different      Adam     64                3      10   \n",
       "36     w2v_pretrained       equal      Adam     64                2      10   \n",
       "38     w2v_pretrained       equal      Adam     64                2      10   \n",
       "307    w2v_pretrained       equal      Adam     64                3      10   \n",
       "309    w2v_pretrained       equal      Adam     64                3      10   \n",
       "67     w2v_pretrained   different      Adam     64                3      10   \n",
       "1069   ft_selftrained       equal      Adam     64                3      10   \n",
       "1068   ft_selftrained       equal      Adam     64                3      10   \n",
       "1067   ft_selftrained       equal      Adam     64                3      10   \n",
       "1116   ft_selftrained       equal      Adam     64                2      10   \n",
       "1066   ft_selftrained       equal      Adam     64                3      10   \n",
       "1065   ft_selftrained       equal      Adam     64                3      10   \n",
       "64     w2v_pretrained   different      Adam     64                3      10   \n",
       "1064   ft_selftrained       equal      Adam     64                3      10   \n",
       "1063   ft_selftrained       equal      Adam     64                3      10   \n",
       "66     w2v_pretrained   different      Adam     64                3      10   \n",
       "1062   ft_selftrained       equal      Adam     64                3      10   \n",
       "310    w2v_pretrained       equal      Adam     64                3      10   \n",
       "1061   ft_selftrained       equal      Adam     64                3      10   \n",
       "68     w2v_pretrained   different      Adam     64                3      10   \n",
       "1118   ft_selftrained       equal      Adam     64                2      10   \n",
       "70     w2v_pretrained   different      Adam     64                3      10   \n",
       "1013   ft_selftrained       equal      Adam     64                2      10   \n",
       "1147   ft_selftrained   different      Adam     64                3      10   \n",
       "1146   ft_selftrained   different      Adam     64                3      10   \n",
       "1120   ft_selftrained       equal      Adam     64                2      10   \n",
       "71     w2v_pretrained   different      Adam     64                3      10   \n",
       "1122   ft_selftrained       equal      Adam     64                2      10   \n",
       "1138   ft_selftrained   different      Adam     64                3      10   \n",
       "1070   ft_selftrained       equal      Adam     64                3      10   \n",
       "1137   ft_selftrained   different      Adam     64                3      10   \n",
       "1124   ft_selftrained       equal      Adam     64                2      10   \n",
       "303    w2v_pretrained       equal      Adam     64                3      10   \n",
       "304    w2v_pretrained       equal      Adam     64                3      10   \n",
       "305    w2v_pretrained       equal      Adam     64                3      10   \n",
       "306    w2v_pretrained       equal      Adam     64                3      10   \n",
       "65     w2v_pretrained   different      Adam     64                3      10   \n",
       "311    w2v_pretrained       equal      Adam     64                3      10   \n",
       "39     w2v_pretrained       equal      Adam     64                2      10   \n",
       "1203   ft_selftrained   different      Adam     64                2      10   \n",
       "89     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1201   ft_selftrained   different      Adam     64                2      10   \n",
       "90     w2v_pretrained       equal      Adam     64                3      10   \n",
       "91     w2v_pretrained       equal      Adam     64                3      10   \n",
       "312    w2v_pretrained       equal      Adam     64                3      10   \n",
       "118    w2v_pretrained   different      Adam     64                2      10   \n",
       "1204   ft_selftrained   different      Adam     64                2      10   \n",
       "62     w2v_pretrained   different      Adam     64                3      10   \n",
       "1205   ft_selftrained   different      Adam     64                2      10   \n",
       "44     w2v_pretrained       equal      Adam     64                2      10   \n",
       "42     w2v_pretrained       equal      Adam     64                2      10   \n",
       "92     w2v_pretrained       equal      Adam     64                3      10   \n",
       "41     w2v_pretrained       equal      Adam     64                2      10   \n",
       "40     w2v_pretrained       equal      Adam     64                2      10   \n",
       "88     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1199   ft_selftrained   different      Adam     64                2      10   \n",
       "1198   ft_selftrained   different      Adam     64                2      10   \n",
       "1196   ft_selftrained   different      Adam     64                2      10   \n",
       "58     w2v_pretrained   different      Adam     64                3      10   \n",
       "1090   ft_selftrained   different      Adam     64                2      10   \n",
       "1175   ft_selftrained       equal      Adam     64                3      10   \n",
       "1174   ft_selftrained       equal      Adam     64                3      10   \n",
       "1173   ft_selftrained       equal      Adam     64                3      10   \n",
       "1172   ft_selftrained       equal      Adam     64                3      10   \n",
       "1170   ft_selftrained       equal      Adam     64                3      10   \n",
       "1059   ft_selftrained       equal      Adam     64                3      10   \n",
       "59     w2v_pretrained   different      Adam     64                3      10   \n",
       "1060   ft_selftrained       equal      Adam     64                3      10   \n",
       "60     w2v_pretrained   different      Adam     64                3      10   \n",
       "61     w2v_pretrained   different      Adam     64                3      10   \n",
       "87     w2v_pretrained       equal      Adam     64                3      10   \n",
       "1176   ft_selftrained       equal      Adam     64                3      10   \n",
       "281    w2v_pretrained   different      Adam     64                3      10   \n",
       "1011   ft_selftrained       equal      Adam     64                2      10   \n",
       "584     ft_pretrained       equal      Adam     64                2      10   \n",
       "578     ft_pretrained       equal      Adam     64                2      10   \n",
       "579     ft_pretrained       equal      Adam     64                2      10   \n",
       "580     ft_pretrained       equal      Adam     64                2      10   \n",
       "581     ft_pretrained       equal      Adam     64                2      10   \n",
       "582     ft_pretrained       equal      Adam     64                2      10   \n",
       "583     ft_pretrained       equal      Adam     64                2      10   \n",
       "597     ft_pretrained   different      Adam     64                3      10   \n",
       "576     ft_pretrained       equal      Adam     64                2      10   \n",
       "598     ft_pretrained   different      Adam     64                3      10   \n",
       "600     ft_pretrained   different      Adam     64                3      10   \n",
       "601     ft_pretrained   different      Adam     64                3      10   \n",
       "602     ft_pretrained   different      Adam     64                3      10   \n",
       "604     ft_pretrained   different      Adam     64                3      10   \n",
       "605     ft_pretrained   different      Adam     64                3      10   \n",
       "577     ft_pretrained       equal      Adam     64                2      10   \n",
       "575     ft_pretrained       equal      Adam     64                2      10   \n",
       "688   w2v_selftrained       equal      Adam     64                2      10   \n",
       "550     ft_pretrained   different      Adam     64                2      10   \n",
       "529     ft_pretrained       equal      Adam     64                3      10   \n",
       "530     ft_pretrained       equal      Adam     64                3      10   \n",
       "546     ft_pretrained   different      Adam     64                2      10   \n",
       "547     ft_pretrained   different      Adam     64                2      10   \n",
       "548     ft_pretrained   different      Adam     64                2      10   \n",
       "549     ft_pretrained   different      Adam     64                2      10   \n",
       "551     ft_pretrained   different      Adam     64                2      10   \n",
       "574     ft_pretrained       equal      Adam     64                2      10   \n",
       "552     ft_pretrained   different      Adam     64                2      10   \n",
       "553     ft_pretrained   different      Adam     64                2      10   \n",
       "554     ft_pretrained   different      Adam     64                2      10   \n",
       "555     ft_pretrained   different      Adam     64                2      10   \n",
       "557     ft_pretrained   different      Adam     64                2      10   \n",
       "573     ft_pretrained       equal      Adam     64                2      10   \n",
       "606     ft_pretrained   different      Adam     64                3      10   \n",
       "607     ft_pretrained   different      Adam     64                3      10   \n",
       "608     ft_pretrained   different      Adam     64                3      10   \n",
       "378     ft_pretrained   different      Adam     64                3      10   \n",
       "656   w2v_selftrained   different      Adam     64                2      10   \n",
       "657   w2v_selftrained   different      Adam     64                2      10   \n",
       "658   w2v_selftrained   different      Adam     64                2      10   \n",
       "661   w2v_selftrained   different      Adam     64                2      10   \n",
       "662   w2v_selftrained   different      Adam     64                2      10   \n",
       "379     ft_pretrained   different      Adam     64                3      10   \n",
       "260    w2v_pretrained       equal      Adam     64                2      10   \n",
       "609     ft_pretrained   different      Adam     64                3      10   \n",
       "258    w2v_pretrained       equal      Adam     64                2      10   \n",
       "681   w2v_selftrained       equal      Adam     64                2      10   \n",
       "682   w2v_selftrained       equal      Adam     64                2      10   \n",
       "683   w2v_selftrained       equal      Adam     64                2      10   \n",
       "684   w2v_selftrained       equal      Adam     64                2      10   \n",
       "686   w2v_selftrained       equal      Adam     64                2      10   \n",
       "655   w2v_selftrained   different      Adam     64                2      10   \n",
       "654   w2v_selftrained   different      Adam     64                2      10   \n",
       "276    w2v_pretrained   different      Adam     64                3      10   \n",
       "277    w2v_pretrained   different      Adam     64                3      10   \n",
       "638     ft_pretrained       equal      Adam     64                3      10   \n",
       "637     ft_pretrained       equal      Adam     64                3      10   \n",
       "635     ft_pretrained       equal      Adam     64                3      10   \n",
       "634     ft_pretrained       equal      Adam     64                3      10   \n",
       "633     ft_pretrained       equal      Adam     64                3      10   \n",
       "632     ft_pretrained       equal      Adam     64                3      10   \n",
       "631     ft_pretrained       equal      Adam     64                3      10   \n",
       "630     ft_pretrained       equal      Adam     64                3      10   \n",
       "629     ft_pretrained       equal      Adam     64                3      10   \n",
       "628     ft_pretrained       equal      Adam     64                3      10   \n",
       "627     ft_pretrained       equal      Adam     64                3      10   \n",
       "611     ft_pretrained   different      Adam     64                3      10   \n",
       "610     ft_pretrained   different      Adam     64                3      10   \n",
       "528     ft_pretrained       equal      Adam     64                3      10   \n",
       "527     ft_pretrained       equal      Adam     64                3      10   \n",
       "526     ft_pretrained       equal      Adam     64                3      10   \n",
       "422     ft_pretrained       equal      Adam     64                3      10   \n",
       "416     ft_pretrained       equal      Adam     64                3      10   \n",
       "417     ft_pretrained       equal      Adam     64                3      10   \n",
       "418     ft_pretrained       equal      Adam     64                3      10   \n",
       "419     ft_pretrained       equal      Adam     64                3      10   \n",
       "420     ft_pretrained       equal      Adam     64                3      10   \n",
       "421     ft_pretrained       equal      Adam     64                3      10   \n",
       "435     ft_pretrained   different      Adam     64                2      10   \n",
       "444     ft_pretrained   different      Adam     64                2      10   \n",
       "436     ft_pretrained   different      Adam     64                2      10   \n",
       "438     ft_pretrained   different      Adam     64                2      10   \n",
       "439     ft_pretrained   different      Adam     64                2      10   \n",
       "440     ft_pretrained   different      Adam     64                2      10   \n",
       "441     ft_pretrained   different      Adam     64                2      10   \n",
       "442     ft_pretrained   different      Adam     64                2      10   \n",
       "415     ft_pretrained       equal      Adam     64                3      10   \n",
       "414     ft_pretrained       equal      Adam     64                3      10   \n",
       "413     ft_pretrained       equal      Adam     64                3      10   \n",
       "412     ft_pretrained       equal      Adam     64                3      10   \n",
       "411     ft_pretrained       equal      Adam     64                3      10   \n",
       "395     ft_pretrained   different      Adam     64                3      10   \n",
       "394     ft_pretrained   different      Adam     64                3      10   \n",
       "393     ft_pretrained   different      Adam     64                3      10   \n",
       "392     ft_pretrained   different      Adam     64                3      10   \n",
       "391     ft_pretrained   different      Adam     64                3      10   \n",
       "390     ft_pretrained   different      Adam     64                3      10   \n",
       "388     ft_pretrained   different      Adam     64                3      10   \n",
       "387     ft_pretrained   different      Adam     64                3      10   \n",
       "386     ft_pretrained   different      Adam     64                3      10   \n",
       "385     ft_pretrained   different      Adam     64                3      10   \n",
       "384     ft_pretrained   different      Adam     64                3      10   \n",
       "383     ft_pretrained   different      Adam     64                3      10   \n",
       "443     ft_pretrained   different      Adam     64                2      10   \n",
       "445     ft_pretrained   different      Adam     64                2      10   \n",
       "525     ft_pretrained       equal      Adam     64                3      10   \n",
       "501     ft_pretrained   different      Adam     64                3      10   \n",
       "495     ft_pretrained   different      Adam     64                3      10   \n",
       "496     ft_pretrained   different      Adam     64                3      10   \n",
       "497     ft_pretrained   different      Adam     64                3      10   \n",
       "498     ft_pretrained   different      Adam     64                3      10   \n",
       "499     ft_pretrained   different      Adam     64                3      10   \n",
       "500     ft_pretrained   different      Adam     64                3      10   \n",
       "503     ft_pretrained   different      Adam     64                3      10   \n",
       "446     ft_pretrained   different      Adam     64                2      10   \n",
       "519     ft_pretrained       equal      Adam     64                3      10   \n",
       "520     ft_pretrained       equal      Adam     64                3      10   \n",
       "521     ft_pretrained       equal      Adam     64                3      10   \n",
       "522     ft_pretrained       equal      Adam     64                3      10   \n",
       "523     ft_pretrained       equal      Adam     64                3      10   \n",
       "524     ft_pretrained       equal      Adam     64                3      10   \n",
       "494     ft_pretrained   different      Adam     64                3      10   \n",
       "493     ft_pretrained   different      Adam     64                3      10   \n",
       "492     ft_pretrained   different      Adam     64                3      10   \n",
       "476     ft_pretrained       equal      Adam     64                2      10   \n",
       "475     ft_pretrained       equal      Adam     64                2      10   \n",
       "474     ft_pretrained       equal      Adam     64                2      10   \n",
       "473     ft_pretrained       equal      Adam     64                2      10   \n",
       "472     ft_pretrained       equal      Adam     64                2      10   \n",
       "471     ft_pretrained       equal      Adam     64                2      10   \n",
       "469     ft_pretrained       equal      Adam     64                2      10   \n",
       "468     ft_pretrained       equal      Adam     64                2      10   \n",
       "467     ft_pretrained       equal      Adam     64                2      10   \n",
       "466     ft_pretrained       equal      Adam     64                2      10   \n",
       "465     ft_pretrained       equal      Adam     64                2      10   \n",
       "449     ft_pretrained   different      Adam     64                2      10   \n",
       "448     ft_pretrained   different      Adam     64                2      10   \n",
       "447     ft_pretrained   different      Adam     64                2      10   \n",
       "1009   ft_selftrained       equal      Adam     64                2      10   \n",
       "687   w2v_selftrained       equal      Adam     64                2      10   \n",
       "689   w2v_selftrained       equal      Adam     64                2      10   \n",
       "171    w2v_pretrained   different      Adam     64                3      10   \n",
       "173    w2v_pretrained   different      Adam     64                3      10   \n",
       "900   w2v_selftrained       equal      Adam     64                2      10   \n",
       "901   w2v_selftrained       equal      Adam     64                2      10   \n",
       "903   w2v_selftrained       equal      Adam     64                2      10   \n",
       "905   w2v_selftrained       equal      Adam     64                2      10   \n",
       "172    w2v_pretrained   different      Adam     64                3      10   \n",
       "338     ft_pretrained   different      Adam     64                2      10   \n",
       "177    w2v_pretrained   different      Adam     64                3      10   \n",
       "923   w2v_selftrained   different      Adam     64                3      10   \n",
       "924   w2v_selftrained   different      Adam     64                3      10   \n",
       "925   w2v_selftrained   different      Adam     64                3      10   \n",
       "926   w2v_selftrained   different      Adam     64                3      10   \n",
       "337     ft_pretrained   different      Adam     64                2      10   \n",
       "929   w2v_selftrained   different      Adam     64                3      10   \n",
       "175    w2v_pretrained   different      Adam     64                3      10   \n",
       "178    w2v_pretrained   different      Adam     64                3      10   \n",
       "690   w2v_selftrained       equal      Adam     64                2      10   \n",
       "872   w2v_selftrained   different      Adam     64                2      10   \n",
       "849   w2v_selftrained       equal      Adam     64                3      10   \n",
       "850   w2v_selftrained       equal      Adam     64                3      10   \n",
       "851   w2v_selftrained       equal      Adam     64                3      10   \n",
       "852   w2v_selftrained       equal      Adam     64                3      10   \n",
       "853   w2v_selftrained       equal      Adam     64                3      10   \n",
       "870   w2v_selftrained   different      Adam     64                2      10   \n",
       "873   w2v_selftrained   different      Adam     64                2      10   \n",
       "179    w2v_pretrained   different      Adam     64                3      10   \n",
       "875   w2v_selftrained   different      Adam     64                2      10   \n",
       "876   w2v_selftrained   different      Adam     64                2      10   \n",
       "877   w2v_selftrained   different      Adam     64                2      10   \n",
       "878   w2v_selftrained   different      Adam     64                2      10   \n",
       "880   w2v_selftrained   different      Adam     64                2      10   \n",
       "881   w2v_selftrained   different      Adam     64                2      10   \n",
       "930   w2v_selftrained   different      Adam     64                3      10   \n",
       "933   w2v_selftrained   different      Adam     64                3      10   \n",
       "336     ft_pretrained   different      Adam     64                2      10   \n",
       "144    w2v_pretrained       equal      Adam     64                2      10   \n",
       "986    ft_selftrained   different      Adam     64                2      10   \n",
       "150    w2v_pretrained       equal      Adam     64                2      10   \n",
       "331     ft_pretrained   different      Adam     64                2      10   \n",
       "149    w2v_pretrained       equal      Adam     64                2      10   \n",
       "148    w2v_pretrained       equal      Adam     64                2      10   \n",
       "146    w2v_pretrained       equal      Adam     64                2      10   \n",
       "330     ft_pretrained   different      Adam     64                2      10   \n",
       "335     ft_pretrained   different      Adam     64                2      10   \n",
       "329     ft_pretrained   different      Adam     64                2      10   \n",
       "328     ft_pretrained   different      Adam     64                2      10   \n",
       "1005   ft_selftrained       equal      Adam     64                2      10   \n",
       "1006   ft_selftrained       equal      Adam     64                2      10   \n",
       "1007   ft_selftrained       equal      Adam     64                2      10   \n",
       "1008   ft_selftrained       equal      Adam     64                2      10   \n",
       "985    ft_selftrained   different      Adam     64                2      10   \n",
       "151    w2v_pretrained       equal      Adam     64                2      10   \n",
       "980    ft_selftrained   different      Adam     64                2      10   \n",
       "979    ft_selftrained   different      Adam     64                2      10   \n",
       "332     ft_pretrained   different      Adam     64                2      10   \n",
       "962   w2v_selftrained       equal      Adam     64                3      10   \n",
       "961   w2v_selftrained       equal      Adam     64                3      10   \n",
       "960   w2v_selftrained       equal      Adam     64                3      10   \n",
       "959   w2v_selftrained       equal      Adam     64                3      10   \n",
       "957   w2v_selftrained       equal      Adam     64                3      10   \n",
       "956   w2v_selftrained       equal      Adam     64                3      10   \n",
       "955   w2v_selftrained       equal      Adam     64                3      10   \n",
       "954   w2v_selftrained       equal      Adam     64                3      10   \n",
       "953   w2v_selftrained       equal      Adam     64                3      10   \n",
       "952   w2v_selftrained       equal      Adam     64                3      10   \n",
       "951   w2v_selftrained       equal      Adam     64                3      10   \n",
       "334     ft_pretrained   different      Adam     64                2      10   \n",
       "848   w2v_selftrained       equal      Adam     64                3      10   \n",
       "846   w2v_selftrained       equal      Adam     64                3      10   \n",
       "199    w2v_pretrained       equal      Adam     64                3      10   \n",
       "765   w2v_selftrained   different      Adam     64                2      10   \n",
       "200    w2v_pretrained       equal      Adam     64                3      10   \n",
       "228    w2v_pretrained   different      Adam     64                2      10   \n",
       "368     ft_pretrained       equal      Adam     64                2      10   \n",
       "229    w2v_pretrained   different      Adam     64                2      10   \n",
       "231    w2v_pretrained   different      Adam     64                2      10   \n",
       "746   w2v_selftrained       equal      Adam     64                3      10   \n",
       "745   w2v_selftrained       equal      Adam     64                3      10   \n",
       "744   w2v_selftrained       equal      Adam     64                3      10   \n",
       "743   w2v_selftrained       equal      Adam     64                3      10   \n",
       "742   w2v_selftrained       equal      Adam     64                3      10   \n",
       "741   w2v_selftrained       equal      Adam     64                3      10   \n",
       "740   w2v_selftrained       equal      Adam     64                3      10   \n",
       "737   w2v_selftrained       equal      Adam     64                3      10   \n",
       "736   w2v_selftrained       equal      Adam     64                3      10   \n",
       "735   w2v_selftrained       equal      Adam     64                3      10   \n",
       "249    w2v_pretrained       equal      Adam     64                2      10   \n",
       "717   w2v_selftrained   different      Adam     64                3      10   \n",
       "716   w2v_selftrained   different      Adam     64                3      10   \n",
       "715   w2v_selftrained   different      Adam     64                3      10   \n",
       "714   w2v_selftrained   different      Adam     64                3      10   \n",
       "710   w2v_selftrained   different      Adam     64                3      10   \n",
       "709   w2v_selftrained   different      Adam     64                3      10   \n",
       "708   w2v_selftrained   different      Adam     64                3      10   \n",
       "252    w2v_pretrained       equal      Adam     64                2      10   \n",
       "254    w2v_pretrained       equal      Adam     64                2      10   \n",
       "255    w2v_pretrained       equal      Adam     64                2      10   \n",
       "256    w2v_pretrained       equal      Adam     64                2      10   \n",
       "257    w2v_pretrained       equal      Adam     64                2      10   \n",
       "691   w2v_selftrained       equal      Adam     64                2      10   \n",
       "764   w2v_selftrained   different      Adam     64                2      10   \n",
       "227    w2v_pretrained   different      Adam     64                2      10   \n",
       "766   w2v_selftrained   different      Adam     64                2      10   \n",
       "357     ft_pretrained       equal      Adam     64                2      10   \n",
       "796   w2v_selftrained       equal      Adam     64                2      10   \n",
       "797   w2v_selftrained       equal      Adam     64                2      10   \n",
       "800   w2v_selftrained       equal      Adam     64                2      10   \n",
       "360     ft_pretrained       equal      Adam     64                2      10   \n",
       "359     ft_pretrained       equal      Adam     64                2      10   \n",
       "358     ft_pretrained       equal      Adam     64                2      10   \n",
       "204    w2v_pretrained       equal      Adam     64                3      10   \n",
       "361     ft_pretrained       equal      Adam     64                2      10   \n",
       "821   w2v_selftrained   different      Adam     64                3      10   \n",
       "823   w2v_selftrained   different      Adam     64                3      10   \n",
       "824   w2v_selftrained   different      Adam     64                3      10   \n",
       "203    w2v_pretrained       equal      Adam     64                3      10   \n",
       "827   w2v_selftrained   different      Adam     64                3      10   \n",
       "201    w2v_pretrained       equal      Adam     64                3      10   \n",
       "768   w2v_selftrained   different      Adam     64                2      10   \n",
       "795   w2v_selftrained       equal      Adam     64                2      10   \n",
       "282    w2v_pretrained   different      Adam     64                3      10   \n",
       "364     ft_pretrained       equal      Adam     64                2      10   \n",
       "226    w2v_pretrained   different      Adam     64                2      10   \n",
       "772   w2v_selftrained   different      Adam     64                2      10   \n",
       "773   w2v_selftrained   different      Adam     64                2      10   \n",
       "367     ft_pretrained       equal      Adam     64                2      10   \n",
       "366     ft_pretrained       equal      Adam     64                2      10   \n",
       "365     ft_pretrained       equal      Adam     64                2      10   \n",
       "225    w2v_pretrained   different      Adam     64                2      10   \n",
       "224    w2v_pretrained   different      Adam     64                2      10   \n",
       "363     ft_pretrained       equal      Adam     64                2      10   \n",
       "362     ft_pretrained       equal      Adam     64                2      10   \n",
       "232    w2v_pretrained   different      Adam     64                2      10   \n",
       "1171   ft_selftrained       equal      Adam     64                3      10   \n",
       "202    w2v_pretrained       equal      Adam     64                3      10   \n",
       "1148   ft_selftrained   different      Adam     64                3      10   \n",
       "636     ft_pretrained       equal      Adam     64                3      10   \n",
       "822   w2v_selftrained   different      Adam     64                3      10   \n",
       "1040   ft_selftrained   different      Adam     64                3      10   \n",
       "\n",
       "      Learning rate Activation function    Initialization Regularization  \\\n",
       "1055          0.001                relu              None           None   \n",
       "1082          0.001                relu  kaiming_uniform_           None   \n",
       "1054          0.001                relu              None           None   \n",
       "1028          0.001                relu              None           None   \n",
       "1189          0.001                relu   xavier_uniform_           None   \n",
       "1109          0.001                relu  kaiming_uniform_           None   \n",
       "1053          0.001                relu              None           None   \n",
       "999           0.001                relu              None           None   \n",
       "1271          0.001                relu   xavier_uniform_           None   \n",
       "972           0.001                relu              None           None   \n",
       "1000          0.001                relu              None           None   \n",
       "1080          0.001                relu  kaiming_uniform_           None   \n",
       "1188          0.001                relu   xavier_uniform_           None   \n",
       "1136          0.001                relu  kaiming_uniform_           None   \n",
       "1272          0.001                relu   xavier_uniform_        dropout   \n",
       "973           0.001                relu              None           None   \n",
       "1058          0.001                relu              None        dropout   \n",
       "1026          0.001                relu              None           None   \n",
       "1274          0.001                relu   xavier_uniform_        dropout   \n",
       "1002          0.001                relu              None        dropout   \n",
       "982           0.001                relu              None           None   \n",
       "1249          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1168          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1222          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1141          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1166          0.001                relu  kaiming_uniform_        dropout   \n",
       "1108          0.001                relu  kaiming_uniform_           None   \n",
       "1114          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1135          0.001                relu  kaiming_uniform_           None   \n",
       "1142          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1242          0.001                relu   xavier_uniform_           None   \n",
       "1169          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1215          0.001                relu   xavier_uniform_           None   \n",
       "1140          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "974           0.001                relu              None           None   \n",
       "1273          0.001                relu   xavier_uniform_        dropout   \n",
       "1003          0.001                relu              None        dropout   \n",
       "1084          0.001                relu  kaiming_uniform_        dropout   \n",
       "1195          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1248          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1165          0.001                relu  kaiming_uniform_        dropout   \n",
       "1190          0.001                relu   xavier_uniform_           None   \n",
       "1243          0.001                relu   xavier_uniform_           None   \n",
       "1275          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1216          0.001                relu   xavier_uniform_           None   \n",
       "1162          0.001                relu  kaiming_uniform_           None   \n",
       "1134          0.001                relu  kaiming_uniform_           None   \n",
       "1115          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1192          0.001                relu   xavier_uniform_        dropout   \n",
       "1088          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1087          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1081          0.001                relu  kaiming_uniform_           None   \n",
       "1270          0.001                relu   xavier_uniform_           None   \n",
       "1167          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1113          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1194          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1221          0.001                relu   xavier_uniform_         l2_reg   \n",
       "978           0.001                relu              None         l2_reg   \n",
       "1086          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1107          0.001                relu  kaiming_uniform_           None   \n",
       "1193          0.001                relu   xavier_uniform_        dropout   \n",
       "1247          0.001                relu   xavier_uniform_        dropout   \n",
       "676           0.001                relu              None           None   \n",
       "1246          0.001                relu   xavier_uniform_        dropout   \n",
       "1131          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1001          0.001                relu              None           None   \n",
       "1219          0.001                relu   xavier_uniform_        dropout   \n",
       "729           0.001                relu              None           None   \n",
       "976           0.001                relu              None        dropout   \n",
       "1220          0.001                relu   xavier_uniform_        dropout   \n",
       "1004          0.001                relu              None        dropout   \n",
       "1150          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1111          0.001                relu  kaiming_uniform_        dropout   \n",
       "1037          0.001                relu              None           None   \n",
       "702           0.001                relu              None           None   \n",
       "675           0.001                relu              None           None   \n",
       "1218          0.001                relu   xavier_uniform_        dropout   \n",
       "892           0.001                relu   xavier_uniform_           None   \n",
       "949           0.001                relu   xavier_uniform_        dropout   \n",
       "677           0.001                relu              None           None   \n",
       "704           0.001                relu              None           None   \n",
       "757           0.001                relu  kaiming_uniform_           None   \n",
       "1110          0.001                relu  kaiming_uniform_        dropout   \n",
       "1244          0.001                relu   xavier_uniform_           None   \n",
       "759           0.001                relu  kaiming_uniform_        dropout   \n",
       "866           0.001                relu   xavier_uniform_           None   \n",
       "871           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1056          0.001                relu              None        dropout   \n",
       "893           0.001                relu   xavier_uniform_           None   \n",
       "712           0.001                relu              None           None   \n",
       "891           0.001                relu   xavier_uniform_           None   \n",
       "790           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "811           0.001                relu  kaiming_uniform_           None   \n",
       "650           0.001                relu              None           None   \n",
       "732           0.001                relu              None        dropout   \n",
       "983           0.001                relu              None           None   \n",
       "763           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "703           0.001                relu              None           None   \n",
       "783           0.001                relu  kaiming_uniform_           None   \n",
       "1161          0.001                relu  kaiming_uniform_           None   \n",
       "653           0.001                relu              None        dropout   \n",
       "1017          0.001                relu              None           None   \n",
       "648           0.001                relu              None           None   \n",
       "898           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1239          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1030          0.001                relu              None        dropout   \n",
       "758           0.001                relu  kaiming_uniform_           None   \n",
       "649           0.001                relu              None           None   \n",
       "818           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1191          0.001                relu   xavier_uniform_        dropout   \n",
       "867           0.001                relu   xavier_uniform_        dropout   \n",
       "785           0.001                relu  kaiming_uniform_           None   \n",
       "1104          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "945           0.001                relu   xavier_uniform_           None   \n",
       "844           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1217          0.001                relu   xavier_uniform_           None   \n",
       "840           0.001                relu  kaiming_uniform_        dropout   \n",
       "996           0.001                relu              None         l2_reg   \n",
       "899           0.001                relu   xavier_uniform_         l2_reg   \n",
       "977           0.001                relu              None        dropout   \n",
       "817           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "865           0.001                relu   xavier_uniform_           None   \n",
       "1163          0.001                relu  kaiming_uniform_           None   \n",
       "752           0.001                relu              None        dropout   \n",
       "841           0.001                relu  kaiming_uniform_        dropout   \n",
       "679           0.001                relu              None        dropout   \n",
       "787           0.001                relu  kaiming_uniform_        dropout   \n",
       "1029          0.001                relu              None        dropout   \n",
       "784           0.001                relu  kaiming_uniform_           None   \n",
       "997           0.001                relu              None         l2_reg   \n",
       "762           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "843           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "680           0.001                relu              None        dropout   \n",
       "868           0.001                relu   xavier_uniform_        dropout   \n",
       "845           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "864           0.001                relu   xavier_uniform_           None   \n",
       "731           0.001                relu              None           None   \n",
       "791           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "919           0.001                relu   xavier_uniform_           None   \n",
       "920           0.001                relu   xavier_uniform_           None   \n",
       "651           0.001                relu              None        dropout   \n",
       "789           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "664           0.001                relu              None         l2_reg   \n",
       "897           0.001                relu   xavier_uniform_         l2_reg   \n",
       "810           0.001                relu  kaiming_uniform_           None   \n",
       "922           0.001                relu   xavier_uniform_        dropout   \n",
       "993           0.001                relu              None        dropout   \n",
       "786           0.001                relu  kaiming_uniform_        dropout   \n",
       "816           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "756           0.001                relu  kaiming_uniform_           None   \n",
       "652           0.001                relu              None        dropout   \n",
       "894           0.001                relu   xavier_uniform_        dropout   \n",
       "730           0.001                relu              None           None   \n",
       "1206          0.001                relu   xavier_uniform_           None   \n",
       "869           0.001                relu   xavier_uniform_        dropout   \n",
       "896           0.001                relu   xavier_uniform_        dropout   \n",
       "760           0.001                relu  kaiming_uniform_        dropout   \n",
       "719           0.001                relu              None         l2_reg   \n",
       "27            0.001                relu              None           None   \n",
       "1269          0.001                relu   xavier_uniform_           None   \n",
       "665           0.001                relu              None         l2_reg   \n",
       "301           0.001                relu   xavier_uniform_        dropout   \n",
       "842           0.001                relu  kaiming_uniform_        dropout   \n",
       "244           0.001                relu   xavier_uniform_           None   \n",
       "1105          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1212          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1112          0.001                relu  kaiming_uniform_        dropout   \n",
       "110           0.001                relu  kaiming_uniform_           None   \n",
       "895           0.001                relu   xavier_uniform_        dropout   \n",
       "918           0.001                relu   xavier_uniform_           None   \n",
       "812           0.001                relu  kaiming_uniform_           None   \n",
       "1238          0.001                relu   xavier_uniform_        dropout   \n",
       "981           0.001                relu              None           None   \n",
       "1130          0.001                relu  kaiming_uniform_        dropout   \n",
       "788           0.001                relu  kaiming_uniform_        dropout   \n",
       "1159          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1020          0.001                relu              None        dropout   \n",
       "54            0.001                relu              None           None   \n",
       "994           0.001                relu              None        dropout   \n",
       "879           0.001                relu   xavier_uniform_         l2_reg   \n",
       "83            0.001                relu              None           None   \n",
       "1046          0.001                relu              None           None   \n",
       "1022          0.001                relu              None        dropout   \n",
       "136           0.001                relu  kaiming_uniform_           None   \n",
       "1076          0.001                relu              None        dropout   \n",
       "697           0.001                relu              None        dropout   \n",
       "950           0.001                relu   xavier_uniform_        dropout   \n",
       "1234          0.001                relu   xavier_uniform_           None   \n",
       "707           0.001                relu              None        dropout   \n",
       "243           0.001                relu   xavier_uniform_           None   \n",
       "948           0.001                relu   xavier_uniform_        dropout   \n",
       "1047          0.001                relu              None        dropout   \n",
       "1051          0.001                relu              None         l2_reg   \n",
       "825           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "696           0.001                relu              None        dropout   \n",
       "17            0.001                relu              None         l2_reg   \n",
       "1101          0.001                relu  kaiming_uniform_        dropout   \n",
       "1267          0.001                relu   xavier_uniform_         l2_reg   \n",
       "108           0.001                relu  kaiming_uniform_           None   \n",
       "734           0.001                relu              None        dropout   \n",
       "2             0.001                relu              None           None   \n",
       "135           0.001                relu  kaiming_uniform_           None   \n",
       "1185          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1290          0.001                relu   xavier_uniform_        dropout   \n",
       "28            0.001                relu              None           None   \n",
       "726           0.001                relu              None         l2_reg   \n",
       "137           0.001                relu  kaiming_uniform_           None   \n",
       "946           0.001                relu   xavier_uniform_           None   \n",
       "1025          0.001                relu              None         l2_reg   \n",
       "218           0.001                relu   xavier_uniform_           None   \n",
       "998           0.001                relu              None         l2_reg   \n",
       "1044          0.001                relu              None           None   \n",
       "82            0.001                relu              None           None   \n",
       "992           0.001                relu              None           None   \n",
       "1023          0.001                relu              None         l2_reg   \n",
       "29            0.001                relu              None           None   \n",
       "750           0.001                relu              None        dropout   \n",
       "995           0.001                relu              None        dropout   \n",
       "968           0.001                relu   xavier_uniform_        dropout   \n",
       "298           0.001                relu   xavier_uniform_           None   \n",
       "678           0.001                relu              None        dropout   \n",
       "1164          0.001                relu  kaiming_uniform_        dropout   \n",
       "802           0.001                relu  kaiming_uniform_           None   \n",
       "217           0.001                relu   xavier_uniform_           None   \n",
       "1202          0.001                relu   xavier_uniform_        dropout   \n",
       "271           0.001                relu   xavier_uniform_           None   \n",
       "659           0.001                relu              None           None   \n",
       "163           0.001                relu  kaiming_uniform_           None   \n",
       "1208          0.001                relu   xavier_uniform_           None   \n",
       "838           0.001                relu  kaiming_uniform_           None   \n",
       "883           0.001                relu   xavier_uniform_           None   \n",
       "915           0.001                relu   xavier_uniform_         l2_reg   \n",
       "670           0.001                relu              None        dropout   \n",
       "216           0.001                relu   xavier_uniform_           None   \n",
       "1             0.001                relu              None           None   \n",
       "245           0.001                relu   xavier_uniform_           None   \n",
       "1268          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1207          0.001                relu   xavier_uniform_           None   \n",
       "858           0.001                relu  kaiming_uniform_        dropout   \n",
       "839           0.001                relu  kaiming_uniform_           None   \n",
       "988           0.001                relu              None         l2_reg   \n",
       "1098          0.001                relu  kaiming_uniform_           None   \n",
       "55            0.001                relu              None           None   \n",
       "1103          0.001                relu  kaiming_uniform_        dropout   \n",
       "111           0.001                relu  kaiming_uniform_        dropout   \n",
       "1075          0.001                relu              None        dropout   \n",
       "1145          0.001                relu  kaiming_uniform_           None   \n",
       "672           0.001                relu              None         l2_reg   \n",
       "274           0.001                relu   xavier_uniform_        dropout   \n",
       "1050          0.001                relu              None         l2_reg   \n",
       "1236          0.001                relu   xavier_uniform_        dropout   \n",
       "1074          0.001                relu              None        dropout   \n",
       "1293          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1213          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1021          0.001                relu              None        dropout   \n",
       "733           0.001                relu              None        dropout   \n",
       "56            0.001                relu              None           None   \n",
       "991           0.001                relu              None           None   \n",
       "1100          0.001                relu  kaiming_uniform_           None   \n",
       "273           0.001                relu   xavier_uniform_        dropout   \n",
       "21            0.001                relu              None        dropout   \n",
       "246           0.001                relu   xavier_uniform_        dropout   \n",
       "233           0.001                relu   xavier_uniform_         l2_reg   \n",
       "771           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "706           0.001                relu              None        dropout   \n",
       "882           0.001                relu   xavier_uniform_           None   \n",
       "807           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "813           0.001                relu  kaiming_uniform_        dropout   \n",
       "885           0.001                relu   xavier_uniform_        dropout   \n",
       "1291          0.001                relu   xavier_uniform_        dropout   \n",
       "1152          0.001                relu  kaiming_uniform_           None   \n",
       "1266          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1127          0.001                relu  kaiming_uniform_           None   \n",
       "751           0.001                relu              None        dropout   \n",
       "669           0.001                relu              None        dropout   \n",
       "1214          0.001                relu   xavier_uniform_         l2_reg   \n",
       "804           0.001                relu  kaiming_uniform_        dropout   \n",
       "190           0.001                relu  kaiming_uniform_           None   \n",
       "1052          0.001                relu              None         l2_reg   \n",
       "913           0.001                relu   xavier_uniform_        dropout   \n",
       "0             0.001                relu              None           None   \n",
       "1133          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "195           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "189           0.001                relu  kaiming_uniform_           None   \n",
       "914           0.001                relu   xavier_uniform_        dropout   \n",
       "63            0.001                relu              None           None   \n",
       "705           0.001                relu              None        dropout   \n",
       "162           0.001                relu  kaiming_uniform_           None   \n",
       "81            0.001                relu              None           None   \n",
       "718           0.001                relu              None         l2_reg   \n",
       "1106          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1024          0.001                relu              None         l2_reg   \n",
       "1295          0.001                relu   xavier_uniform_         l2_reg   \n",
       "164           0.001                relu  kaiming_uniform_           None   \n",
       "1128          0.001                relu  kaiming_uniform_        dropout   \n",
       "826           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "84            0.001                relu              None        dropout   \n",
       "666           0.001                relu              None           None   \n",
       "196           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "910           0.001                relu   xavier_uniform_           None   \n",
       "1057          0.001                relu              None        dropout   \n",
       "170           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "699           0.001                relu              None         l2_reg   \n",
       "917           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1077          0.001                relu              None         l2_reg   \n",
       "947           0.001                relu   xavier_uniform_           None   \n",
       "3             0.001                relu              None        dropout   \n",
       "251           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1264          0.001                relu   xavier_uniform_        dropout   \n",
       "140           0.001                relu  kaiming_uniform_        dropout   \n",
       "780           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1019          0.001                relu              None           None   \n",
       "874           0.001                relu   xavier_uniform_           None   \n",
       "966           0.001                relu   xavier_uniform_        dropout   \n",
       "1241          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1132          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "109           0.001                relu  kaiming_uniform_           None   \n",
       "1125          0.001                relu  kaiming_uniform_           None   \n",
       "831           0.001                relu  kaiming_uniform_        dropout   \n",
       "143           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "711           0.001                relu              None           None   \n",
       "197           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "16            0.001                relu              None         l2_reg   \n",
       "671           0.001                relu              None        dropout   \n",
       "805           0.001                relu  kaiming_uniform_        dropout   \n",
       "1160          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "815           0.001                relu  kaiming_uniform_        dropout   \n",
       "222           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1155          0.001                relu  kaiming_uniform_        dropout   \n",
       "1126          0.001                relu  kaiming_uniform_           None   \n",
       "1211          0.001                relu   xavier_uniform_        dropout   \n",
       "1018          0.001                relu              None           None   \n",
       "1237          0.001                relu   xavier_uniform_        dropout   \n",
       "1210          0.001                relu   xavier_uniform_        dropout   \n",
       "141           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1043          0.001                relu              None         l2_reg   \n",
       "299           0.001                relu   xavier_uniform_           None   \n",
       "169           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "278           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1158          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1129          0.001                relu  kaiming_uniform_        dropout   \n",
       "761           0.001                relu  kaiming_uniform_        dropout   \n",
       "221           0.001                relu   xavier_uniform_        dropout   \n",
       "193           0.001                relu  kaiming_uniform_        dropout   \n",
       "219           0.001                relu   xavier_uniform_        dropout   \n",
       "837           0.001                relu  kaiming_uniform_           None   \n",
       "57            0.001                relu              None        dropout   \n",
       "755           0.001                relu              None         l2_reg   \n",
       "116           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "31            0.001                relu              None        dropout   \n",
       "775           0.001                relu  kaiming_uniform_           None   \n",
       "114           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "168           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "300           0.001                relu   xavier_uniform_        dropout   \n",
       "782           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "774           0.001                relu  kaiming_uniform_           None   \n",
       "927           0.001                relu   xavier_uniform_           None   \n",
       "916           0.001                relu   xavier_uniform_         l2_reg   \n",
       "85            0.001                relu              None        dropout   \n",
       "1182          0.001                relu  kaiming_uniform_        dropout   \n",
       "1184          0.001                relu  kaiming_uniform_        dropout   \n",
       "834           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "890           0.001                relu   xavier_uniform_         l2_reg   \n",
       "819           0.001                relu  kaiming_uniform_           None   \n",
       "126           0.001                relu  kaiming_uniform_           None   \n",
       "723           0.001                relu              None        dropout   \n",
       "809           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1153          0.001                relu  kaiming_uniform_           None   \n",
       "803           0.001                relu  kaiming_uniform_           None   \n",
       "142           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1048          0.001                relu              None        dropout   \n",
       "248           0.001                relu   xavier_uniform_        dropout   \n",
       "693           0.001                relu              None           None   \n",
       "50            0.001                relu              None        dropout   \n",
       "139           0.001                relu  kaiming_uniform_        dropout   \n",
       "1099          0.001                relu  kaiming_uniform_           None   \n",
       "990           0.001                relu              None           None   \n",
       "1045          0.001                relu              None           None   \n",
       "1240          0.001                relu   xavier_uniform_         l2_reg   \n",
       "969           0.001                relu   xavier_uniform_         l2_reg   \n",
       "220           0.001                relu   xavier_uniform_        dropout   \n",
       "1260          0.001                relu   xavier_uniform_           None   \n",
       "668           0.001                relu              None           None   \n",
       "115           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "814           0.001                relu  kaiming_uniform_        dropout   \n",
       "801           0.001                relu  kaiming_uniform_           None   \n",
       "1233          0.001                relu   xavier_uniform_           None   \n",
       "698           0.001                relu              None        dropout   \n",
       "4             0.001                relu              None        dropout   \n",
       "5             0.001                relu              None        dropout   \n",
       "250           0.001                relu   xavier_uniform_         l2_reg   \n",
       "191           0.001                relu  kaiming_uniform_           None   \n",
       "808           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "667           0.001                relu              None           None   \n",
       "836           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1079          0.001                relu              None         l2_reg   \n",
       "69            0.001                relu              None         l2_reg   \n",
       "15            0.001                relu              None         l2_reg   \n",
       "884           0.001                relu   xavier_uniform_           None   \n",
       "291           0.001                relu   xavier_uniform_        dropout   \n",
       "921           0.001                relu   xavier_uniform_        dropout   \n",
       "32            0.001                relu              None        dropout   \n",
       "778           0.001                relu  kaiming_uniform_        dropout   \n",
       "724           0.001                relu              None        dropout   \n",
       "747           0.001                relu              None           None   \n",
       "888           0.001                relu   xavier_uniform_         l2_reg   \n",
       "720           0.001                relu              None           None   \n",
       "909           0.001                relu   xavier_uniform_           None   \n",
       "25            0.001                relu              None         l2_reg   \n",
       "701           0.001                relu              None         l2_reg   \n",
       "694           0.001                relu              None           None   \n",
       "26            0.001                relu              None         l2_reg   \n",
       "192           0.001                relu  kaiming_uniform_        dropout   \n",
       "722           0.001                relu              None           None   \n",
       "674           0.001                relu              None         l2_reg   \n",
       "138           0.001                relu  kaiming_uniform_        dropout   \n",
       "695           0.001                relu              None           None   \n",
       "936           0.001                relu   xavier_uniform_           None   \n",
       "10            0.001                relu              None           None   \n",
       "700           0.001                relu              None         l2_reg   \n",
       "1186          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "911           0.001                relu   xavier_uniform_           None   \n",
       "272           0.001                relu   xavier_uniform_           None   \n",
       "270           0.001                relu   xavier_uniform_           None   \n",
       "887           0.001                relu   xavier_uniform_        dropout   \n",
       "860           0.001                relu  kaiming_uniform_        dropout   \n",
       "781           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "971           0.001                relu   xavier_uniform_         l2_reg   \n",
       "889           0.001                relu   xavier_uniform_         l2_reg   \n",
       "112           0.001                relu  kaiming_uniform_        dropout   \n",
       "1245          0.001                relu   xavier_uniform_        dropout   \n",
       "727           0.001                relu              None         l2_reg   \n",
       "133           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1072          0.001                relu              None           None   \n",
       "663           0.001                relu              None         l2_reg   \n",
       "132           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1292          0.001                relu   xavier_uniform_        dropout   \n",
       "754           0.001                relu              None         l2_reg   \n",
       "828           0.001                relu  kaiming_uniform_           None   \n",
       "1261          0.001                relu   xavier_uniform_           None   \n",
       "829           0.001                relu  kaiming_uniform_           None   \n",
       "223           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1078          0.001                relu              None         l2_reg   \n",
       "975           0.001                relu              None        dropout   \n",
       "30            0.001                relu              None        dropout   \n",
       "967           0.001                relu   xavier_uniform_        dropout   \n",
       "776           0.001                relu  kaiming_uniform_           None   \n",
       "102           0.001                relu              None        dropout   \n",
       "320           0.001                relu   xavier_uniform_        dropout   \n",
       "156           0.001                relu  kaiming_uniform_        dropout   \n",
       "22            0.001                relu              None        dropout   \n",
       "806           0.001                relu  kaiming_uniform_        dropout   \n",
       "80            0.001                relu              None         l2_reg   \n",
       "728           0.001                relu              None         l2_reg   \n",
       "103           0.001                relu              None        dropout   \n",
       "1187          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "19            0.001                relu              None           None   \n",
       "863           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "214           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "673           0.001                relu              None         l2_reg   \n",
       "134           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1071          0.001                relu              None           None   \n",
       "835           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "318           0.001                relu   xavier_uniform_        dropout   \n",
       "861           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1289          0.001                relu   xavier_uniform_           None   \n",
       "944           0.001                relu   xavier_uniform_         l2_reg   \n",
       "886           0.001                relu   xavier_uniform_        dropout   \n",
       "753           0.001                relu              None         l2_reg   \n",
       "237           0.001                relu   xavier_uniform_        dropout   \n",
       "1049          0.001                relu              None        dropout   \n",
       "24            0.001                relu              None         l2_reg   \n",
       "127           0.001                relu  kaiming_uniform_           None   \n",
       "1262          0.001                relu   xavier_uniform_           None   \n",
       "779           0.001                relu  kaiming_uniform_        dropout   \n",
       "73            0.001                relu              None           None   \n",
       "155           0.001                relu  kaiming_uniform_           None   \n",
       "49            0.001                relu              None        dropout   \n",
       "1183          0.001                relu  kaiming_uniform_        dropout   \n",
       "1235          0.001                relu   xavier_uniform_           None   \n",
       "267           0.001                relu   xavier_uniform_         l2_reg   \n",
       "275           0.001                relu   xavier_uniform_        dropout   \n",
       "1179          0.001                relu  kaiming_uniform_           None   \n",
       "319           0.001                relu   xavier_uniform_        dropout   \n",
       "938           0.001                relu   xavier_uniform_           None   \n",
       "1287          0.001                relu   xavier_uniform_           None   \n",
       "266           0.001                relu   xavier_uniform_        dropout   \n",
       "154           0.001                relu  kaiming_uniform_           None   \n",
       "75            0.001                relu              None        dropout   \n",
       "51            0.001                relu              None         l2_reg   \n",
       "297           0.001                relu   xavier_uniform_           None   \n",
       "18            0.001                relu              None           None   \n",
       "942           0.001                relu   xavier_uniform_         l2_reg   \n",
       "859           0.001                relu  kaiming_uniform_        dropout   \n",
       "912           0.001                relu   xavier_uniform_        dropout   \n",
       "1288          0.001                relu   xavier_uniform_           None   \n",
       "970           0.001                relu   xavier_uniform_         l2_reg   \n",
       "264           0.001                relu   xavier_uniform_        dropout   \n",
       "53            0.001                relu              None         l2_reg   \n",
       "212           0.001                relu  kaiming_uniform_        dropout   \n",
       "1197          0.001                relu   xavier_uniform_           None   \n",
       "48            0.001                relu              None        dropout   \n",
       "153           0.001                relu  kaiming_uniform_           None   \n",
       "23            0.001                relu              None        dropout   \n",
       "1294          0.001                relu   xavier_uniform_         l2_reg   \n",
       "685           0.001                relu              None           None   \n",
       "161           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "78            0.001                relu              None         l2_reg   \n",
       "159           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "240           0.001                relu   xavier_uniform_         l2_reg   \n",
       "262           0.001                relu   xavier_uniform_           None   \n",
       "1085          0.001                relu  kaiming_uniform_        dropout   \n",
       "194           0.001                relu  kaiming_uniform_        dropout   \n",
       "234           0.001                relu   xavier_uniform_           None   \n",
       "167           0.001                relu  kaiming_uniform_        dropout   \n",
       "268           0.001                relu   xavier_uniform_         l2_reg   \n",
       "235           0.001                relu   xavier_uniform_           None   \n",
       "1073          0.001                relu              None           None   \n",
       "47            0.001                relu              None           None   \n",
       "1209          0.001                relu   xavier_uniform_        dropout   \n",
       "279           0.001                relu   xavier_uniform_           None   \n",
       "721           0.001                relu              None           None   \n",
       "188           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "105           0.001                relu              None         l2_reg   \n",
       "943           0.001                relu   xavier_uniform_         l2_reg   \n",
       "294           0.001                relu   xavier_uniform_         l2_reg   \n",
       "45            0.001                relu              None           None   \n",
       "323           0.001                relu   xavier_uniform_         l2_reg   \n",
       "963           0.001                relu   xavier_uniform_           None   \n",
       "104           0.001                relu              None        dropout   \n",
       "79            0.001                relu              None         l2_reg   \n",
       "1180          0.001                relu  kaiming_uniform_           None   \n",
       "777           0.001                relu  kaiming_uniform_        dropout   \n",
       "749           0.001                relu              None           None   \n",
       "238           0.001                relu   xavier_uniform_        dropout   \n",
       "321           0.001                relu   xavier_uniform_         l2_reg   \n",
       "748           0.001                relu              None           None   \n",
       "236           0.001                relu   xavier_uniform_           None   \n",
       "242           0.001                relu   xavier_uniform_         l2_reg   \n",
       "101           0.001                relu              None           None   \n",
       "289           0.001                relu   xavier_uniform_           None   \n",
       "166           0.001                relu  kaiming_uniform_        dropout   \n",
       "269           0.001                relu   xavier_uniform_         l2_reg   \n",
       "295           0.001                relu   xavier_uniform_         l2_reg   \n",
       "107           0.001                relu              None         l2_reg   \n",
       "261           0.001                relu   xavier_uniform_           None   \n",
       "129           0.001                relu  kaiming_uniform_        dropout   \n",
       "158           0.001                relu  kaiming_uniform_        dropout   \n",
       "213           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "72            0.001                relu              None           None   \n",
       "106           0.001                relu              None         l2_reg   \n",
       "856           0.001                relu  kaiming_uniform_           None   \n",
       "263           0.001                relu   xavier_uniform_           None   \n",
       "239           0.001                relu   xavier_uniform_        dropout   \n",
       "830           0.001                relu  kaiming_uniform_           None   \n",
       "937           0.001                relu   xavier_uniform_           None   \n",
       "862           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1181          0.001                relu  kaiming_uniform_           None   \n",
       "210           0.001                relu  kaiming_uniform_        dropout   \n",
       "157           0.001                relu  kaiming_uniform_        dropout   \n",
       "52            0.001                relu              None         l2_reg   \n",
       "288           0.001                relu   xavier_uniform_           None   \n",
       "181           0.001                relu  kaiming_uniform_           None   \n",
       "241           0.001                relu   xavier_uniform_         l2_reg   \n",
       "20            0.001                relu              None           None   \n",
       "160           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "215           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "186           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "131           0.001                relu  kaiming_uniform_        dropout   \n",
       "183           0.001                relu  kaiming_uniform_        dropout   \n",
       "74            0.001                relu              None           None   \n",
       "86            0.001                relu              None        dropout   \n",
       "46            0.001                relu              None           None   \n",
       "315           0.001                relu   xavier_uniform_           None   \n",
       "290           0.001                relu   xavier_uniform_           None   \n",
       "322           0.001                relu   xavier_uniform_         l2_reg   \n",
       "165           0.001                relu  kaiming_uniform_        dropout   \n",
       "128           0.001                relu  kaiming_uniform_           None   \n",
       "316           0.001                relu   xavier_uniform_           None   \n",
       "296           0.001                relu   xavier_uniform_         l2_reg   \n",
       "857           0.001                relu  kaiming_uniform_           None   \n",
       "692           0.001                relu              None         l2_reg   \n",
       "1083          0.001                relu  kaiming_uniform_        dropout   \n",
       "725           0.001                relu              None        dropout   \n",
       "293           0.001                relu   xavier_uniform_        dropout   \n",
       "265           0.001                relu   xavier_uniform_        dropout   \n",
       "1156          0.001                relu  kaiming_uniform_        dropout   \n",
       "99            0.001                relu              None           None   \n",
       "965           0.001                relu   xavier_uniform_           None   \n",
       "187           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "964           0.001                relu   xavier_uniform_           None   \n",
       "211           0.001                relu  kaiming_uniform_        dropout   \n",
       "302           0.001                relu   xavier_uniform_        dropout   \n",
       "180           0.001                relu  kaiming_uniform_           None   \n",
       "247           0.001                relu   xavier_uniform_        dropout   \n",
       "941           0.001                relu   xavier_uniform_        dropout   \n",
       "940           0.001                relu   xavier_uniform_        dropout   \n",
       "208           0.001                relu  kaiming_uniform_           None   \n",
       "209           0.001                relu  kaiming_uniform_           None   \n",
       "1265          0.001                relu   xavier_uniform_        dropout   \n",
       "207           0.001                relu  kaiming_uniform_           None   \n",
       "100           0.001                relu              None           None   \n",
       "855           0.001                relu  kaiming_uniform_           None   \n",
       "113           0.001                relu  kaiming_uniform_        dropout   \n",
       "317           0.001                relu   xavier_uniform_           None   \n",
       "77            0.001                relu              None        dropout   \n",
       "1144          0.001                relu  kaiming_uniform_           None   \n",
       "1154          0.001                relu  kaiming_uniform_           None   \n",
       "182           0.001                relu  kaiming_uniform_           None   \n",
       "832           0.001                relu  kaiming_uniform_        dropout   \n",
       "1102          0.001                relu  kaiming_uniform_        dropout   \n",
       "130           0.001                relu  kaiming_uniform_        dropout   \n",
       "174           0.001                relu  kaiming_uniform_        dropout   \n",
       "833           0.001                relu  kaiming_uniform_        dropout   \n",
       "292           0.001                relu   xavier_uniform_        dropout   \n",
       "987           0.001                relu              None         l2_reg   \n",
       "512           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "43            0.001                relu              None         l2_reg   \n",
       "1224          0.001                relu   xavier_uniform_           None   \n",
       "939           0.001                relu   xavier_uniform_        dropout   \n",
       "1157          0.001                relu  kaiming_uniform_        dropout   \n",
       "511           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "344           0.001                relu              None           None   \n",
       "428           0.001                relu              None        dropout   \n",
       "459           0.001                relu  kaiming_uniform_           None   \n",
       "1263          0.001                relu   xavier_uniform_        dropout   \n",
       "377           0.001                relu              None         l2_reg   \n",
       "11            0.001                relu              None           None   \n",
       "404           0.001                relu              None         l2_reg   \n",
       "76            0.001                relu              None        dropout   \n",
       "375           0.001                relu              None         l2_reg   \n",
       "353           0.001                relu              None           None   \n",
       "405           0.001                relu              None           None   \n",
       "351           0.001                relu              None           None   \n",
       "456           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "596           0.001                relu   xavier_uniform_           None   \n",
       "514           0.001                relu  kaiming_uniform_           None   \n",
       "488           0.001                relu  kaiming_uniform_           None   \n",
       "647           0.001                relu   xavier_uniform_         l2_reg   \n",
       "568           0.001                relu   xavier_uniform_           None   \n",
       "565           0.001                relu   xavier_uniform_         l2_reg   \n",
       "450           0.001                relu  kaiming_uniform_           None   \n",
       "487           0.001                relu  kaiming_uniform_           None   \n",
       "587           0.001                relu   xavier_uniform_           None   \n",
       "407           0.001                relu              None           None   \n",
       "461           0.001                relu  kaiming_uniform_           None   \n",
       "621           0.001                relu   xavier_uniform_           None   \n",
       "341           0.001                relu              None         l2_reg   \n",
       "380           0.001                relu              None           None   \n",
       "794           0.001                relu  kaiming_uniform_           None   \n",
       "389           0.001                relu              None           None   \n",
       "349           0.001                relu              None         l2_reg   \n",
       "713           0.001                relu              None           None   \n",
       "433           0.001                relu  kaiming_uniform_           None   \n",
       "406           0.001                relu              None           None   \n",
       "460           0.001                relu  kaiming_uniform_           None   \n",
       "595           0.001                relu   xavier_uniform_           None   \n",
       "431           0.001                relu              None         l2_reg   \n",
       "485           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "646           0.001                relu   xavier_uniform_         l2_reg   \n",
       "541           0.001                relu   xavier_uniform_           None   \n",
       "622           0.001                relu   xavier_uniform_           None   \n",
       "352           0.001                relu              None           None   \n",
       "373           0.001                relu              None        dropout   \n",
       "402           0.001                relu              None         l2_reg   \n",
       "569           0.001                relu   xavier_uniform_           None   \n",
       "457           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "594           0.001                relu   xavier_uniform_           None   \n",
       "423           0.001                relu              None           None   \n",
       "372           0.001                relu              None        dropout   \n",
       "397           0.001                relu              None           None   \n",
       "567           0.001                relu   xavier_uniform_           None   \n",
       "425           0.001                relu              None           None   \n",
       "348           0.001                relu              None         l2_reg   \n",
       "346           0.001                relu              None        dropout   \n",
       "1139          0.001                relu  kaiming_uniform_        dropout   \n",
       "374           0.001                relu              None        dropout   \n",
       "370           0.001                relu              None           None   \n",
       "429           0.001                relu              None         l2_reg   \n",
       "426           0.001                relu              None        dropout   \n",
       "934           0.001                relu   xavier_uniform_         l2_reg   \n",
       "369           0.001                relu              None           None   \n",
       "623           0.001                relu   xavier_uniform_           None   \n",
       "540           0.001                relu   xavier_uniform_           None   \n",
       "343           0.001                relu              None           None   \n",
       "376           0.001                relu              None         l2_reg   \n",
       "398           0.001                relu              None           None   \n",
       "434           0.001                relu  kaiming_uniform_           None   \n",
       "515           0.001                relu  kaiming_uniform_           None   \n",
       "586           0.001                relu   xavier_uniform_           None   \n",
       "345           0.001                relu              None        dropout   \n",
       "479           0.001                relu  kaiming_uniform_           None   \n",
       "458           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "539           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "642           0.001                relu   xavier_uniform_        dropout   \n",
       "543           0.001                relu   xavier_uniform_        dropout   \n",
       "326           0.001                relu              None           None   \n",
       "538           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "371           0.001                relu              None           None   \n",
       "564           0.001                relu   xavier_uniform_         l2_reg   \n",
       "480           0.001                relu  kaiming_uniform_        dropout   \n",
       "793           0.001                relu  kaiming_uniform_           None   \n",
       "592           0.001                relu   xavier_uniform_         l2_reg   \n",
       "482           0.001                relu  kaiming_uniform_        dropout   \n",
       "566           0.001                relu   xavier_uniform_         l2_reg   \n",
       "484           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "408           0.001                relu              None        dropout   \n",
       "424           0.001                relu              None           None   \n",
       "350           0.001                relu              None         l2_reg   \n",
       "481           0.001                relu  kaiming_uniform_        dropout   \n",
       "542           0.001                relu   xavier_uniform_           None   \n",
       "617           0.001                relu   xavier_uniform_        dropout   \n",
       "618           0.001                relu   xavier_uniform_         l2_reg   \n",
       "624           0.001                relu   xavier_uniform_        dropout   \n",
       "591           0.001                relu   xavier_uniform_         l2_reg   \n",
       "612           0.001                relu   xavier_uniform_           None   \n",
       "342           0.001                relu              None           None   \n",
       "427           0.001                relu              None        dropout   \n",
       "437           0.001                relu  kaiming_uniform_        dropout   \n",
       "613           0.001                relu   xavier_uniform_           None   \n",
       "531           0.001                relu  kaiming_uniform_           None   \n",
       "513           0.001                relu  kaiming_uniform_           None   \n",
       "478           0.001                relu  kaiming_uniform_           None   \n",
       "533           0.001                relu  kaiming_uniform_           None   \n",
       "593           0.001                relu   xavier_uniform_         l2_reg   \n",
       "537           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "396           0.001                relu              None           None   \n",
       "534           0.001                relu  kaiming_uniform_        dropout   \n",
       "477           0.001                relu  kaiming_uniform_           None   \n",
       "614           0.001                relu   xavier_uniform_           None   \n",
       "984           0.001                relu              None        dropout   \n",
       "560           0.001                relu   xavier_uniform_           None   \n",
       "403           0.001                relu              None         l2_reg   \n",
       "462           0.001                relu  kaiming_uniform_        dropout   \n",
       "504           0.001                relu  kaiming_uniform_           None   \n",
       "619           0.001                relu   xavier_uniform_         l2_reg   \n",
       "451           0.001                relu  kaiming_uniform_           None   \n",
       "620           0.001                relu   xavier_uniform_         l2_reg   \n",
       "432           0.001                relu  kaiming_uniform_           None   \n",
       "464           0.001                relu  kaiming_uniform_        dropout   \n",
       "536           0.001                relu  kaiming_uniform_        dropout   \n",
       "559           0.001                relu   xavier_uniform_           None   \n",
       "510           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "430           0.001                relu              None         l2_reg   \n",
       "561           0.001                relu   xavier_uniform_        dropout   \n",
       "599           0.001                relu   xavier_uniform_        dropout   \n",
       "588           0.001                relu   xavier_uniform_        dropout   \n",
       "452           0.001                relu  kaiming_uniform_           None   \n",
       "645           0.001                relu   xavier_uniform_         l2_reg   \n",
       "589           0.001                relu   xavier_uniform_        dropout   \n",
       "354           0.001                relu              None        dropout   \n",
       "185           0.001                relu  kaiming_uniform_        dropout   \n",
       "483           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "639           0.001                relu   xavier_uniform_           None   \n",
       "489           0.001                relu  kaiming_uniform_        dropout   \n",
       "516           0.001                relu  kaiming_uniform_        dropout   \n",
       "1177          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "558           0.001                relu   xavier_uniform_           None   \n",
       "644           0.001                relu   xavier_uniform_        dropout   \n",
       "506           0.001                relu  kaiming_uniform_           None   \n",
       "325           0.001                relu              None           None   \n",
       "616           0.001                relu   xavier_uniform_        dropout   \n",
       "327           0.001                relu              None        dropout   \n",
       "490           0.001                relu  kaiming_uniform_        dropout   \n",
       "640           0.001                relu   xavier_uniform_           None   \n",
       "356           0.001                relu              None        dropout   \n",
       "532           0.001                relu  kaiming_uniform_           None   \n",
       "505           0.001                relu  kaiming_uniform_           None   \n",
       "641           0.001                relu   xavier_uniform_           None   \n",
       "453           0.001                relu  kaiming_uniform_        dropout   \n",
       "585           0.001                relu   xavier_uniform_           None   \n",
       "455           0.001                relu  kaiming_uniform_        dropout   \n",
       "347           0.001                relu              None        dropout   \n",
       "486           0.001                relu  kaiming_uniform_           None   \n",
       "355           0.001                relu              None        dropout   \n",
       "626           0.001                relu   xavier_uniform_        dropout   \n",
       "454           0.001                relu  kaiming_uniform_        dropout   \n",
       "535           0.001                relu  kaiming_uniform_        dropout   \n",
       "590           0.001                relu   xavier_uniform_        dropout   \n",
       "625           0.001                relu   xavier_uniform_        dropout   \n",
       "615           0.001                relu   xavier_uniform_        dropout   \n",
       "562           0.001                relu   xavier_uniform_        dropout   \n",
       "570           0.001                relu   xavier_uniform_        dropout   \n",
       "643           0.001                relu   xavier_uniform_        dropout   \n",
       "184           0.001                relu  kaiming_uniform_        dropout   \n",
       "463           0.001                relu  kaiming_uniform_        dropout   \n",
       "571           0.001                relu   xavier_uniform_        dropout   \n",
       "820           0.001                relu  kaiming_uniform_           None   \n",
       "340           0.001                relu              None         l2_reg   \n",
       "409           0.001                relu              None        dropout   \n",
       "507           0.001                relu  kaiming_uniform_        dropout   \n",
       "563           0.001                relu   xavier_uniform_        dropout   \n",
       "382           0.001                relu              None        dropout   \n",
       "572           0.001                relu   xavier_uniform_        dropout   \n",
       "401           0.001                relu              None        dropout   \n",
       "509           0.001                relu  kaiming_uniform_        dropout   \n",
       "508           0.001                relu  kaiming_uniform_        dropout   \n",
       "935           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1259          0.001                relu   xavier_uniform_         l2_reg   \n",
       "399           0.001                relu              None        dropout   \n",
       "544           0.001                relu   xavier_uniform_        dropout   \n",
       "502           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1251          0.001                relu   xavier_uniform_           None   \n",
       "284           0.001                relu   xavier_uniform_        dropout   \n",
       "739           0.001                relu              None           None   \n",
       "518           0.001                relu  kaiming_uniform_        dropout   \n",
       "491           0.001                relu  kaiming_uniform_        dropout   \n",
       "603           0.001                relu   xavier_uniform_           None   \n",
       "152           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "410           0.001                relu              None        dropout   \n",
       "1151          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "400           0.001                relu              None        dropout   \n",
       "381           0.001                relu              None        dropout   \n",
       "333           0.001                relu              None           None   \n",
       "1010          0.001                relu              None           None   \n",
       "1285          0.001                relu   xavier_uniform_         l2_reg   \n",
       "314           0.001                relu   xavier_uniform_         l2_reg   \n",
       "907           0.001                relu   xavier_uniform_         l2_reg   \n",
       "902           0.001                relu   xavier_uniform_           None   \n",
       "1117          0.001                relu  kaiming_uniform_           None   \n",
       "545           0.001                relu   xavier_uniform_        dropout   \n",
       "989           0.001                relu              None         l2_reg   \n",
       "906           0.001                relu   xavier_uniform_         l2_reg   \n",
       "517           0.001                relu  kaiming_uniform_        dropout   \n",
       "799           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "767           0.001                relu  kaiming_uniform_           None   \n",
       "339           0.001                relu              None         l2_reg   \n",
       "145           0.001                relu  kaiming_uniform_           None   \n",
       "1149          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "792           0.001                relu  kaiming_uniform_           None   \n",
       "770           0.001                relu  kaiming_uniform_        dropout   \n",
       "1035          0.001                relu              None           None   \n",
       "1143          0.001                relu  kaiming_uniform_           None   \n",
       "798           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "117           0.001                relu  kaiming_uniform_           None   \n",
       "1200          0.001                relu   xavier_uniform_        dropout   \n",
       "908           0.001                relu   xavier_uniform_         l2_reg   \n",
       "904           0.001                relu   xavier_uniform_        dropout   \n",
       "1123          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "253           0.001                relu   xavier_uniform_           None   \n",
       "1119          0.001                relu  kaiming_uniform_        dropout   \n",
       "12            0.001                relu              None        dropout   \n",
       "660           0.001                relu              None        dropout   \n",
       "556           0.001                relu   xavier_uniform_         l2_reg   \n",
       "932           0.001                relu   xavier_uniform_        dropout   \n",
       "1095          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "259           0.001                relu   xavier_uniform_         l2_reg   \n",
       "769           0.001                relu  kaiming_uniform_        dropout   \n",
       "1041          0.001                relu              None         l2_reg   \n",
       "1252          0.001                relu   xavier_uniform_           None   \n",
       "122           0.001                relu  kaiming_uniform_        dropout   \n",
       "1036          0.001                relu              None           None   \n",
       "854           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "119           0.001                relu  kaiming_uniform_           None   \n",
       "283           0.001                relu   xavier_uniform_        dropout   \n",
       "1091          0.001                relu  kaiming_uniform_           None   \n",
       "1121          0.001                relu  kaiming_uniform_        dropout   \n",
       "1255          0.001                relu   xavier_uniform_        dropout   \n",
       "198           0.001                relu  kaiming_uniform_           None   \n",
       "176           0.001                relu  kaiming_uniform_        dropout   \n",
       "1012          0.001                relu              None        dropout   \n",
       "928           0.001                relu   xavier_uniform_           None   \n",
       "847           0.001                relu  kaiming_uniform_           None   \n",
       "958           0.001                relu   xavier_uniform_        dropout   \n",
       "1097          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "285           0.001                relu   xavier_uniform_         l2_reg   \n",
       "470           0.001                relu  kaiming_uniform_           None   \n",
       "1258          0.001                relu   xavier_uniform_         l2_reg   \n",
       "931           0.001                relu   xavier_uniform_        dropout   \n",
       "230           0.001                relu   xavier_uniform_        dropout   \n",
       "280           0.001                relu   xavier_uniform_           None   \n",
       "738           0.001                relu              None           None   \n",
       "1089          0.001                relu  kaiming_uniform_           None   \n",
       "205           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "147           0.001                relu  kaiming_uniform_        dropout   \n",
       "1178          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "206           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1232          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1228          0.001                relu   xavier_uniform_        dropout   \n",
       "1229          0.001                relu   xavier_uniform_        dropout   \n",
       "1230          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1231          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1034          0.001                relu              None         l2_reg   \n",
       "97            0.001                relu              None         l2_reg   \n",
       "287           0.001                relu   xavier_uniform_         l2_reg   \n",
       "286           0.001                relu   xavier_uniform_         l2_reg   \n",
       "98            0.001                relu              None         l2_reg   \n",
       "1250          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1096          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1227          0.001                relu   xavier_uniform_        dropout   \n",
       "313           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1254          0.001                relu   xavier_uniform_        dropout   \n",
       "1225          0.001                relu   xavier_uniform_           None   \n",
       "35            0.001                relu              None         l2_reg   \n",
       "34            0.001                relu              None         l2_reg   \n",
       "33            0.001                relu              None         l2_reg   \n",
       "93            0.001                relu              None        dropout   \n",
       "1223          0.001                relu   xavier_uniform_         l2_reg   \n",
       "120           0.001                relu  kaiming_uniform_        dropout   \n",
       "121           0.001                relu  kaiming_uniform_        dropout   \n",
       "96            0.001                relu              None         l2_reg   \n",
       "1226          0.001                relu   xavier_uniform_           None   \n",
       "1042          0.001                relu              None         l2_reg   \n",
       "94            0.001                relu              None        dropout   \n",
       "1039          0.001                relu              None        dropout   \n",
       "95            0.001                relu              None        dropout   \n",
       "1038          0.001                relu              None        dropout   \n",
       "1253          0.001                relu   xavier_uniform_           None   \n",
       "308           0.001                relu   xavier_uniform_           None   \n",
       "37            0.001                relu              None           None   \n",
       "1283          0.001                relu   xavier_uniform_        dropout   \n",
       "1277          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1278          0.001                relu   xavier_uniform_           None   \n",
       "1279          0.001                relu   xavier_uniform_           None   \n",
       "1280          0.001                relu   xavier_uniform_           None   \n",
       "1281          0.001                relu   xavier_uniform_        dropout   \n",
       "1282          0.001                relu   xavier_uniform_        dropout   \n",
       "324           0.001                relu              None           None   \n",
       "1033          0.001                relu              None         l2_reg   \n",
       "1284          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1286          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1016          0.001                relu              None         l2_reg   \n",
       "1015          0.001                relu              None         l2_reg   \n",
       "1092          0.001                relu  kaiming_uniform_        dropout   \n",
       "1014          0.001                relu              None         l2_reg   \n",
       "1276          0.001                relu   xavier_uniform_         l2_reg   \n",
       "6             0.001                relu              None         l2_reg   \n",
       "7             0.001                relu              None         l2_reg   \n",
       "8             0.001                relu              None         l2_reg   \n",
       "9             0.001                relu              None           None   \n",
       "1093          0.001                relu  kaiming_uniform_        dropout   \n",
       "1027          0.001                relu              None           None   \n",
       "13            0.001                relu              None        dropout   \n",
       "125           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "14            0.001                relu              None        dropout   \n",
       "124           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "123           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1094          0.001                relu  kaiming_uniform_        dropout   \n",
       "1031          0.001                relu              None        dropout   \n",
       "1257          0.001                relu   xavier_uniform_         l2_reg   \n",
       "1256          0.001                relu   xavier_uniform_        dropout   \n",
       "1032          0.001                relu              None         l2_reg   \n",
       "36            0.001                relu              None           None   \n",
       "38            0.001                relu              None           None   \n",
       "307           0.001                relu   xavier_uniform_           None   \n",
       "309           0.001                relu   xavier_uniform_        dropout   \n",
       "67            0.001                relu              None        dropout   \n",
       "1069          0.001                relu              None         l2_reg   \n",
       "1068          0.001                relu              None         l2_reg   \n",
       "1067          0.001                relu              None        dropout   \n",
       "1116          0.001                relu  kaiming_uniform_           None   \n",
       "1066          0.001                relu              None        dropout   \n",
       "1065          0.001                relu              None        dropout   \n",
       "64            0.001                relu              None           None   \n",
       "1064          0.001                relu              None           None   \n",
       "1063          0.001                relu              None           None   \n",
       "66            0.001                relu              None        dropout   \n",
       "1062          0.001                relu              None           None   \n",
       "310           0.001                relu   xavier_uniform_        dropout   \n",
       "1061          0.001                relu              None         l2_reg   \n",
       "68            0.001                relu              None        dropout   \n",
       "1118          0.001                relu  kaiming_uniform_           None   \n",
       "70            0.001                relu              None         l2_reg   \n",
       "1013          0.001                relu              None        dropout   \n",
       "1147          0.001                relu  kaiming_uniform_        dropout   \n",
       "1146          0.001                relu  kaiming_uniform_        dropout   \n",
       "1120          0.001                relu  kaiming_uniform_        dropout   \n",
       "71            0.001                relu              None         l2_reg   \n",
       "1122          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1138          0.001                relu  kaiming_uniform_        dropout   \n",
       "1070          0.001                relu              None         l2_reg   \n",
       "1137          0.001                relu  kaiming_uniform_        dropout   \n",
       "1124          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "303           0.001                relu   xavier_uniform_         l2_reg   \n",
       "304           0.001                relu   xavier_uniform_         l2_reg   \n",
       "305           0.001                relu   xavier_uniform_         l2_reg   \n",
       "306           0.001                relu   xavier_uniform_           None   \n",
       "65            0.001                relu              None           None   \n",
       "311           0.001                relu   xavier_uniform_        dropout   \n",
       "39            0.001                relu              None        dropout   \n",
       "1203          0.001                relu   xavier_uniform_         l2_reg   \n",
       "89            0.001                relu              None         l2_reg   \n",
       "1201          0.001                relu   xavier_uniform_        dropout   \n",
       "90            0.001                relu              None           None   \n",
       "91            0.001                relu              None           None   \n",
       "312           0.001                relu   xavier_uniform_         l2_reg   \n",
       "118           0.001                relu  kaiming_uniform_           None   \n",
       "1204          0.001                relu   xavier_uniform_         l2_reg   \n",
       "62            0.001                relu              None         l2_reg   \n",
       "1205          0.001                relu   xavier_uniform_         l2_reg   \n",
       "44            0.001                relu              None         l2_reg   \n",
       "42            0.001                relu              None         l2_reg   \n",
       "92            0.001                relu              None           None   \n",
       "41            0.001                relu              None        dropout   \n",
       "40            0.001                relu              None        dropout   \n",
       "88            0.001                relu              None         l2_reg   \n",
       "1199          0.001                relu   xavier_uniform_           None   \n",
       "1198          0.001                relu   xavier_uniform_           None   \n",
       "1196          0.001                relu   xavier_uniform_         l2_reg   \n",
       "58            0.001                relu              None        dropout   \n",
       "1090          0.001                relu  kaiming_uniform_           None   \n",
       "1175          0.001                relu  kaiming_uniform_        dropout   \n",
       "1174          0.001                relu  kaiming_uniform_        dropout   \n",
       "1173          0.001                relu  kaiming_uniform_        dropout   \n",
       "1172          0.001                relu  kaiming_uniform_           None   \n",
       "1170          0.001                relu  kaiming_uniform_           None   \n",
       "1059          0.001                relu              None         l2_reg   \n",
       "59            0.001                relu              None        dropout   \n",
       "1060          0.001                relu              None         l2_reg   \n",
       "60            0.001                relu              None         l2_reg   \n",
       "61            0.001                relu              None         l2_reg   \n",
       "87            0.001                relu              None         l2_reg   \n",
       "1176          0.001                relu  kaiming_uniform_         l2_reg   \n",
       "281           0.001                relu   xavier_uniform_           None   \n",
       "1011          0.001                relu              None        dropout   \n",
       "584           0.001                relu   xavier_uniform_         l2_reg   \n",
       "578           0.001                relu   xavier_uniform_           None   \n",
       "579           0.001                relu   xavier_uniform_        dropout   \n",
       "580           0.001                relu   xavier_uniform_        dropout   \n",
       "581           0.001                relu   xavier_uniform_        dropout   \n",
       "582           0.001                relu   xavier_uniform_         l2_reg   \n",
       "583           0.001                relu   xavier_uniform_         l2_reg   \n",
       "597           0.001                relu   xavier_uniform_        dropout   \n",
       "576           0.001                relu   xavier_uniform_           None   \n",
       "598           0.001                relu   xavier_uniform_        dropout   \n",
       "600           0.001                relu   xavier_uniform_         l2_reg   \n",
       "601           0.001                relu   xavier_uniform_         l2_reg   \n",
       "602           0.001                relu   xavier_uniform_         l2_reg   \n",
       "604           0.001                relu   xavier_uniform_           None   \n",
       "605           0.001                relu   xavier_uniform_           None   \n",
       "577           0.001                relu   xavier_uniform_           None   \n",
       "575           0.001                relu   xavier_uniform_         l2_reg   \n",
       "688           0.001                relu              None        dropout   \n",
       "550           0.001                relu   xavier_uniform_           None   \n",
       "529           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "530           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "546           0.001                relu   xavier_uniform_         l2_reg   \n",
       "547           0.001                relu   xavier_uniform_         l2_reg   \n",
       "548           0.001                relu   xavier_uniform_         l2_reg   \n",
       "549           0.001                relu   xavier_uniform_           None   \n",
       "551           0.001                relu   xavier_uniform_           None   \n",
       "574           0.001                relu   xavier_uniform_         l2_reg   \n",
       "552           0.001                relu   xavier_uniform_        dropout   \n",
       "553           0.001                relu   xavier_uniform_        dropout   \n",
       "554           0.001                relu   xavier_uniform_        dropout   \n",
       "555           0.001                relu   xavier_uniform_         l2_reg   \n",
       "557           0.001                relu   xavier_uniform_         l2_reg   \n",
       "573           0.001                relu   xavier_uniform_         l2_reg   \n",
       "606           0.001                relu   xavier_uniform_        dropout   \n",
       "607           0.001                relu   xavier_uniform_        dropout   \n",
       "608           0.001                relu   xavier_uniform_        dropout   \n",
       "378           0.001                relu              None           None   \n",
       "656           0.001                relu              None         l2_reg   \n",
       "657           0.001                relu              None           None   \n",
       "658           0.001                relu              None           None   \n",
       "661           0.001                relu              None        dropout   \n",
       "662           0.001                relu              None        dropout   \n",
       "379           0.001                relu              None           None   \n",
       "260           0.001                relu   xavier_uniform_         l2_reg   \n",
       "609           0.001                relu   xavier_uniform_         l2_reg   \n",
       "258           0.001                relu   xavier_uniform_         l2_reg   \n",
       "681           0.001                relu              None         l2_reg   \n",
       "682           0.001                relu              None         l2_reg   \n",
       "683           0.001                relu              None         l2_reg   \n",
       "684           0.001                relu              None           None   \n",
       "686           0.001                relu              None           None   \n",
       "655           0.001                relu              None         l2_reg   \n",
       "654           0.001                relu              None         l2_reg   \n",
       "276           0.001                relu   xavier_uniform_         l2_reg   \n",
       "277           0.001                relu   xavier_uniform_         l2_reg   \n",
       "638           0.001                relu   xavier_uniform_         l2_reg   \n",
       "637           0.001                relu   xavier_uniform_         l2_reg   \n",
       "635           0.001                relu   xavier_uniform_        dropout   \n",
       "634           0.001                relu   xavier_uniform_        dropout   \n",
       "633           0.001                relu   xavier_uniform_        dropout   \n",
       "632           0.001                relu   xavier_uniform_           None   \n",
       "631           0.001                relu   xavier_uniform_           None   \n",
       "630           0.001                relu   xavier_uniform_           None   \n",
       "629           0.001                relu   xavier_uniform_         l2_reg   \n",
       "628           0.001                relu   xavier_uniform_         l2_reg   \n",
       "627           0.001                relu   xavier_uniform_         l2_reg   \n",
       "611           0.001                relu   xavier_uniform_         l2_reg   \n",
       "610           0.001                relu   xavier_uniform_         l2_reg   \n",
       "528           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "527           0.001                relu  kaiming_uniform_        dropout   \n",
       "526           0.001                relu  kaiming_uniform_        dropout   \n",
       "422           0.001                relu              None         l2_reg   \n",
       "416           0.001                relu              None           None   \n",
       "417           0.001                relu              None        dropout   \n",
       "418           0.001                relu              None        dropout   \n",
       "419           0.001                relu              None        dropout   \n",
       "420           0.001                relu              None         l2_reg   \n",
       "421           0.001                relu              None         l2_reg   \n",
       "435           0.001                relu  kaiming_uniform_        dropout   \n",
       "444           0.001                relu  kaiming_uniform_        dropout   \n",
       "436           0.001                relu  kaiming_uniform_        dropout   \n",
       "438           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "439           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "440           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "441           0.001                relu  kaiming_uniform_           None   \n",
       "442           0.001                relu  kaiming_uniform_           None   \n",
       "415           0.001                relu              None           None   \n",
       "414           0.001                relu              None           None   \n",
       "413           0.001                relu              None         l2_reg   \n",
       "412           0.001                relu              None         l2_reg   \n",
       "411           0.001                relu              None         l2_reg   \n",
       "395           0.001                relu              None         l2_reg   \n",
       "394           0.001                relu              None         l2_reg   \n",
       "393           0.001                relu              None         l2_reg   \n",
       "392           0.001                relu              None        dropout   \n",
       "391           0.001                relu              None        dropout   \n",
       "390           0.001                relu              None        dropout   \n",
       "388           0.001                relu              None           None   \n",
       "387           0.001                relu              None           None   \n",
       "386           0.001                relu              None         l2_reg   \n",
       "385           0.001                relu              None         l2_reg   \n",
       "384           0.001                relu              None         l2_reg   \n",
       "383           0.001                relu              None        dropout   \n",
       "443           0.001                relu  kaiming_uniform_           None   \n",
       "445           0.001                relu  kaiming_uniform_        dropout   \n",
       "525           0.001                relu  kaiming_uniform_        dropout   \n",
       "501           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "495           0.001                relu  kaiming_uniform_           None   \n",
       "496           0.001                relu  kaiming_uniform_           None   \n",
       "497           0.001                relu  kaiming_uniform_           None   \n",
       "498           0.001                relu  kaiming_uniform_        dropout   \n",
       "499           0.001                relu  kaiming_uniform_        dropout   \n",
       "500           0.001                relu  kaiming_uniform_        dropout   \n",
       "503           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "446           0.001                relu  kaiming_uniform_        dropout   \n",
       "519           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "520           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "521           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "522           0.001                relu  kaiming_uniform_           None   \n",
       "523           0.001                relu  kaiming_uniform_           None   \n",
       "524           0.001                relu  kaiming_uniform_           None   \n",
       "494           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "493           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "492           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "476           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "475           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "474           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "473           0.001                relu  kaiming_uniform_        dropout   \n",
       "472           0.001                relu  kaiming_uniform_        dropout   \n",
       "471           0.001                relu  kaiming_uniform_        dropout   \n",
       "469           0.001                relu  kaiming_uniform_           None   \n",
       "468           0.001                relu  kaiming_uniform_           None   \n",
       "467           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "466           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "465           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "449           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "448           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "447           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "1009          0.001                relu              None           None   \n",
       "687           0.001                relu              None        dropout   \n",
       "689           0.001                relu              None        dropout   \n",
       "171           0.001                relu  kaiming_uniform_           None   \n",
       "173           0.001                relu  kaiming_uniform_           None   \n",
       "900           0.001                relu   xavier_uniform_           None   \n",
       "901           0.001                relu   xavier_uniform_           None   \n",
       "903           0.001                relu   xavier_uniform_        dropout   \n",
       "905           0.001                relu   xavier_uniform_        dropout   \n",
       "172           0.001                relu  kaiming_uniform_           None   \n",
       "338           0.001                relu              None        dropout   \n",
       "177           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "923           0.001                relu   xavier_uniform_        dropout   \n",
       "924           0.001                relu   xavier_uniform_         l2_reg   \n",
       "925           0.001                relu   xavier_uniform_         l2_reg   \n",
       "926           0.001                relu   xavier_uniform_         l2_reg   \n",
       "337           0.001                relu              None        dropout   \n",
       "929           0.001                relu   xavier_uniform_           None   \n",
       "175           0.001                relu  kaiming_uniform_        dropout   \n",
       "178           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "690           0.001                relu              None         l2_reg   \n",
       "872           0.001                relu   xavier_uniform_         l2_reg   \n",
       "849           0.001                relu  kaiming_uniform_        dropout   \n",
       "850           0.001                relu  kaiming_uniform_        dropout   \n",
       "851           0.001                relu  kaiming_uniform_        dropout   \n",
       "852           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "853           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "870           0.001                relu   xavier_uniform_         l2_reg   \n",
       "873           0.001                relu   xavier_uniform_           None   \n",
       "179           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "875           0.001                relu   xavier_uniform_           None   \n",
       "876           0.001                relu   xavier_uniform_        dropout   \n",
       "877           0.001                relu   xavier_uniform_        dropout   \n",
       "878           0.001                relu   xavier_uniform_        dropout   \n",
       "880           0.001                relu   xavier_uniform_         l2_reg   \n",
       "881           0.001                relu   xavier_uniform_         l2_reg   \n",
       "930           0.001                relu   xavier_uniform_        dropout   \n",
       "933           0.001                relu   xavier_uniform_         l2_reg   \n",
       "336           0.001                relu              None        dropout   \n",
       "144           0.001                relu  kaiming_uniform_           None   \n",
       "986           0.001                relu              None        dropout   \n",
       "150           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "331           0.001                relu              None         l2_reg   \n",
       "149           0.001                relu  kaiming_uniform_        dropout   \n",
       "148           0.001                relu  kaiming_uniform_        dropout   \n",
       "146           0.001                relu  kaiming_uniform_           None   \n",
       "330           0.001                relu              None         l2_reg   \n",
       "335           0.001                relu              None           None   \n",
       "329           0.001                relu              None        dropout   \n",
       "328           0.001                relu              None        dropout   \n",
       "1005          0.001                relu              None         l2_reg   \n",
       "1006          0.001                relu              None         l2_reg   \n",
       "1007          0.001                relu              None         l2_reg   \n",
       "1008          0.001                relu              None           None   \n",
       "985           0.001                relu              None        dropout   \n",
       "151           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "980           0.001                relu              None         l2_reg   \n",
       "979           0.001                relu              None         l2_reg   \n",
       "332           0.001                relu              None         l2_reg   \n",
       "962           0.001                relu   xavier_uniform_         l2_reg   \n",
       "961           0.001                relu   xavier_uniform_         l2_reg   \n",
       "960           0.001                relu   xavier_uniform_         l2_reg   \n",
       "959           0.001                relu   xavier_uniform_        dropout   \n",
       "957           0.001                relu   xavier_uniform_        dropout   \n",
       "956           0.001                relu   xavier_uniform_           None   \n",
       "955           0.001                relu   xavier_uniform_           None   \n",
       "954           0.001                relu   xavier_uniform_           None   \n",
       "953           0.001                relu   xavier_uniform_         l2_reg   \n",
       "952           0.001                relu   xavier_uniform_         l2_reg   \n",
       "951           0.001                relu   xavier_uniform_         l2_reg   \n",
       "334           0.001                relu              None           None   \n",
       "848           0.001                relu  kaiming_uniform_           None   \n",
       "846           0.001                relu  kaiming_uniform_           None   \n",
       "199           0.001                relu  kaiming_uniform_           None   \n",
       "765           0.001                relu  kaiming_uniform_           None   \n",
       "200           0.001                relu  kaiming_uniform_           None   \n",
       "228           0.001                relu   xavier_uniform_        dropout   \n",
       "368           0.001                relu              None         l2_reg   \n",
       "229           0.001                relu   xavier_uniform_        dropout   \n",
       "231           0.001                relu   xavier_uniform_         l2_reg   \n",
       "746           0.001                relu              None         l2_reg   \n",
       "745           0.001                relu              None         l2_reg   \n",
       "744           0.001                relu              None         l2_reg   \n",
       "743           0.001                relu              None        dropout   \n",
       "742           0.001                relu              None        dropout   \n",
       "741           0.001                relu              None        dropout   \n",
       "740           0.001                relu              None           None   \n",
       "737           0.001                relu              None         l2_reg   \n",
       "736           0.001                relu              None         l2_reg   \n",
       "735           0.001                relu              None         l2_reg   \n",
       "249           0.001                relu   xavier_uniform_         l2_reg   \n",
       "717           0.001                relu              None         l2_reg   \n",
       "716           0.001                relu              None        dropout   \n",
       "715           0.001                relu              None        dropout   \n",
       "714           0.001                relu              None        dropout   \n",
       "710           0.001                relu              None         l2_reg   \n",
       "709           0.001                relu              None         l2_reg   \n",
       "708           0.001                relu              None         l2_reg   \n",
       "252           0.001                relu   xavier_uniform_           None   \n",
       "254           0.001                relu   xavier_uniform_           None   \n",
       "255           0.001                relu   xavier_uniform_        dropout   \n",
       "256           0.001                relu   xavier_uniform_        dropout   \n",
       "257           0.001                relu   xavier_uniform_        dropout   \n",
       "691           0.001                relu              None         l2_reg   \n",
       "764           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "227           0.001                relu   xavier_uniform_           None   \n",
       "766           0.001                relu  kaiming_uniform_           None   \n",
       "357           0.001                relu              None         l2_reg   \n",
       "796           0.001                relu  kaiming_uniform_        dropout   \n",
       "797           0.001                relu  kaiming_uniform_        dropout   \n",
       "800           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "360           0.001                relu              None           None   \n",
       "359           0.001                relu              None         l2_reg   \n",
       "358           0.001                relu              None         l2_reg   \n",
       "204           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "361           0.001                relu              None           None   \n",
       "821           0.001                relu  kaiming_uniform_           None   \n",
       "823           0.001                relu  kaiming_uniform_        dropout   \n",
       "824           0.001                relu  kaiming_uniform_        dropout   \n",
       "203           0.001                relu  kaiming_uniform_        dropout   \n",
       "827           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "201           0.001                relu  kaiming_uniform_        dropout   \n",
       "768           0.001                relu  kaiming_uniform_        dropout   \n",
       "795           0.001                relu  kaiming_uniform_        dropout   \n",
       "282           0.001                relu   xavier_uniform_        dropout   \n",
       "364           0.001                relu              None        dropout   \n",
       "226           0.001                relu   xavier_uniform_           None   \n",
       "772           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "773           0.001                relu  kaiming_uniform_         l2_reg   \n",
       "367           0.001                relu              None         l2_reg   \n",
       "366           0.001                relu              None         l2_reg   \n",
       "365           0.001                relu              None        dropout   \n",
       "225           0.001                relu   xavier_uniform_           None   \n",
       "224           0.001                relu   xavier_uniform_         l2_reg   \n",
       "363           0.001                relu              None        dropout   \n",
       "362           0.001                relu              None           None   \n",
       "232           0.001                relu   xavier_uniform_         l2_reg   \n",
       "1171          0.001                relu  kaiming_uniform_           None   \n",
       "202           0.001                relu  kaiming_uniform_        dropout   \n",
       "1148          0.001                relu  kaiming_uniform_        dropout   \n",
       "636           0.001                relu   xavier_uniform_         l2_reg   \n",
       "822           0.001                relu  kaiming_uniform_        dropout   \n",
       "1040          0.001                relu              None        dropout   \n",
       "\n",
       "     Normalization      Scheduler  F1-train  F1-val  F1-test  \n",
       "1055          None    MultiStepLR    0.7235  0.6919   0.6974  \n",
       "1082          None    MultiStepLR    0.7027  0.6914   0.6192  \n",
       "1054          None  ExponentialLR    0.7314  0.6914   0.6000  \n",
       "1028          None    MultiStepLR    0.7007  0.6907   0.6406  \n",
       "1189          None  ExponentialLR    0.7100  0.6895   0.6800  \n",
       "1109          None    MultiStepLR    0.7139  0.6890   0.6805  \n",
       "1053          None           None    0.7331  0.6883   0.5314  \n",
       "999           None           None    0.7089  0.6880   0.6800  \n",
       "1271          None    MultiStepLR    0.7507  0.6878   0.6784  \n",
       "972           None           None    0.6954  0.6874   0.6006  \n",
       "1000          None  ExponentialLR    0.6966  0.6870   0.6006  \n",
       "1080          None           None    0.7134  0.6869   0.6192  \n",
       "1188          None           None    0.7122  0.6868   0.6205  \n",
       "1136          None    MultiStepLR    0.7358  0.6866   0.5792  \n",
       "1272          None           None    0.5666  0.6865   0.5805  \n",
       "973           None  ExponentialLR    0.7015  0.6863   0.6192  \n",
       "1058          None    MultiStepLR    0.5676  0.6860   0.6129  \n",
       "1026          None           None    0.7001  0.6860   0.6406  \n",
       "1274          None    MultiStepLR    0.5762  0.6858   0.5792  \n",
       "1002          None           None    0.5754  0.6857   0.5579  \n",
       "982      LayerNorm  ExponentialLR    0.7146  0.6856   0.6382  \n",
       "1249          None  ExponentialLR    0.6816  0.6854   0.6006  \n",
       "1168          None  ExponentialLR    0.6815  0.6854   0.6006  \n",
       "1222          None  ExponentialLR    0.6810  0.6846   0.6006  \n",
       "1141          None  ExponentialLR    0.6812  0.6846   0.6006  \n",
       "1166          None    MultiStepLR    0.5743  0.6846   0.5391  \n",
       "1108          None  ExponentialLR    0.7174  0.6839   0.6406  \n",
       "1114          None  ExponentialLR    0.6817  0.6839   0.6006  \n",
       "1135          None  ExponentialLR    0.7507  0.6836   0.6205  \n",
       "1142          None    MultiStepLR    0.6764  0.6835   0.6006  \n",
       "1242          None           None    0.7423  0.6834   0.6353  \n",
       "1169          None    MultiStepLR    0.6775  0.6833   0.6006  \n",
       "1215          None           None    0.7174  0.6833   0.7186  \n",
       "1140          None           None    0.6751  0.6832   0.6006  \n",
       "974           None    MultiStepLR    0.6941  0.6831   0.6192  \n",
       "1273          None  ExponentialLR    0.5592  0.6831   0.6353  \n",
       "1003          None  ExponentialLR    0.5797  0.6829   0.6382  \n",
       "1084          None  ExponentialLR    0.5743  0.6826   0.5805  \n",
       "1195          None  ExponentialLR    0.6799  0.6826   0.6000  \n",
       "1248          None           None    0.6744  0.6825   0.6205  \n",
       "1165          None  ExponentialLR    0.5649  0.6824   0.5981  \n",
       "1190          None    MultiStepLR    0.7111  0.6816   0.5764  \n",
       "1243          None  ExponentialLR    0.7269  0.6814   0.6000  \n",
       "1275          None           None    0.6743  0.6814   0.6192  \n",
       "1216          None  ExponentialLR    0.7101  0.6813   0.6400  \n",
       "1162          None  ExponentialLR    0.7604  0.6812   0.6167  \n",
       "1134          None           None    0.7460  0.6810   0.5792  \n",
       "1115          None    MultiStepLR    0.6767  0.6810   0.5805  \n",
       "1192          None  ExponentialLR    0.5795  0.6809   0.6000  \n",
       "1088          None    MultiStepLR    0.6771  0.6809   0.5805  \n",
       "1087          None  ExponentialLR    0.6804  0.6809   0.6006  \n",
       "1081          None  ExponentialLR    0.7018  0.6803   0.6000  \n",
       "1270          None  ExponentialLR    0.7575  0.6801   0.6192  \n",
       "1167          None           None    0.6731  0.6801   0.6192  \n",
       "1113          None           None    0.6761  0.6799   0.6006  \n",
       "1194          None           None    0.6707  0.6799   0.6205  \n",
       "1221          None           None    0.6762  0.6796   0.5805  \n",
       "978           None           None    0.6735  0.6793   0.5805  \n",
       "1086          None           None    0.6746  0.6791   0.6006  \n",
       "1107          None           None    0.7192  0.6790   0.6205  \n",
       "1193          None    MultiStepLR    0.5762  0.6788   0.6000  \n",
       "1247          None    MultiStepLR    0.5613  0.6784   0.6205  \n",
       "676           None  ExponentialLR    0.6983  0.6781   0.6382  \n",
       "1246          None  ExponentialLR    0.5670  0.6781   0.6205  \n",
       "1131   BatchNorm1d           None    0.7434  0.6780   0.5579  \n",
       "1001          None    MultiStepLR    0.7149  0.6780   0.6400  \n",
       "1219          None  ExponentialLR    0.5887  0.6778   0.6400  \n",
       "729           None           None    0.7519  0.6778   0.7004  \n",
       "976           None  ExponentialLR    0.5745  0.6774   0.5579  \n",
       "1220          None    MultiStepLR    0.5796  0.6774   0.5764  \n",
       "1004          None    MultiStepLR    0.5819  0.6770   0.6903  \n",
       "1150     LayerNorm  ExponentialLR    0.6996  0.6762   0.5664  \n",
       "1111          None  ExponentialLR    0.5878  0.6762   0.6784  \n",
       "1037     LayerNorm    MultiStepLR    0.7394  0.6758   0.5805  \n",
       "702           None           None    0.7051  0.6755   0.6800  \n",
       "675           None           None    0.6964  0.6754   0.6400  \n",
       "1218          None           None    0.5802  0.6754   0.5981  \n",
       "892           None  ExponentialLR    0.7183  0.6752   0.7186  \n",
       "949           None  ExponentialLR    0.5673  0.6752   0.6994  \n",
       "677           None    MultiStepLR    0.7195  0.6752   0.6800  \n",
       "704           None    MultiStepLR    0.6987  0.6752   0.6593  \n",
       "757           None  ExponentialLR    0.7217  0.6751   0.6537  \n",
       "1110          None           None    0.5886  0.6749   0.5251  \n",
       "1244          None    MultiStepLR    0.7432  0.6747   0.6192  \n",
       "759           None           None    0.5721  0.6747   0.6490  \n",
       "866           None    MultiStepLR    0.7207  0.6743   0.6604  \n",
       "871           None  ExponentialLR    0.6783  0.6742   0.7352  \n",
       "1056          None           None    0.5620  0.6742   0.5490  \n",
       "893           None    MultiStepLR    0.7259  0.6742   0.6593  \n",
       "712      LayerNorm  ExponentialLR    0.7702  0.6742   0.7588  \n",
       "891           None           None    0.7395  0.6738   0.6400  \n",
       "790           None  ExponentialLR    0.6773  0.6738   0.7378  \n",
       "811           None  ExponentialLR    0.7377  0.6737   0.6205  \n",
       "650           None    MultiStepLR    0.6909  0.6736   0.7130  \n",
       "732           None           None    0.5717  0.6734   0.6974  \n",
       "983      LayerNorm    MultiStepLR    0.6879  0.6732   0.6205  \n",
       "763           None  ExponentialLR    0.6740  0.6729   0.7352  \n",
       "703           None  ExponentialLR    0.6974  0.6728   0.6758  \n",
       "783           None           None    0.7360  0.6728   0.7004  \n",
       "1161          None           None    0.7800  0.6727   0.5792  \n",
       "653           None    MultiStepLR    0.5807  0.6725   0.6784  \n",
       "1017   BatchNorm1d           None    0.7719  0.6724   0.6994  \n",
       "648           None           None    0.6954  0.6724   0.7186  \n",
       "898           None  ExponentialLR    0.6776  0.6723   0.7352  \n",
       "1239   BatchNorm1d           None    0.7452  0.6722   0.5792  \n",
       "1030          None  ExponentialLR    0.5647  0.6720   0.5947  \n",
       "758           None    MultiStepLR    0.7159  0.6720   0.6758  \n",
       "649           None  ExponentialLR    0.6979  0.6718   0.6944  \n",
       "818           None    MultiStepLR    0.6747  0.6718   0.7186  \n",
       "1191          None           None    0.5878  0.6718   0.6000  \n",
       "867           None           None    0.5842  0.6718   0.7352  \n",
       "785           None    MultiStepLR    0.7258  0.6718   0.6382  \n",
       "1104   BatchNorm1d           None    0.7397  0.6718   0.6205  \n",
       "945           None           None    0.7772  0.6717   0.7378  \n",
       "844           None  ExponentialLR    0.6796  0.6715   0.7378  \n",
       "1217          None    MultiStepLR    0.7201  0.6715   0.5361  \n",
       "840           None           None    0.5768  0.6713   0.6720  \n",
       "996    BatchNorm1d           None    0.7405  0.6712   0.6800  \n",
       "899           None    MultiStepLR    0.6753  0.6710   0.7378  \n",
       "977           None    MultiStepLR    0.5816  0.6709   0.5900  \n",
       "817           None  ExponentialLR    0.6744  0.6708   0.7163  \n",
       "865           None  ExponentialLR    0.7031  0.6705   0.6167  \n",
       "1163          None    MultiStepLR    0.7729  0.6705   0.7004  \n",
       "752    BatchNorm1d    MultiStepLR    0.5821  0.6704   0.6537  \n",
       "841           None  ExponentialLR    0.5671  0.6703   0.7130  \n",
       "679           None  ExponentialLR    0.5834  0.6702   0.6903  \n",
       "787           None  ExponentialLR    0.5854  0.6701   0.6490  \n",
       "1029          None           None    0.5599  0.6701   0.5947  \n",
       "784           None  ExponentialLR    0.7079  0.6700   0.7186  \n",
       "997    BatchNorm1d  ExponentialLR    0.7578  0.6697   0.5208  \n",
       "762           None           None    0.6748  0.6696   0.7378  \n",
       "843           None           None    0.6731  0.6695   0.7200  \n",
       "680           None    MultiStepLR    0.5781  0.6693   0.6974  \n",
       "868           None  ExponentialLR    0.5735  0.6692   0.6784  \n",
       "845           None    MultiStepLR    0.6746  0.6691   0.6994  \n",
       "864           None           None    0.7297  0.6690   0.7204  \n",
       "731           None    MultiStepLR    0.7426  0.6687   0.6400  \n",
       "791           None    MultiStepLR    0.6752  0.6687   0.7378  \n",
       "919           None  ExponentialLR    0.7554  0.6685   0.6994  \n",
       "920           None    MultiStepLR    0.7538  0.6682   0.7200  \n",
       "651           None           None    0.5794  0.6682   0.7163  \n",
       "789           None           None    0.6731  0.6678   0.7186  \n",
       "664      LayerNorm  ExponentialLR    0.7389  0.6677   0.6077  \n",
       "897           None           None    0.6717  0.6676   0.7186  \n",
       "810           None           None    0.7646  0.6676   0.6205  \n",
       "922           None  ExponentialLR    0.5651  0.6674   0.6537  \n",
       "993    BatchNorm1d           None    0.5855  0.6672   0.6758  \n",
       "786           None           None    0.5910  0.6668   0.7378  \n",
       "816           None           None    0.6707  0.6666   0.6994  \n",
       "756           None           None    0.7269  0.6666   0.6800  \n",
       "652           None  ExponentialLR    0.5660  0.6665   0.6994  \n",
       "894           None           None    0.5872  0.6663   0.6944  \n",
       "730           None  ExponentialLR    0.7385  0.6663   0.6400  \n",
       "1206   BatchNorm1d           None    0.7573  0.6663   0.5947  \n",
       "869           None    MultiStepLR    0.5831  0.6660   0.6720  \n",
       "896           None    MultiStepLR    0.5825  0.6660   0.5664  \n",
       "760           None  ExponentialLR    0.5814  0.6657   0.6784  \n",
       "719      LayerNorm    MultiStepLR    0.7217  0.6656   0.7200  \n",
       "27            None           None    0.6837  0.6654   0.6406  \n",
       "1269          None           None    0.7646  0.6654   0.6537  \n",
       "665      LayerNorm    MultiStepLR    0.7003  0.6653   0.6406  \n",
       "301           None  ExponentialLR    0.5640  0.6653   0.7163  \n",
       "842           None    MultiStepLR    0.5728  0.6650   0.6382  \n",
       "244           None  ExponentialLR    0.6986  0.6649   0.6604  \n",
       "1105   BatchNorm1d  ExponentialLR    0.7683  0.6649   0.5805  \n",
       "1212   BatchNorm1d           None    0.7298  0.6649   0.6353  \n",
       "1112          None    MultiStepLR    0.5824  0.6647   0.5900  \n",
       "110           None    MultiStepLR    0.6909  0.6646   0.6994  \n",
       "895           None  ExponentialLR    0.5816  0.6646   0.7316  \n",
       "918           None           None    0.7579  0.6645   0.7395  \n",
       "812           None    MultiStepLR    0.7637  0.6645   0.6805  \n",
       "1238   BatchNorm1d    MultiStepLR    0.5873  0.6644   0.7568  \n",
       "981      LayerNorm           None    0.7094  0.6644   0.6168  \n",
       "1130   BatchNorm1d    MultiStepLR    0.5951  0.6644   0.6571  \n",
       "788           None    MultiStepLR    0.5845  0.6643   0.6593  \n",
       "1159   BatchNorm1d  ExponentialLR    0.7888  0.6642   0.5792  \n",
       "1020   BatchNorm1d           None    0.5941  0.6641   0.6167  \n",
       "54            None           None    0.7041  0.6640   0.6205  \n",
       "994    BatchNorm1d  ExponentialLR    0.5817  0.6639   0.5900  \n",
       "879      LayerNorm           None    0.7009  0.6639   0.6310  \n",
       "83            None    MultiStepLR    0.7036  0.6636   0.6805  \n",
       "1046   BatchNorm1d    MultiStepLR    0.7935  0.6636   0.6994  \n",
       "1022   BatchNorm1d    MultiStepLR    0.5884  0.6636   0.5722  \n",
       "136           None  ExponentialLR    0.6934  0.6635   0.6800  \n",
       "1076   BatchNorm1d    MultiStepLR    0.5808  0.6634   0.6383  \n",
       "697    BatchNorm1d  ExponentialLR    0.5957  0.6633   0.6593  \n",
       "950           None    MultiStepLR    0.5659  0.6633   0.6429  \n",
       "1234   BatchNorm1d  ExponentialLR    0.7611  0.6631   0.6006  \n",
       "707           None    MultiStepLR    0.5594  0.6630   0.6903  \n",
       "243           None           None    0.7041  0.6628   0.6994  \n",
       "948           None           None    0.5810  0.6627   0.7568  \n",
       "1047   BatchNorm1d           None    0.5729  0.6627   0.6670  \n",
       "1051   BatchNorm1d  ExponentialLR    0.8087  0.6627   0.6382  \n",
       "825      LayerNorm           None    0.7105  0.6624   0.6670  \n",
       "696    BatchNorm1d           None    0.5929  0.6623   0.6758  \n",
       "17       LayerNorm    MultiStepLR    0.6763  0.6622   0.6205  \n",
       "1101   BatchNorm1d           None    0.5865  0.6622   0.6490  \n",
       "1267   BatchNorm1d  ExponentialLR    0.8082  0.6622   0.6006  \n",
       "108           None           None    0.6933  0.6622   0.7200  \n",
       "734           None    MultiStepLR    0.5712  0.6621   0.6849  \n",
       "2             None    MultiStepLR    0.6858  0.6619   0.6805  \n",
       "135           None           None    0.7045  0.6619   0.6800  \n",
       "1185   BatchNorm1d           None    0.7712  0.6619   0.5805  \n",
       "1290   BatchNorm1d           None    0.5780  0.6616   0.6800  \n",
       "28            None  ExponentialLR    0.6824  0.6616   0.6994  \n",
       "726    BatchNorm1d           None    0.7509  0.6615   0.6000  \n",
       "137           None    MultiStepLR    0.7058  0.6614   0.7004  \n",
       "946           None  ExponentialLR    0.7716  0.6613   0.6192  \n",
       "1025   BatchNorm1d    MultiStepLR    0.7550  0.6613   0.6205  \n",
       "218           None    MultiStepLR    0.6912  0.6613   0.6205  \n",
       "998    BatchNorm1d    MultiStepLR    0.7579  0.6613   0.6974  \n",
       "1044   BatchNorm1d           None    0.7967  0.6609   0.6406  \n",
       "82            None  ExponentialLR    0.7241  0.6609   0.7004  \n",
       "992    BatchNorm1d    MultiStepLR    0.7519  0.6607   0.6167  \n",
       "1023   BatchNorm1d           None    0.7487  0.6607   0.6805  \n",
       "29            None    MultiStepLR    0.6827  0.6606   0.6604  \n",
       "750    BatchNorm1d           None    0.5698  0.6606   0.6800  \n",
       "995    BatchNorm1d    MultiStepLR    0.5945  0.6605   0.6000  \n",
       "968    BatchNorm1d    MultiStepLR    0.5753  0.6603   0.7378  \n",
       "298           None  ExponentialLR    0.7353  0.6603   0.6800  \n",
       "678           None           None    0.5806  0.6602   0.6849  \n",
       "1164          None           None    0.5633  0.6601   0.6490  \n",
       "802    BatchNorm1d  ExponentialLR    0.7572  0.6601   0.6400  \n",
       "217           None  ExponentialLR    0.6918  0.6601   0.6604  \n",
       "1202     LayerNorm    MultiStepLR    0.5536  0.6600   0.5792  \n",
       "271           None  ExponentialLR    0.7141  0.6599   0.7004  \n",
       "659      LayerNorm    MultiStepLR    0.7305  0.6599   0.6604  \n",
       "163           None  ExponentialLR    0.6913  0.6599   0.6382  \n",
       "1208   BatchNorm1d    MultiStepLR    0.7415  0.6599   0.6006  \n",
       "838           None  ExponentialLR    0.7773  0.6599   0.7004  \n",
       "883    BatchNorm1d  ExponentialLR    0.7437  0.6598   0.7200  \n",
       "915    BatchNorm1d           None    0.7333  0.6598   0.6400  \n",
       "670    BatchNorm1d  ExponentialLR    0.5851  0.6597   0.5837  \n",
       "216           None           None    0.6997  0.6597   0.6604  \n",
       "1             None  ExponentialLR    0.6847  0.6597   0.6604  \n",
       "245           None    MultiStepLR    0.7050  0.6596   0.6382  \n",
       "1268   BatchNorm1d    MultiStepLR    0.7906  0.6595   0.5600  \n",
       "1207   BatchNorm1d  ExponentialLR    0.7401  0.6594   0.6670  \n",
       "858    BatchNorm1d           None    0.5734  0.6594   0.6784  \n",
       "839           None    MultiStepLR    0.7892  0.6592   0.5792  \n",
       "988      LayerNorm  ExponentialLR    0.7016  0.6592   0.5764  \n",
       "1098   BatchNorm1d           None    0.7536  0.6591   0.6593  \n",
       "55            None  ExponentialLR    0.6931  0.6591   0.6192  \n",
       "1103   BatchNorm1d    MultiStepLR    0.5882  0.6590   0.6205  \n",
       "111           None           None    0.5744  0.6590   0.7004  \n",
       "1075   BatchNorm1d  ExponentialLR    0.5934  0.6589   0.6353  \n",
       "1145     LayerNorm    MultiStepLR    0.7345  0.6589   0.5924  \n",
       "672    BatchNorm1d           None    0.7176  0.6589   0.6400  \n",
       "274           None  ExponentialLR    0.5653  0.6588   0.7004  \n",
       "1050   BatchNorm1d           None    0.7472  0.6587   0.6805  \n",
       "1236   BatchNorm1d           None    0.5946  0.6587   0.6571  \n",
       "1074   BatchNorm1d           None    0.5844  0.6587   0.6537  \n",
       "1293   BatchNorm1d           None    0.7752  0.6587   0.5208  \n",
       "1213   BatchNorm1d  ExponentialLR    0.7701  0.6586   0.5406  \n",
       "1021   BatchNorm1d  ExponentialLR    0.5986  0.6585   0.6784  \n",
       "733           None  ExponentialLR    0.5689  0.6585   0.6849  \n",
       "56            None    MultiStepLR    0.6897  0.6584   0.6994  \n",
       "991    BatchNorm1d  ExponentialLR    0.7650  0.6584   0.5805  \n",
       "1100   BatchNorm1d    MultiStepLR    0.7405  0.6583   0.6604  \n",
       "273           None           None    0.5562  0.6583   0.7004  \n",
       "21     BatchNorm1d           None    0.5813  0.6582   0.6805  \n",
       "246           None           None    0.5735  0.6582   0.6784  \n",
       "233      LayerNorm    MultiStepLR    0.6667  0.6581   0.6800  \n",
       "771      LayerNorm           None    0.6951  0.6581   0.6604  \n",
       "706           None  ExponentialLR    0.5570  0.6580   0.7030  \n",
       "882    BatchNorm1d           None    0.7415  0.6580   0.7204  \n",
       "807    BatchNorm1d           None    0.7315  0.6577   0.7568  \n",
       "813           None           None    0.5476  0.6576   0.6994  \n",
       "885    BatchNorm1d           None    0.5948  0.6576   0.7378  \n",
       "1291   BatchNorm1d  ExponentialLR    0.5812  0.6574   0.6944  \n",
       "1152   BatchNorm1d           None    0.7974  0.6572   0.6353  \n",
       "1266   BatchNorm1d           None    0.7613  0.6571   0.6593  \n",
       "1127   BatchNorm1d    MultiStepLR    0.7539  0.6571   0.6205  \n",
       "751    BatchNorm1d  ExponentialLR    0.5882  0.6570   0.5757  \n",
       "669    BatchNorm1d           None    0.5814  0.6569   0.6800  \n",
       "1214   BatchNorm1d    MultiStepLR    0.7507  0.6569   0.6593  \n",
       "804    BatchNorm1d           None    0.5905  0.6568   0.6782  \n",
       "190           None  ExponentialLR    0.7420  0.6568   0.7204  \n",
       "1052   BatchNorm1d    MultiStepLR    0.7821  0.6567   0.5764  \n",
       "913    BatchNorm1d  ExponentialLR    0.5885  0.6567   0.7130  \n",
       "0             None           None    0.6870  0.6564   0.6805  \n",
       "1133   BatchNorm1d    MultiStepLR    0.7572  0.6563   0.6994  \n",
       "195           None           None    0.6536  0.6563   0.6800  \n",
       "189           None           None    0.7434  0.6563   0.6800  \n",
       "914    BatchNorm1d    MultiStepLR    0.5890  0.6563   0.6720  \n",
       "63       LayerNorm           None    0.7061  0.6563   0.6758  \n",
       "705           None           None    0.5664  0.6562   0.6670  \n",
       "162           None           None    0.7338  0.6562   0.6800  \n",
       "81            None           None    0.7124  0.6562   0.6604  \n",
       "718      LayerNorm  ExponentialLR    0.7287  0.6561   0.6353  \n",
       "1106   BatchNorm1d    MultiStepLR    0.7491  0.6561   0.6000  \n",
       "1024   BatchNorm1d  ExponentialLR    0.7754  0.6560   0.6406  \n",
       "1295   BatchNorm1d    MultiStepLR    0.7865  0.6559   0.5391  \n",
       "164           None    MultiStepLR    0.7235  0.6558   0.6593  \n",
       "1128   BatchNorm1d           None    0.5890  0.6558   0.6077  \n",
       "826      LayerNorm  ExponentialLR    0.7124  0.6557   0.6604  \n",
       "84            None           None    0.5569  0.6557   0.6944  \n",
       "666    BatchNorm1d           None    0.7491  0.6557   0.6800  \n",
       "196           None  ExponentialLR    0.6641  0.6555   0.6994  \n",
       "910    BatchNorm1d  ExponentialLR    0.7503  0.6554   0.6253  \n",
       "1057          None  ExponentialLR    0.5687  0.6554   0.5757  \n",
       "170           None    MultiStepLR    0.6584  0.6553   0.6800  \n",
       "699    BatchNorm1d           None    0.7416  0.6553   0.6571  \n",
       "917    BatchNorm1d    MultiStepLR    0.7514  0.6553   0.7186  \n",
       "1077   BatchNorm1d           None    0.7749  0.6553   0.5981  \n",
       "947           None    MultiStepLR    0.7771  0.6552   0.5391  \n",
       "3             None           None    0.5617  0.6552   0.6785  \n",
       "251           None    MultiStepLR    0.6574  0.6551   0.6800  \n",
       "1264   BatchNorm1d  ExponentialLR    0.5773  0.6551   0.5757  \n",
       "140           None    MultiStepLR    0.5764  0.6551   0.6974  \n",
       "780    BatchNorm1d           None    0.7302  0.6550   0.7186  \n",
       "1019   BatchNorm1d    MultiStepLR    0.7692  0.6550   0.5947  \n",
       "874      LayerNorm  ExponentialLR    0.7169  0.6549   0.6784  \n",
       "966    BatchNorm1d           None    0.5699  0.6549   0.5792  \n",
       "1241   BatchNorm1d    MultiStepLR    0.7491  0.6548   0.5764  \n",
       "1132   BatchNorm1d  ExponentialLR    0.7674  0.6548   0.6604  \n",
       "109           None  ExponentialLR    0.6896  0.6548   0.7186  \n",
       "1125   BatchNorm1d           None    0.7545  0.6548   0.6490  \n",
       "831    BatchNorm1d           None    0.5870  0.6547   0.6903  \n",
       "143           None    MultiStepLR    0.6572  0.6547   0.6800  \n",
       "711      LayerNorm           None    0.7383  0.6546   0.6670  \n",
       "197           None    MultiStepLR    0.6560  0.6545   0.6800  \n",
       "16       LayerNorm  ExponentialLR    0.7072  0.6545   0.6604  \n",
       "671    BatchNorm1d    MultiStepLR    0.5883  0.6544   0.6903  \n",
       "805    BatchNorm1d  ExponentialLR    0.5864  0.6542   0.7352  \n",
       "1160   BatchNorm1d    MultiStepLR    0.7662  0.6542   0.6758  \n",
       "815           None    MultiStepLR    0.5701  0.6541   0.6849  \n",
       "222           None           None    0.6541  0.6539   0.6800  \n",
       "1155   BatchNorm1d           None    0.5633  0.6539   0.6129  \n",
       "1126   BatchNorm1d  ExponentialLR    0.7599  0.6537   0.6192  \n",
       "1211   BatchNorm1d    MultiStepLR    0.5833  0.6537   0.5947  \n",
       "1018   BatchNorm1d  ExponentialLR    0.7782  0.6535   0.5406  \n",
       "1237   BatchNorm1d  ExponentialLR    0.5944  0.6535   0.7204  \n",
       "1210   BatchNorm1d  ExponentialLR    0.5838  0.6535   0.6784  \n",
       "141           None           None    0.6551  0.6535   0.6800  \n",
       "1043     LayerNorm    MultiStepLR    0.7109  0.6534   0.5900  \n",
       "299           None    MultiStepLR    0.7515  0.6533   0.6800  \n",
       "169           None  ExponentialLR    0.6641  0.6533   0.6994  \n",
       "278           None    MultiStepLR    0.6575  0.6533   0.6800  \n",
       "1158   BatchNorm1d           None    0.7546  0.6531   0.6974  \n",
       "1129   BatchNorm1d  ExponentialLR    0.5940  0.6531   0.5542  \n",
       "761           None    MultiStepLR    0.5747  0.6530   0.6400  \n",
       "221           None    MultiStepLR    0.5797  0.6530   0.6784  \n",
       "193           None  ExponentialLR    0.5608  0.6529   0.7378  \n",
       "219           None           None    0.5689  0.6529   0.7004  \n",
       "837           None           None    0.7909  0.6528   0.5805  \n",
       "57            None           None    0.5510  0.6528   0.6604  \n",
       "755    BatchNorm1d    MultiStepLR    0.7937  0.6528   0.5792  \n",
       "116           None    MultiStepLR    0.6565  0.6528   0.6800  \n",
       "31            None  ExponentialLR    0.5712  0.6527   0.6974  \n",
       "775    BatchNorm1d  ExponentialLR    0.7408  0.6527   0.7378  \n",
       "114           None           None    0.6559  0.6526   0.6800  \n",
       "168           None           None    0.6493  0.6526   0.7004  \n",
       "300           None           None    0.5607  0.6525   0.6571  \n",
       "782    BatchNorm1d    MultiStepLR    0.7481  0.6525   0.6784  \n",
       "774    BatchNorm1d           None    0.7425  0.6525   0.6406  \n",
       "927      LayerNorm           None    0.7428  0.6524   0.8000  \n",
       "916    BatchNorm1d  ExponentialLR    0.7626  0.6522   0.6253  \n",
       "85            None  ExponentialLR    0.5536  0.6521   0.7163  \n",
       "1182   BatchNorm1d           None    0.5745  0.6520   0.5421  \n",
       "1184   BatchNorm1d    MultiStepLR    0.5825  0.6520   0.5947  \n",
       "834    BatchNorm1d           None    0.7460  0.6518   0.7186  \n",
       "890    BatchNorm1d    MultiStepLR    0.7396  0.6518   0.6758  \n",
       "819      LayerNorm           None    0.7092  0.6517   0.6606  \n",
       "126    BatchNorm1d           None    0.7355  0.6517   0.6604  \n",
       "723    BatchNorm1d           None    0.5620  0.6516   0.6253  \n",
       "809    BatchNorm1d    MultiStepLR    0.7442  0.6516   0.6353  \n",
       "1153   BatchNorm1d  ExponentialLR    0.8197  0.6515   0.6006  \n",
       "803    BatchNorm1d    MultiStepLR    0.7553  0.6514   0.6800  \n",
       "142           None  ExponentialLR    0.6604  0.6510   0.6994  \n",
       "1048   BatchNorm1d  ExponentialLR    0.5702  0.6510   0.6092  \n",
       "248           None    MultiStepLR    0.5834  0.6508   0.6758  \n",
       "693    BatchNorm1d           None    0.7609  0.6507   0.7568  \n",
       "50     BatchNorm1d    MultiStepLR    0.5826  0.6506   0.6604  \n",
       "139           None  ExponentialLR    0.5695  0.6503   0.6944  \n",
       "1099   BatchNorm1d  ExponentialLR    0.7554  0.6503   0.6382  \n",
       "990    BatchNorm1d           None    0.7566  0.6502   0.6720  \n",
       "1045   BatchNorm1d  ExponentialLR    0.8174  0.6502   0.5579  \n",
       "1240   BatchNorm1d  ExponentialLR    0.7661  0.6500   0.6000  \n",
       "969    BatchNorm1d           None    0.7676  0.6496   0.7004  \n",
       "220           None  ExponentialLR    0.5690  0.6496   0.7204  \n",
       "1260   BatchNorm1d           None    0.7862  0.6495   0.6400  \n",
       "668    BatchNorm1d    MultiStepLR    0.7447  0.6495   0.6537  \n",
       "115           None  ExponentialLR    0.6604  0.6495   0.6994  \n",
       "814           None  ExponentialLR    0.5714  0.6493   0.6181  \n",
       "801    BatchNorm1d           None    0.7519  0.6492   0.6192  \n",
       "1233   BatchNorm1d           None    0.7603  0.6491   0.4607  \n",
       "698    BatchNorm1d    MultiStepLR    0.5894  0.6489   0.6758  \n",
       "4             None  ExponentialLR    0.5648  0.6489   0.6994  \n",
       "5             None    MultiStepLR    0.5689  0.6489   0.6994  \n",
       "250           None  ExponentialLR    0.6608  0.6488   0.6994  \n",
       "191           None    MultiStepLR    0.7548  0.6487   0.6800  \n",
       "808    BatchNorm1d  ExponentialLR    0.7603  0.6487   0.8196  \n",
       "667    BatchNorm1d  ExponentialLR    0.7688  0.6486   0.7604  \n",
       "836    BatchNorm1d    MultiStepLR    0.7599  0.6485   0.7004  \n",
       "1079   BatchNorm1d    MultiStepLR    0.8033  0.6485   0.5600  \n",
       "69       LayerNorm           None    0.6651  0.6484   0.6800  \n",
       "15       LayerNorm           None    0.6533  0.6482   0.6192  \n",
       "884    BatchNorm1d    MultiStepLR    0.7452  0.6481   0.6192  \n",
       "291    BatchNorm1d           None    0.5636  0.6481   0.6205  \n",
       "921           None           None    0.5627  0.6481   0.6782  \n",
       "32            None    MultiStepLR    0.5721  0.6480   0.6720  \n",
       "778    BatchNorm1d  ExponentialLR    0.5914  0.6479   0.6944  \n",
       "724    BatchNorm1d  ExponentialLR    0.5684  0.6479   0.6490  \n",
       "747    BatchNorm1d           None    0.8193  0.6478   0.6784  \n",
       "888    BatchNorm1d           None    0.7412  0.6477   0.5764  \n",
       "720    BatchNorm1d           None    0.7931  0.6473   0.6784  \n",
       "909    BatchNorm1d           None    0.7566  0.6471   0.6006  \n",
       "25     BatchNorm1d  ExponentialLR    0.7520  0.6469   0.6400  \n",
       "701    BatchNorm1d    MultiStepLR    0.7595  0.6468   0.6994  \n",
       "694    BatchNorm1d  ExponentialLR    0.7767  0.6467   0.5764  \n",
       "26     BatchNorm1d    MultiStepLR    0.7380  0.6465   0.7403  \n",
       "192           None           None    0.5610  0.6465   0.7352  \n",
       "722    BatchNorm1d    MultiStepLR    0.7818  0.6464   0.5805  \n",
       "674    BatchNorm1d    MultiStepLR    0.7447  0.6462   0.7604  \n",
       "138           None           None    0.5734  0.6462   0.6720  \n",
       "695    BatchNorm1d    MultiStepLR    0.7685  0.6461   0.6604  \n",
       "936    BatchNorm1d           None    0.8037  0.6460   0.6006  \n",
       "10       LayerNorm  ExponentialLR    0.7132  0.6460   0.6604  \n",
       "700    BatchNorm1d  ExponentialLR    0.7665  0.6458   0.7004  \n",
       "1186   BatchNorm1d  ExponentialLR    0.8420  0.6457   0.5314  \n",
       "911    BatchNorm1d    MultiStepLR    0.7568  0.6454   0.6192  \n",
       "272           None    MultiStepLR    0.7265  0.6454   0.6800  \n",
       "270           None           None    0.7330  0.6451   0.6604  \n",
       "887    BatchNorm1d    MultiStepLR    0.5873  0.6449   0.6606  \n",
       "860    BatchNorm1d    MultiStepLR    0.5770  0.6448   0.6400  \n",
       "781    BatchNorm1d  ExponentialLR    0.7547  0.6444   0.7004  \n",
       "971    BatchNorm1d    MultiStepLR    0.7849  0.6444   0.6353  \n",
       "889    BatchNorm1d  ExponentialLR    0.7564  0.6444   0.7600  \n",
       "112           None  ExponentialLR    0.5446  0.6442   0.6759  \n",
       "1245          None           None    0.5640  0.6440   0.4940  \n",
       "727    BatchNorm1d  ExponentialLR    0.7930  0.6439   0.6944  \n",
       "133    BatchNorm1d  ExponentialLR    0.7333  0.6438   0.7378  \n",
       "1072   BatchNorm1d  ExponentialLR    0.8673  0.6437   0.6167  \n",
       "663      LayerNorm           None    0.6964  0.6436   0.7187  \n",
       "132    BatchNorm1d           None    0.7044  0.6436   0.7004  \n",
       "1292   BatchNorm1d    MultiStepLR    0.5740  0.6436   0.5722  \n",
       "754    BatchNorm1d  ExponentialLR    0.8309  0.6435   0.6784  \n",
       "828    BatchNorm1d           None    0.7852  0.6433   0.6720  \n",
       "1261   BatchNorm1d  ExponentialLR    0.7836  0.6433   0.5391  \n",
       "829    BatchNorm1d  ExponentialLR    0.7956  0.6429   0.5490  \n",
       "223           None  ExponentialLR    0.6549  0.6429   0.6571  \n",
       "1078   BatchNorm1d  ExponentialLR    0.8417  0.6428   0.6006  \n",
       "975           None           None    0.5803  0.6428   0.6092  \n",
       "30            None           None    0.5720  0.6427   0.6944  \n",
       "967    BatchNorm1d  ExponentialLR    0.5740  0.6427   0.7316  \n",
       "776    BatchNorm1d    MultiStepLR    0.7288  0.6427   0.6604  \n",
       "102    BatchNorm1d           None    0.5696  0.6426   0.6944  \n",
       "320    BatchNorm1d    MultiStepLR    0.5708  0.6425   0.6784  \n",
       "156    BatchNorm1d           None    0.5784  0.6423   0.6400  \n",
       "22     BatchNorm1d  ExponentialLR    0.5830  0.6420   0.6537  \n",
       "806    BatchNorm1d    MultiStepLR    0.5878  0.6420   0.7803  \n",
       "80     BatchNorm1d    MultiStepLR    0.7314  0.6420   0.5579  \n",
       "728    BatchNorm1d    MultiStepLR    0.7635  0.6418   0.6604  \n",
       "103    BatchNorm1d  ExponentialLR    0.5713  0.6418   0.7200  \n",
       "1187   BatchNorm1d    MultiStepLR    0.7930  0.6416   0.6167  \n",
       "19     BatchNorm1d  ExponentialLR    0.7539  0.6415   0.6205  \n",
       "863    BatchNorm1d    MultiStepLR    0.7837  0.6414   0.6205  \n",
       "214    BatchNorm1d  ExponentialLR    0.8101  0.6414   0.6593  \n",
       "673    BatchNorm1d  ExponentialLR    0.7593  0.6412   0.6006  \n",
       "134    BatchNorm1d    MultiStepLR    0.7227  0.6412   0.6593  \n",
       "1071   BatchNorm1d           None    0.8327  0.6411   0.5600  \n",
       "835    BatchNorm1d  ExponentialLR    0.7998  0.6410   0.6077  \n",
       "318    BatchNorm1d           None    0.5716  0.6409   0.6205  \n",
       "861    BatchNorm1d           None    0.7560  0.6408   0.6006  \n",
       "1289   BatchNorm1d    MultiStepLR    0.8472  0.6406   0.6784  \n",
       "944    BatchNorm1d    MultiStepLR    0.7458  0.6406   0.6205  \n",
       "886    BatchNorm1d  ExponentialLR    0.5811  0.6405   0.7395  \n",
       "753    BatchNorm1d           None    0.7641  0.6404   0.6604  \n",
       "237    BatchNorm1d           None    0.5705  0.6404   0.6382  \n",
       "1049   BatchNorm1d    MultiStepLR    0.5680  0.6403   0.5722  \n",
       "24     BatchNorm1d           None    0.7190  0.6403   0.7352  \n",
       "127    BatchNorm1d  ExponentialLR    0.7259  0.6401   0.6604  \n",
       "1262   BatchNorm1d    MultiStepLR    0.7962  0.6401   0.5579  \n",
       "779    BatchNorm1d    MultiStepLR    0.5822  0.6399   0.6490  \n",
       "73     BatchNorm1d  ExponentialLR    0.7968  0.6398   0.6382  \n",
       "155    BatchNorm1d    MultiStepLR    0.7417  0.6397   0.6353  \n",
       "49     BatchNorm1d  ExponentialLR    0.5909  0.6391   0.6167  \n",
       "1183   BatchNorm1d  ExponentialLR    0.5787  0.6391   0.7378  \n",
       "1235   BatchNorm1d    MultiStepLR    0.7656  0.6391   0.6077  \n",
       "267    BatchNorm1d           None    0.7192  0.6389   0.7200  \n",
       "275           None    MultiStepLR    0.5638  0.6389   0.6903  \n",
       "1179   BatchNorm1d           None    0.8336  0.6385   0.5792  \n",
       "319    BatchNorm1d  ExponentialLR    0.5777  0.6385   0.6800  \n",
       "938    BatchNorm1d    MultiStepLR    0.8022  0.6385   0.7004  \n",
       "1287   BatchNorm1d           None    0.8368  0.6384   0.5542  \n",
       "266    BatchNorm1d    MultiStepLR    0.5760  0.6381   0.7200  \n",
       "154    BatchNorm1d  ExponentialLR    0.7392  0.6381   0.7403  \n",
       "75     BatchNorm1d           None    0.5562  0.6380   0.6537  \n",
       "51     BatchNorm1d           None    0.7203  0.6379   0.7004  \n",
       "297           None           None    0.7584  0.6378   0.5981  \n",
       "18     BatchNorm1d           None    0.7352  0.6377   0.7187  \n",
       "942    BatchNorm1d           None    0.7397  0.6377   0.6310  \n",
       "859    BatchNorm1d  ExponentialLR    0.5847  0.6375   0.6758  \n",
       "912    BatchNorm1d           None    0.5939  0.6372   0.6181  \n",
       "1288   BatchNorm1d  ExponentialLR    0.8498  0.6371   0.6205  \n",
       "970    BatchNorm1d  ExponentialLR    0.8287  0.6370   0.5333  \n",
       "264    BatchNorm1d           None    0.5714  0.6369   0.6167  \n",
       "53     BatchNorm1d    MultiStepLR    0.7344  0.6369   0.6571  \n",
       "212    BatchNorm1d    MultiStepLR    0.5725  0.6368   0.6974  \n",
       "1197     LayerNorm           None    0.6906  0.6366   0.6077  \n",
       "48     BatchNorm1d           None    0.5837  0.6366   0.6537  \n",
       "153    BatchNorm1d           None    0.7404  0.6366   0.7781  \n",
       "23     BatchNorm1d    MultiStepLR    0.5780  0.6366   0.6800  \n",
       "1294   BatchNorm1d  ExponentialLR    0.8377  0.6365   0.5805  \n",
       "685      LayerNorm  ExponentialLR    0.6433  0.6364   0.7163  \n",
       "161    BatchNorm1d    MultiStepLR    0.7275  0.6361   0.6758  \n",
       "78     BatchNorm1d           None    0.7212  0.6360   0.6571  \n",
       "159    BatchNorm1d           None    0.7177  0.6359   0.6974  \n",
       "240    BatchNorm1d           None    0.7157  0.6357   0.6604  \n",
       "262    BatchNorm1d  ExponentialLR    0.7408  0.6355   0.6400  \n",
       "1085          None    MultiStepLR    0.5843  0.6354   0.5537  \n",
       "194           None    MultiStepLR    0.5652  0.6354   0.7086  \n",
       "234    BatchNorm1d           None    0.7269  0.6352   0.7759  \n",
       "167           None    MultiStepLR    0.5606  0.6352   0.6903  \n",
       "268    BatchNorm1d  ExponentialLR    0.7416  0.6352   0.6167  \n",
       "235    BatchNorm1d  ExponentialLR    0.7195  0.6351   0.5542  \n",
       "1073   BatchNorm1d    MultiStepLR    0.8391  0.6351   0.6000  \n",
       "47     BatchNorm1d    MultiStepLR    0.7461  0.6350   0.6205  \n",
       "1209   BatchNorm1d           None    0.5876  0.6349   0.5924  \n",
       "279      LayerNorm           None    0.7174  0.6349   0.7130  \n",
       "721    BatchNorm1d  ExponentialLR    0.8080  0.6346   0.6994  \n",
       "188    BatchNorm1d    MultiStepLR    0.7395  0.6345   0.7186  \n",
       "105    BatchNorm1d           None    0.7332  0.6341   0.6205  \n",
       "943    BatchNorm1d  ExponentialLR    0.7922  0.6341   0.6400  \n",
       "294    BatchNorm1d           None    0.7352  0.6340   0.7204  \n",
       "45     BatchNorm1d           None    0.7437  0.6340   0.6571  \n",
       "323    BatchNorm1d    MultiStepLR    0.7738  0.6338   0.6406  \n",
       "963    BatchNorm1d           None    0.8282  0.6338   0.6784  \n",
       "104    BatchNorm1d    MultiStepLR    0.5727  0.6337   0.7600  \n",
       "79     BatchNorm1d  ExponentialLR    0.7884  0.6337   0.7781  \n",
       "1180   BatchNorm1d  ExponentialLR    0.8540  0.6332   0.5805  \n",
       "777    BatchNorm1d           None    0.5709  0.6331   0.7403  \n",
       "749    BatchNorm1d    MultiStepLR    0.8300  0.6330   0.6604  \n",
       "238    BatchNorm1d  ExponentialLR    0.5757  0.6328   0.6167  \n",
       "321    BatchNorm1d           None    0.7326  0.6316   0.7378  \n",
       "748    BatchNorm1d  ExponentialLR    0.8553  0.6313   0.7004  \n",
       "236    BatchNorm1d    MultiStepLR    0.7204  0.6312   0.6593  \n",
       "242    BatchNorm1d    MultiStepLR    0.7090  0.6310   0.6994  \n",
       "101    BatchNorm1d    MultiStepLR    0.8031  0.6307   0.6537  \n",
       "289    BatchNorm1d  ExponentialLR    0.7704  0.6307   0.7186  \n",
       "166           None  ExponentialLR    0.5660  0.6305   0.7086  \n",
       "269    BatchNorm1d    MultiStepLR    0.7321  0.6305   0.6974  \n",
       "295    BatchNorm1d  ExponentialLR    0.7786  0.6303   0.6758  \n",
       "107    BatchNorm1d    MultiStepLR    0.7643  0.6303   0.7186  \n",
       "261    BatchNorm1d           None    0.7392  0.6301   0.7186  \n",
       "129    BatchNorm1d           None    0.5745  0.6298   0.7163  \n",
       "158    BatchNorm1d    MultiStepLR    0.5750  0.6297   0.7604  \n",
       "213    BatchNorm1d           None    0.7422  0.6287   0.6805  \n",
       "72     BatchNorm1d           None    0.7438  0.6285   0.6805  \n",
       "106    BatchNorm1d  ExponentialLR    0.8017  0.6284   0.6800  \n",
       "856    BatchNorm1d  ExponentialLR    0.8442  0.6281   0.6205  \n",
       "263    BatchNorm1d    MultiStepLR    0.7391  0.6280   0.6994  \n",
       "239    BatchNorm1d    MultiStepLR    0.5591  0.6279   0.6800  \n",
       "830    BatchNorm1d    MultiStepLR    0.7968  0.6278   0.6593  \n",
       "937    BatchNorm1d  ExponentialLR    0.7992  0.6275   0.6593  \n",
       "862    BatchNorm1d  ExponentialLR    0.8392  0.6275   0.6537  \n",
       "1181   BatchNorm1d    MultiStepLR    0.8418  0.6274   0.6205  \n",
       "210    BatchNorm1d           None    0.5672  0.6271   0.5981  \n",
       "157    BatchNorm1d  ExponentialLR    0.5794  0.6270   0.6758  \n",
       "52     BatchNorm1d  ExponentialLR    0.7571  0.6266   0.6903  \n",
       "288    BatchNorm1d           None    0.7726  0.6263   0.6800  \n",
       "181    BatchNorm1d  ExponentialLR    0.7680  0.6262   0.7378  \n",
       "241    BatchNorm1d  ExponentialLR    0.7320  0.6261   0.6604  \n",
       "20     BatchNorm1d    MultiStepLR    0.7439  0.6255   0.6205  \n",
       "160    BatchNorm1d  ExponentialLR    0.7425  0.6255   0.6167  \n",
       "215    BatchNorm1d    MultiStepLR    0.7635  0.6253   0.5947  \n",
       "186    BatchNorm1d           None    0.7166  0.6251   0.6192  \n",
       "131    BatchNorm1d    MultiStepLR    0.5703  0.6250   0.6784  \n",
       "183    BatchNorm1d           None    0.5545  0.6247   0.6785  \n",
       "74     BatchNorm1d    MultiStepLR    0.7934  0.6247   0.6571  \n",
       "86            None    MultiStepLR    0.5553  0.6243   0.7086  \n",
       "46     BatchNorm1d  ExponentialLR    0.7673  0.6241   0.7200  \n",
       "315    BatchNorm1d           None    0.8076  0.6238   0.7269  \n",
       "290    BatchNorm1d    MultiStepLR    0.7689  0.6238   0.7004  \n",
       "322    BatchNorm1d  ExponentialLR    0.8077  0.6236   0.6593  \n",
       "165           None           None    0.5581  0.6234   0.7269  \n",
       "128    BatchNorm1d    MultiStepLR    0.7160  0.6233   0.6994  \n",
       "316    BatchNorm1d  ExponentialLR    0.8298  0.6233   0.7604  \n",
       "296    BatchNorm1d    MultiStepLR    0.7419  0.6232   0.7204  \n",
       "857    BatchNorm1d    MultiStepLR    0.8377  0.6226   0.5664  \n",
       "692      LayerNorm    MultiStepLR    0.6224  0.6225   0.6604  \n",
       "1083          None           None    0.5839  0.6223   0.5694  \n",
       "725    BatchNorm1d    MultiStepLR    0.5730  0.6220   0.6429  \n",
       "293    BatchNorm1d    MultiStepLR    0.5573  0.6216   0.6784  \n",
       "265    BatchNorm1d  ExponentialLR    0.5797  0.6215   0.6974  \n",
       "1156   BatchNorm1d  ExponentialLR    0.5618  0.6214   0.6670  \n",
       "99     BatchNorm1d           None    0.8026  0.6212   0.7004  \n",
       "965    BatchNorm1d    MultiStepLR    0.8448  0.6212   0.7600  \n",
       "187    BatchNorm1d  ExponentialLR    0.7488  0.6209   0.6800  \n",
       "964    BatchNorm1d  ExponentialLR    0.8518  0.6203   0.6000  \n",
       "211    BatchNorm1d  ExponentialLR    0.5578  0.6190   0.6353  \n",
       "302           None    MultiStepLR    0.5636  0.6189   0.6606  \n",
       "180    BatchNorm1d           None    0.7667  0.6186   0.6758  \n",
       "247           None  ExponentialLR    0.5781  0.6185   0.7269  \n",
       "941    BatchNorm1d    MultiStepLR    0.5689  0.6185   0.6253  \n",
       "940    BatchNorm1d  ExponentialLR    0.5700  0.6177   0.7086  \n",
       "208    BatchNorm1d  ExponentialLR    0.8302  0.6172   0.5805  \n",
       "209    BatchNorm1d    MultiStepLR    0.8207  0.6172   0.6205  \n",
       "1265   BatchNorm1d    MultiStepLR    0.5704  0.6171   0.5837  \n",
       "207    BatchNorm1d           None    0.8105  0.6170   0.6400  \n",
       "100    BatchNorm1d  ExponentialLR    0.8451  0.6165   0.6604  \n",
       "855    BatchNorm1d           None    0.8224  0.6163   0.7200  \n",
       "113           None    MultiStepLR    0.5727  0.6157   0.7316  \n",
       "317    BatchNorm1d    MultiStepLR    0.8202  0.6151   0.5722  \n",
       "77     BatchNorm1d    MultiStepLR    0.5567  0.6132   0.6720  \n",
       "1144     LayerNorm  ExponentialLR    0.6585  0.6122   0.6131  \n",
       "1154   BatchNorm1d    MultiStepLR    0.8003  0.6120   0.7588  \n",
       "182    BatchNorm1d    MultiStepLR    0.7584  0.6114   0.6604  \n",
       "832    BatchNorm1d  ExponentialLR    0.5678  0.6111   0.6537  \n",
       "1102   BatchNorm1d  ExponentialLR    0.5777  0.6092   0.5694  \n",
       "130    BatchNorm1d  ExponentialLR    0.5786  0.6090   0.6310  \n",
       "174      LayerNorm           None    0.5365  0.6075   0.6205  \n",
       "833    BatchNorm1d    MultiStepLR    0.5612  0.6071   0.6670  \n",
       "292    BatchNorm1d  ExponentialLR    0.5559  0.6052   0.6944  \n",
       "987      LayerNorm           None    0.6771  0.6050   0.6010  \n",
       "512    BatchNorm1d    MultiStepLR    0.7233  0.6041   0.6604  \n",
       "43       LayerNorm  ExponentialLR    0.5731  0.6041   0.6758  \n",
       "1224     LayerNorm           None    0.5415  0.6037   0.5138  \n",
       "939    BatchNorm1d           None    0.5686  0.6020   0.6260  \n",
       "1157   BatchNorm1d    MultiStepLR    0.5612  0.5988   0.5380  \n",
       "511    BatchNorm1d  ExponentialLR    0.7733  0.5984   0.6604  \n",
       "344    BatchNorm1d    MultiStepLR    0.6993  0.5971   0.6382  \n",
       "428    BatchNorm1d    MultiStepLR    0.5557  0.5959   0.5764  \n",
       "459           None           None    0.6028  0.5954   0.5080  \n",
       "1263   BatchNorm1d           None    0.5668  0.5953   0.6353  \n",
       "377    BatchNorm1d    MultiStepLR    0.7172  0.5952   0.5600  \n",
       "11       LayerNorm    MultiStepLR    0.6651  0.5926   0.6782  \n",
       "404    BatchNorm1d    MultiStepLR    0.7332  0.5925   0.5542  \n",
       "76     BatchNorm1d  ExponentialLR    0.5555  0.5922   0.6526  \n",
       "375    BatchNorm1d           None    0.6891  0.5919   0.5607  \n",
       "353           None    MultiStepLR    0.6080  0.5916   0.5251  \n",
       "405           None           None    0.6034  0.5915   0.5169  \n",
       "351           None           None    0.6069  0.5913   0.5251  \n",
       "456    BatchNorm1d           None    0.6940  0.5912   0.5757  \n",
       "596           None    MultiStepLR    0.6042  0.5912   0.4907  \n",
       "514           None  ExponentialLR    0.6133  0.5912   0.4670  \n",
       "488           None    MultiStepLR    0.6060  0.5908   0.5169  \n",
       "647    BatchNorm1d    MultiStepLR    0.7359  0.5905   0.6382  \n",
       "568           None  ExponentialLR    0.6069  0.5905   0.5391  \n",
       "565    BatchNorm1d  ExponentialLR    0.7130  0.5903   0.6167  \n",
       "450    BatchNorm1d           None    0.7055  0.5901   0.4907  \n",
       "487           None  ExponentialLR    0.6158  0.5899   0.5251  \n",
       "587    BatchNorm1d    MultiStepLR    0.7168  0.5899   0.5792  \n",
       "407           None    MultiStepLR    0.6100  0.5898   0.5251  \n",
       "461           None    MultiStepLR    0.6073  0.5897   0.5837  \n",
       "621           None           None    0.6117  0.5896   0.4940  \n",
       "341      LayerNorm    MultiStepLR    0.5345  0.5896   0.5004  \n",
       "380           None    MultiStepLR    0.6088  0.5891   0.5169  \n",
       "794      LayerNorm    MultiStepLR    0.5866  0.5887   0.6192  \n",
       "389      LayerNorm    MultiStepLR    0.5635  0.5885   0.4908  \n",
       "349    BatchNorm1d  ExponentialLR    0.7212  0.5884   0.5607  \n",
       "713      LayerNorm    MultiStepLR    0.6352  0.5881   0.6526  \n",
       "433           None  ExponentialLR    0.6101  0.5880   0.5251  \n",
       "406           None  ExponentialLR    0.6112  0.5878   0.5490  \n",
       "460           None  ExponentialLR    0.6125  0.5878   0.6406  \n",
       "595           None  ExponentialLR    0.6147  0.5874   0.4775  \n",
       "431    BatchNorm1d    MultiStepLR    0.7541  0.5873   0.5947  \n",
       "485    BatchNorm1d    MultiStepLR    0.7086  0.5872   0.5200  \n",
       "646    BatchNorm1d  ExponentialLR    0.7995  0.5870   0.6400  \n",
       "541           None  ExponentialLR    0.5991  0.5870   0.5004  \n",
       "622           None  ExponentialLR    0.6193  0.5868   0.5314  \n",
       "352           None  ExponentialLR    0.6103  0.5867   0.5314  \n",
       "373    BatchNorm1d  ExponentialLR    0.5714  0.5866   0.5137  \n",
       "402    BatchNorm1d           None    0.6907  0.5862   0.6400  \n",
       "569           None    MultiStepLR    0.6054  0.5860   0.4957  \n",
       "457    BatchNorm1d  ExponentialLR    0.7134  0.5856   0.5579  \n",
       "594           None           None    0.6055  0.5854   0.5177  \n",
       "423    BatchNorm1d           None    0.7910  0.5850   0.5006  \n",
       "372    BatchNorm1d           None    0.5707  0.5848   0.4172  \n",
       "397    BatchNorm1d  ExponentialLR    0.7839  0.5847   0.6205  \n",
       "567           None           None    0.6040  0.5846   0.4789  \n",
       "425    BatchNorm1d    MultiStepLR    0.8029  0.5843   0.5981  \n",
       "348    BatchNorm1d           None    0.6915  0.5841   0.5589  \n",
       "346    BatchNorm1d  ExponentialLR    0.5526  0.5835   0.5080  \n",
       "1139          None    MultiStepLR    0.5692  0.5834   0.6429  \n",
       "374    BatchNorm1d    MultiStepLR    0.5763  0.5833   0.5664  \n",
       "370    BatchNorm1d  ExponentialLR    0.7358  0.5833   0.6784  \n",
       "429    BatchNorm1d           None    0.7175  0.5829   0.5792  \n",
       "426    BatchNorm1d           None    0.5605  0.5825   0.5658  \n",
       "934      LayerNorm  ExponentialLR    0.5947  0.5823   0.6606  \n",
       "369    BatchNorm1d           None    0.7286  0.5823   0.6205  \n",
       "623           None    MultiStepLR    0.6116  0.5822   0.5333  \n",
       "540           None           None    0.6027  0.5819   0.5066  \n",
       "343    BatchNorm1d  ExponentialLR    0.7298  0.5819   0.5200  \n",
       "376    BatchNorm1d  ExponentialLR    0.7319  0.5811   0.6382  \n",
       "398    BatchNorm1d    MultiStepLR    0.7466  0.5807   0.6382  \n",
       "434           None    MultiStepLR    0.5975  0.5802   0.5004  \n",
       "515           None    MultiStepLR    0.6122  0.5801   0.5066  \n",
       "586    BatchNorm1d  ExponentialLR    0.7146  0.5801   0.4172  \n",
       "345    BatchNorm1d           None    0.5600  0.5799   0.6571  \n",
       "479    BatchNorm1d    MultiStepLR    0.7100  0.5794   0.5600  \n",
       "458    BatchNorm1d    MultiStepLR    0.6820  0.5794   0.6400  \n",
       "539    BatchNorm1d    MultiStepLR    0.7495  0.5793   0.5947  \n",
       "642    BatchNorm1d           None    0.5547  0.5793   0.6009  \n",
       "543           None           None    0.5317  0.5791   0.4908  \n",
       "326           None    MultiStepLR    0.5901  0.5789   0.5080  \n",
       "538    BatchNorm1d  ExponentialLR    0.7895  0.5786   0.5137  \n",
       "371    BatchNorm1d    MultiStepLR    0.7318  0.5785   0.5837  \n",
       "564    BatchNorm1d           None    0.6626  0.5785   0.5837  \n",
       "480    BatchNorm1d           None    0.5622  0.5780   0.5792  \n",
       "793      LayerNorm  ExponentialLR    0.5732  0.5777   0.6571  \n",
       "592    BatchNorm1d  ExponentialLR    0.7275  0.5775   0.5579  \n",
       "482    BatchNorm1d    MultiStepLR    0.5583  0.5774   0.6805  \n",
       "566    BatchNorm1d    MultiStepLR    0.6937  0.5772   0.6129  \n",
       "484    BatchNorm1d  ExponentialLR    0.7233  0.5763   0.5406  \n",
       "408           None           None    0.5273  0.5762   0.5004  \n",
       "424    BatchNorm1d  ExponentialLR    0.8178  0.5762   0.5837  \n",
       "350    BatchNorm1d    MultiStepLR    0.6985  0.5761   0.6205  \n",
       "481    BatchNorm1d  ExponentialLR    0.5563  0.5761   0.6129  \n",
       "542           None    MultiStepLR    0.6052  0.5761   0.5066  \n",
       "617    BatchNorm1d    MultiStepLR    0.5496  0.5758   0.6429  \n",
       "618    BatchNorm1d           None    0.6900  0.5757   0.5361  \n",
       "624           None           None    0.5289  0.5753   0.4749  \n",
       "591    BatchNorm1d           None    0.6929  0.5751   0.5607  \n",
       "612    BatchNorm1d           None    0.7615  0.5751   0.5361  \n",
       "342    BatchNorm1d           None    0.7207  0.5745   0.5664  \n",
       "427    BatchNorm1d  ExponentialLR    0.5590  0.5738   0.5066  \n",
       "437           None    MultiStepLR    0.5358  0.5738   0.5542  \n",
       "613    BatchNorm1d  ExponentialLR    0.7497  0.5734   0.5805  \n",
       "531    BatchNorm1d           None    0.8016  0.5732   0.5805  \n",
       "513           None           None    0.6047  0.5731   0.4940  \n",
       "478    BatchNorm1d  ExponentialLR    0.6942  0.5730   0.5805  \n",
       "533    BatchNorm1d    MultiStepLR    0.8038  0.5728   0.5981  \n",
       "593    BatchNorm1d    MultiStepLR    0.7044  0.5724   0.6192  \n",
       "537    BatchNorm1d           None    0.7129  0.5723   0.7130  \n",
       "396    BatchNorm1d           None    0.7373  0.5723   0.5805  \n",
       "534    BatchNorm1d           None    0.5461  0.5720   0.6077  \n",
       "477    BatchNorm1d           None    0.7185  0.5718   0.5251  \n",
       "614    BatchNorm1d    MultiStepLR    0.7682  0.5717   0.6000  \n",
       "984      LayerNorm           None    0.5287  0.5712   0.5081  \n",
       "560    BatchNorm1d    MultiStepLR    0.6884  0.5709   0.5421  \n",
       "403    BatchNorm1d  ExponentialLR    0.7551  0.5708   0.5314  \n",
       "462           None           None    0.5312  0.5707   0.4500  \n",
       "504    BatchNorm1d           None    0.7608  0.5697   0.5805  \n",
       "619    BatchNorm1d  ExponentialLR    0.7529  0.5697   0.7004  \n",
       "451    BatchNorm1d  ExponentialLR    0.6878  0.5697   0.6205  \n",
       "620    BatchNorm1d    MultiStepLR    0.7110  0.5694   0.5589  \n",
       "432           None           None    0.5961  0.5689   0.4940  \n",
       "464           None    MultiStepLR    0.5348  0.5687   0.4940  \n",
       "536    BatchNorm1d    MultiStepLR    0.5441  0.5684   0.6537  \n",
       "559    BatchNorm1d  ExponentialLR    0.7026  0.5683   0.4838  \n",
       "510    BatchNorm1d           None    0.6956  0.5683   0.5981  \n",
       "430    BatchNorm1d  ExponentialLR    0.7974  0.5682   0.5981  \n",
       "561    BatchNorm1d           None    0.5535  0.5682   0.4789  \n",
       "599           None    MultiStepLR    0.5198  0.5681   0.4749  \n",
       "588    BatchNorm1d           None    0.5598  0.5680   0.5722  \n",
       "452    BatchNorm1d    MultiStepLR    0.6807  0.5679   0.5600  \n",
       "645    BatchNorm1d           None    0.7163  0.5679   0.7588  \n",
       "589    BatchNorm1d  ExponentialLR    0.5673  0.5671   0.5333  \n",
       "354           None           None    0.5376  0.5668   0.4789  \n",
       "185    BatchNorm1d    MultiStepLR    0.5566  0.5668   0.6312  \n",
       "483    BatchNorm1d           None    0.6822  0.5665   0.5177  \n",
       "639    BatchNorm1d           None    0.7986  0.5658   0.4172  \n",
       "489           None           None    0.5139  0.5646   0.4355  \n",
       "516           None           None    0.5238  0.5641   0.5495  \n",
       "1177     LayerNorm  ExponentialLR    0.3765  0.5636   0.6312  \n",
       "558    BatchNorm1d           None    0.7012  0.5634   0.5722  \n",
       "644    BatchNorm1d    MultiStepLR    0.5546  0.5632   0.6571  \n",
       "506    BatchNorm1d    MultiStepLR    0.7386  0.5629   0.5600  \n",
       "325           None  ExponentialLR    0.5674  0.5621   0.4329  \n",
       "616    BatchNorm1d  ExponentialLR    0.5316  0.5612   0.4908  \n",
       "327           None           None    0.5293  0.5609   0.4637  \n",
       "490           None  ExponentialLR    0.5336  0.5604   0.5066  \n",
       "640    BatchNorm1d  ExponentialLR    0.8165  0.5601   0.5006  \n",
       "356           None    MultiStepLR    0.5383  0.5589   0.4909  \n",
       "532    BatchNorm1d  ExponentialLR    0.8191  0.5586   0.4957  \n",
       "505    BatchNorm1d  ExponentialLR    0.7393  0.5585   0.6604  \n",
       "641    BatchNorm1d    MultiStepLR    0.8001  0.5579   0.5361  \n",
       "453    BatchNorm1d           None    0.5398  0.5573   0.4588  \n",
       "585    BatchNorm1d           None    0.7103  0.5568   0.7796  \n",
       "455    BatchNorm1d    MultiStepLR    0.5618  0.5564   0.4908  \n",
       "347    BatchNorm1d    MultiStepLR    0.5550  0.5564   0.5924  \n",
       "486           None           None    0.5965  0.5547   0.5090  \n",
       "355           None  ExponentialLR    0.5346  0.5543   0.5090  \n",
       "626           None    MultiStepLR    0.5258  0.5542   0.4644  \n",
       "454    BatchNorm1d  ExponentialLR    0.5320  0.5536   0.5981  \n",
       "535    BatchNorm1d  ExponentialLR    0.5478  0.5531   0.5169  \n",
       "590    BatchNorm1d    MultiStepLR    0.5610  0.5528   0.4908  \n",
       "625           None  ExponentialLR    0.5298  0.5528   0.4940  \n",
       "615    BatchNorm1d           None    0.5326  0.5479   0.5837  \n",
       "562    BatchNorm1d  ExponentialLR    0.5457  0.5473   0.5837  \n",
       "570           None           None    0.5353  0.5464   0.4469  \n",
       "643    BatchNorm1d  ExponentialLR    0.5476  0.5459   0.5251  \n",
       "184    BatchNorm1d  ExponentialLR    0.5387  0.5454   0.5002  \n",
       "463           None  ExponentialLR    0.5349  0.5432   0.5066  \n",
       "571           None  ExponentialLR    0.5318  0.5392   0.4469  \n",
       "820      LayerNorm  ExponentialLR    0.5183  0.5390   0.4193  \n",
       "340      LayerNorm  ExponentialLR    0.5553  0.5380   0.4787  \n",
       "409           None  ExponentialLR    0.5262  0.5363   0.4787  \n",
       "507    BatchNorm1d           None    0.5357  0.5340   0.5169  \n",
       "563    BatchNorm1d    MultiStepLR    0.5420  0.5292   0.5090  \n",
       "382           None  ExponentialLR    0.5250  0.5284   0.4930  \n",
       "572           None    MultiStepLR    0.5347  0.5218   0.4930  \n",
       "401    BatchNorm1d    MultiStepLR    0.5253  0.5164   0.5658  \n",
       "509    BatchNorm1d    MultiStepLR    0.5390  0.5140   0.5693  \n",
       "508    BatchNorm1d  ExponentialLR    0.5168  0.5123   0.4789  \n",
       "935      LayerNorm    MultiStepLR    0.4699  0.5074   0.5390  \n",
       "1259     LayerNorm    MultiStepLR    0.5281  0.5069   0.5674  \n",
       "399    BatchNorm1d           None    0.5214  0.4954   0.4502  \n",
       "544           None  ExponentialLR    0.5349  0.4952   0.4602  \n",
       "502      LayerNorm  ExponentialLR    0.5560  0.4949   0.4602  \n",
       "1251     LayerNorm           None    0.5590  0.4924   0.5402  \n",
       "284      LayerNorm    MultiStepLR    0.4852  0.4878   0.5562  \n",
       "739      LayerNorm  ExponentialLR    0.5317  0.4855   0.5390  \n",
       "518           None    MultiStepLR    0.5301  0.4849   0.4257  \n",
       "491           None    MultiStepLR    0.5093  0.4818   0.4002  \n",
       "603      LayerNorm           None    0.5674  0.4813   0.4380  \n",
       "152      LayerNorm    MultiStepLR    0.5204  0.4691   0.4657  \n",
       "410           None    MultiStepLR    0.5291  0.4651   0.4002  \n",
       "1151     LayerNorm    MultiStepLR    0.4382  0.4638   0.4624  \n",
       "400    BatchNorm1d  ExponentialLR    0.5309  0.4620   0.4736  \n",
       "381           None           None    0.5253  0.4612   0.4502  \n",
       "333      LayerNorm           None    0.5589  0.4552   0.4380  \n",
       "1010     LayerNorm    MultiStepLR    0.4060  0.4535   0.4380  \n",
       "1285     LayerNorm  ExponentialLR    0.3844  0.4488   0.5541  \n",
       "314      LayerNorm    MultiStepLR    0.4875  0.4487   0.4326  \n",
       "907      LayerNorm  ExponentialLR    0.4525  0.4478   0.4220  \n",
       "902      LayerNorm    MultiStepLR    0.4048  0.4457   0.4380  \n",
       "1117     LayerNorm  ExponentialLR    0.4119  0.4409   0.4112  \n",
       "545           None    MultiStepLR    0.5261  0.4352   0.4112  \n",
       "989      LayerNorm    MultiStepLR    0.4985  0.4276   0.4624  \n",
       "906      LayerNorm           None    0.3927  0.4164   0.4624  \n",
       "517           None  ExponentialLR    0.5240  0.4109   0.3787  \n",
       "799      LayerNorm  ExponentialLR    0.4038  0.4052   0.3787  \n",
       "767      LayerNorm    MultiStepLR    0.4211  0.4051   0.4220  \n",
       "339      LayerNorm           None    0.5483  0.3926   0.3787  \n",
       "145      LayerNorm  ExponentialLR    0.3822  0.3843   0.3600  \n",
       "1149     LayerNorm           None    0.3787  0.3841   0.4220  \n",
       "792      LayerNorm           None    0.3867  0.3833   0.3787  \n",
       "770      LayerNorm    MultiStepLR    0.4705  0.3822   0.3787  \n",
       "1035     LayerNorm           None    0.3806  0.3809   0.4220  \n",
       "1143     LayerNorm           None    0.3776  0.3803   0.3787  \n",
       "798      LayerNorm           None    0.3755  0.3779   0.3787  \n",
       "117      LayerNorm           None    0.3786  0.3776   0.3787  \n",
       "1200     LayerNorm           None    0.4755  0.3776   0.3787  \n",
       "908      LayerNorm    MultiStepLR    0.3790  0.3772   0.3787  \n",
       "904      LayerNorm  ExponentialLR    0.4996  0.3771   0.3787  \n",
       "1123     LayerNorm  ExponentialLR    0.3817  0.3767   0.3787  \n",
       "253      LayerNorm  ExponentialLR    0.3768  0.3759   0.3787  \n",
       "1119     LayerNorm           None    0.4694  0.3751   0.3787  \n",
       "12       LayerNorm           None    0.4717  0.3749   0.3787  \n",
       "660      LayerNorm           None    0.4750  0.3749   0.3787  \n",
       "556      LayerNorm  ExponentialLR    0.3751  0.3746   0.3695  \n",
       "932      LayerNorm    MultiStepLR    0.4819  0.3745   0.3787  \n",
       "1095     LayerNorm           None    0.3776  0.3743   0.3787  \n",
       "259      LayerNorm  ExponentialLR    0.3735  0.3743   0.3787  \n",
       "769      LayerNorm  ExponentialLR    0.5020  0.3743   0.3787  \n",
       "1041     LayerNorm           None    0.3745  0.3743   0.3787  \n",
       "1252     LayerNorm  ExponentialLR    0.3749  0.3742   0.3787  \n",
       "122      LayerNorm    MultiStepLR    0.4724  0.3741   0.3787  \n",
       "1036     LayerNorm  ExponentialLR    0.3748  0.3740   0.3787  \n",
       "854      LayerNorm    MultiStepLR    0.3745  0.3740   0.3787  \n",
       "119      LayerNorm    MultiStepLR    0.3746  0.3740   0.3787  \n",
       "283      LayerNorm  ExponentialLR    0.4990  0.3739   0.3787  \n",
       "1091     LayerNorm    MultiStepLR    0.3741  0.3739   0.3787  \n",
       "1121     LayerNorm    MultiStepLR    0.5047  0.3738   0.3787  \n",
       "1255     LayerNorm  ExponentialLR    0.4973  0.3738   0.3787  \n",
       "198      LayerNorm           None    0.3741  0.3737   0.3787  \n",
       "176      LayerNorm    MultiStepLR    0.4767  0.3737   0.3787  \n",
       "1012     LayerNorm  ExponentialLR    0.4671  0.3736   0.3787  \n",
       "928      LayerNorm  ExponentialLR    0.3735  0.3736   0.3787  \n",
       "847      LayerNorm  ExponentialLR    0.3738  0.3736   0.3787  \n",
       "958      LayerNorm  ExponentialLR    0.4773  0.3736   0.3787  \n",
       "1097     LayerNorm    MultiStepLR    0.3764  0.3736   0.4220  \n",
       "285      LayerNorm           None    0.3737  0.3736   0.3787  \n",
       "470      LayerNorm    MultiStepLR    0.3736  0.3736   0.3787  \n",
       "1258     LayerNorm  ExponentialLR    0.3750  0.3736   0.3787  \n",
       "931      LayerNorm  ExponentialLR    0.4727  0.3735   0.3787  \n",
       "230      LayerNorm    MultiStepLR    0.5043  0.3735   0.3787  \n",
       "280      LayerNorm  ExponentialLR    0.3755  0.3735   0.3787  \n",
       "738      LayerNorm           None    0.3735  0.3735   0.3787  \n",
       "1089     LayerNorm           None    0.3751  0.3735   0.3787  \n",
       "205      LayerNorm  ExponentialLR    0.3737  0.3735   0.3787  \n",
       "147      LayerNorm           None    0.4783  0.3734   0.3787  \n",
       "1178     LayerNorm    MultiStepLR    0.3737  0.3734   0.3787  \n",
       "206      LayerNorm    MultiStepLR    0.3744  0.3733   0.3787  \n",
       "1232     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1228     LayerNorm  ExponentialLR    0.4714  0.3732   0.3787  \n",
       "1229     LayerNorm    MultiStepLR    0.4768  0.3732   0.3787  \n",
       "1230     LayerNorm           None    0.3736  0.3732   0.3787  \n",
       "1231     LayerNorm  ExponentialLR    0.3660  0.3732   0.3787  \n",
       "1034          None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "97       LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "287      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "286      LayerNorm  ExponentialLR    0.3736  0.3732   0.3787  \n",
       "98       LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1250          None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1096     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1227     LayerNorm           None    0.4662  0.3732   0.3787  \n",
       "313      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1254     LayerNorm           None    0.4724  0.3732   0.3787  \n",
       "1225     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "35            None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "34            None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "33            None           None    0.3735  0.3732   0.3787  \n",
       "93       LayerNorm           None    0.4721  0.3732   0.3787  \n",
       "1223          None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "120      LayerNorm           None    0.4762  0.3732   0.3787  \n",
       "121      LayerNorm  ExponentialLR    0.5056  0.3732   0.3787  \n",
       "96       LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1226     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1042     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "94       LayerNorm  ExponentialLR    0.4672  0.3732   0.3787  \n",
       "1039     LayerNorm  ExponentialLR    0.5569  0.3732   0.3787  \n",
       "95       LayerNorm    MultiStepLR    0.4696  0.3732   0.3787  \n",
       "1038     LayerNorm           None    0.5442  0.3732   0.3787  \n",
       "1253     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "308      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "37       LayerNorm  ExponentialLR    0.3736  0.3732   0.3787  \n",
       "1283     LayerNorm    MultiStepLR    0.4700  0.3732   0.3787  \n",
       "1277          None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1278     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1279     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1280     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1281     LayerNorm           None    0.4783  0.3732   0.3787  \n",
       "1282     LayerNorm  ExponentialLR    0.4714  0.3732   0.3787  \n",
       "324           None           None    0.3735  0.3732   0.3787  \n",
       "1033          None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1284     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1286     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1016     LayerNorm    MultiStepLR    0.3736  0.3732   0.3787  \n",
       "1015     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1092     LayerNorm           None    0.4686  0.3732   0.3787  \n",
       "1014     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1276          None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "6             None           None    0.3735  0.3732   0.3787  \n",
       "7             None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "8             None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "9        LayerNorm           None    0.3743  0.3732   0.3787  \n",
       "1093     LayerNorm  ExponentialLR    0.4700  0.3732   0.3787  \n",
       "1027          None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "13       LayerNorm  ExponentialLR    0.5585  0.3732   0.3787  \n",
       "125      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "14       LayerNorm    MultiStepLR    0.4673  0.3732   0.3787  \n",
       "124      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "123      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1094     LayerNorm    MultiStepLR    0.4741  0.3732   0.3787  \n",
       "1031          None    MultiStepLR    0.4678  0.3732   0.3787  \n",
       "1257     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1256     LayerNorm    MultiStepLR    0.4724  0.3732   0.3787  \n",
       "1032          None           None    0.3735  0.3732   0.3787  \n",
       "36       LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "38       LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "307      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "309      LayerNorm           None    0.4764  0.3732   0.3787  \n",
       "67       LayerNorm  ExponentialLR    0.4675  0.3732   0.3787  \n",
       "1069     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1068     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1067     LayerNorm    MultiStepLR    0.4784  0.3732   0.3787  \n",
       "1116     LayerNorm           None    0.3738  0.3732   0.3787  \n",
       "1066     LayerNorm  ExponentialLR    0.4905  0.3732   0.3787  \n",
       "1065     LayerNorm           None    0.4737  0.3732   0.3787  \n",
       "64       LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1064     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1063     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "66       LayerNorm           None    0.4897  0.3732   0.3787  \n",
       "1062     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "310      LayerNorm  ExponentialLR    0.4759  0.3732   0.3787  \n",
       "1061          None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "68       LayerNorm    MultiStepLR    0.4710  0.3732   0.3787  \n",
       "1118     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "70       LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1013     LayerNorm    MultiStepLR    0.4714  0.3732   0.3787  \n",
       "1147     LayerNorm  ExponentialLR    0.4743  0.3732   0.3787  \n",
       "1146     LayerNorm           None    0.4698  0.3732   0.3787  \n",
       "1120     LayerNorm  ExponentialLR    0.4709  0.3732   0.3787  \n",
       "71       LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1122     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1138          None  ExponentialLR    0.4736  0.3732   0.3787  \n",
       "1070     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1137          None           None    0.4698  0.3732   0.3787  \n",
       "1124     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "303           None           None    0.3735  0.3732   0.3787  \n",
       "304           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "305           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "306      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "65       LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "311      LayerNorm    MultiStepLR    0.4934  0.3732   0.3787  \n",
       "39       LayerNorm           None    0.4777  0.3732   0.3787  \n",
       "1203     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "89            None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1201     LayerNorm  ExponentialLR    0.4706  0.3732   0.3787  \n",
       "90       LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "91       LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "312      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "118      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1204     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "62            None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1205     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "44       LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "42       LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "92       LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "41       LayerNorm    MultiStepLR    0.4750  0.3732   0.3787  \n",
       "40       LayerNorm  ExponentialLR    0.4669  0.3732   0.3787  \n",
       "88            None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1199     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1198     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1196          None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "58            None  ExponentialLR    0.4734  0.3732   0.3787  \n",
       "1090     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1175     LayerNorm    MultiStepLR    0.4681  0.3732   0.3787  \n",
       "1174     LayerNorm  ExponentialLR    0.4697  0.3732   0.3787  \n",
       "1173     LayerNorm           None    0.4730  0.3732   0.3787  \n",
       "1172     LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1170     LayerNorm           None    0.3736  0.3732   0.3787  \n",
       "1059          None           None    0.3735  0.3732   0.3787  \n",
       "59            None    MultiStepLR    0.5049  0.3732   0.3787  \n",
       "1060          None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "60            None           None    0.3735  0.3732   0.3787  \n",
       "61            None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "87            None           None    0.3735  0.3732   0.3787  \n",
       "1176     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "281      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1011     LayerNorm           None    0.4831  0.3732   0.3787  \n",
       "584      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "578      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "579      LayerNorm           None    0.4742  0.3732   0.3787  \n",
       "580      LayerNorm  ExponentialLR    0.5084  0.3732   0.3787  \n",
       "581      LayerNorm    MultiStepLR    0.4695  0.3732   0.3787  \n",
       "582      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "583      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "597           None           None    0.4768  0.3732   0.3787  \n",
       "576      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "598           None  ExponentialLR    0.4662  0.3732   0.3787  \n",
       "600           None           None    0.3735  0.3732   0.3787  \n",
       "601           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "602           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "604      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "605      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "577      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "575           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "688      LayerNorm  ExponentialLR    0.4689  0.3732   0.3787  \n",
       "550      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "529      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "530      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "546           None           None    0.3735  0.3732   0.3787  \n",
       "547           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "548           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "549      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "551      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "574           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "552      LayerNorm           None    0.4745  0.3732   0.3787  \n",
       "553      LayerNorm  ExponentialLR    0.4955  0.3732   0.3787  \n",
       "554      LayerNorm    MultiStepLR    0.4714  0.3732   0.3787  \n",
       "555      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "557      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "573           None           None    0.3735  0.3732   0.3787  \n",
       "606      LayerNorm           None    0.4716  0.3732   0.3787  \n",
       "607      LayerNorm  ExponentialLR    0.4964  0.3732   0.3787  \n",
       "608      LayerNorm    MultiStepLR    0.4675  0.3732   0.3787  \n",
       "378           None           None    0.3735  0.3732   0.3787  \n",
       "656           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "657      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "658      LayerNorm  ExponentialLR    0.3822  0.3732   0.3787  \n",
       "661      LayerNorm  ExponentialLR    0.4704  0.3732   0.3787  \n",
       "662      LayerNorm    MultiStepLR    0.5715  0.3732   0.3787  \n",
       "379           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "260      LayerNorm    MultiStepLR    0.3736  0.3732   0.3787  \n",
       "609      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "258      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "681           None           None    0.3735  0.3732   0.3787  \n",
       "682           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "683           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "684      LayerNorm           None    0.3740  0.3732   0.3787  \n",
       "686      LayerNorm    MultiStepLR    0.3736  0.3732   0.3787  \n",
       "655           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "654           None           None    0.3735  0.3732   0.3787  \n",
       "276           None           None    0.3735  0.3732   0.3787  \n",
       "277           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "638      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "637      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "635      LayerNorm    MultiStepLR    0.4722  0.3732   0.3787  \n",
       "634      LayerNorm  ExponentialLR    0.4671  0.3732   0.3787  \n",
       "633      LayerNorm           None    0.4698  0.3732   0.3787  \n",
       "632      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "631      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "630      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "629           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "628           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "627           None           None    0.3735  0.3732   0.3787  \n",
       "611      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "610      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "528      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "527      LayerNorm    MultiStepLR    0.4712  0.3732   0.3787  \n",
       "526      LayerNorm  ExponentialLR    0.4639  0.3732   0.3787  \n",
       "422      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "416      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "417      LayerNorm           None    0.4727  0.3732   0.3787  \n",
       "418      LayerNorm  ExponentialLR    0.4907  0.3732   0.3787  \n",
       "419      LayerNorm    MultiStepLR    0.4957  0.3732   0.3787  \n",
       "420      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "421      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "435           None           None    0.4724  0.3732   0.3787  \n",
       "444      LayerNorm           None    0.4672  0.3732   0.3787  \n",
       "436           None  ExponentialLR    0.4714  0.3732   0.3787  \n",
       "438           None           None    0.3735  0.3732   0.3787  \n",
       "439           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "440           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "441      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "442      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "415      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "414      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "413           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "412           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "411           None           None    0.3735  0.3732   0.3787  \n",
       "395      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "394      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "393      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "392      LayerNorm    MultiStepLR    0.4696  0.3732   0.3787  \n",
       "391      LayerNorm  ExponentialLR    0.4723  0.3732   0.3787  \n",
       "390      LayerNorm           None    0.4741  0.3732   0.3787  \n",
       "388      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "387      LayerNorm           None    0.4342  0.3732   0.3787  \n",
       "386           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "385           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "384           None           None    0.3735  0.3732   0.3787  \n",
       "383           None    MultiStepLR    0.4694  0.3732   0.3787  \n",
       "443      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "445      LayerNorm  ExponentialLR    0.4704  0.3732   0.3787  \n",
       "525      LayerNorm           None    0.4693  0.3732   0.3787  \n",
       "501      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "495      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "496      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "497      LayerNorm    MultiStepLR    0.3737  0.3732   0.3787  \n",
       "498      LayerNorm           None    0.4732  0.3732   0.3787  \n",
       "499      LayerNorm  ExponentialLR    0.4751  0.3732   0.3787  \n",
       "500      LayerNorm    MultiStepLR    0.4776  0.3732   0.3787  \n",
       "503      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "446      LayerNorm    MultiStepLR    0.4682  0.3732   0.3787  \n",
       "519           None           None    0.3735  0.3732   0.3787  \n",
       "520           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "521           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "522      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "523      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "524      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "494           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "493           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "492           None           None    0.3735  0.3732   0.3787  \n",
       "476      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "475      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "474      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "473      LayerNorm    MultiStepLR    0.4727  0.3732   0.3787  \n",
       "472      LayerNorm  ExponentialLR    0.4997  0.3732   0.3787  \n",
       "471      LayerNorm           None    0.4694  0.3732   0.3787  \n",
       "469      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "468      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "467           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "466           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "465           None           None    0.3735  0.3732   0.3787  \n",
       "449      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "448      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "447      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "1009     LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "687      LayerNorm           None    0.4726  0.3732   0.3787  \n",
       "689      LayerNorm    MultiStepLR    0.4722  0.3732   0.3787  \n",
       "171      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "173      LayerNorm    MultiStepLR    0.3737  0.3732   0.3787  \n",
       "900      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "901      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "903      LayerNorm           None    0.4740  0.3732   0.3787  \n",
       "905      LayerNorm    MultiStepLR    0.4698  0.3732   0.3787  \n",
       "172      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "338      LayerNorm    MultiStepLR    0.4755  0.3732   0.3787  \n",
       "177      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "923           None    MultiStepLR    0.4731  0.3732   0.3787  \n",
       "924           None           None    0.3735  0.3732   0.3787  \n",
       "925           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "926           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "337      LayerNorm  ExponentialLR    0.4709  0.3732   0.3787  \n",
       "929      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "175      LayerNorm  ExponentialLR    0.4697  0.3732   0.3787  \n",
       "178      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "690      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "872           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "849      LayerNorm           None    0.4771  0.3732   0.3787  \n",
       "850      LayerNorm  ExponentialLR    0.4731  0.3732   0.3787  \n",
       "851      LayerNorm    MultiStepLR    0.4734  0.3732   0.3787  \n",
       "852      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "853      LayerNorm  ExponentialLR    0.3737  0.3732   0.3787  \n",
       "870           None           None    0.3735  0.3732   0.3787  \n",
       "873      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "179      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "875      LayerNorm    MultiStepLR    0.3737  0.3732   0.3787  \n",
       "876      LayerNorm           None    0.4752  0.3732   0.3787  \n",
       "877      LayerNorm  ExponentialLR    0.4671  0.3732   0.3787  \n",
       "878      LayerNorm    MultiStepLR    0.4789  0.3732   0.3787  \n",
       "880      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "881      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "930      LayerNorm           None    0.4757  0.3732   0.3787  \n",
       "933      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "336      LayerNorm           None    0.4723  0.3732   0.3787  \n",
       "144      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "986      LayerNorm    MultiStepLR    0.4706  0.3732   0.3787  \n",
       "150      LayerNorm           None    0.3734  0.3732   0.3787  \n",
       "331           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "149      LayerNorm    MultiStepLR    0.4770  0.3732   0.3787  \n",
       "148      LayerNorm  ExponentialLR    0.4738  0.3732   0.3787  \n",
       "146      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "330           None           None    0.3735  0.3732   0.3787  \n",
       "335      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "329           None    MultiStepLR    0.4750  0.3732   0.3787  \n",
       "328           None  ExponentialLR    0.4740  0.3732   0.3787  \n",
       "1005          None           None    0.3735  0.3732   0.3787  \n",
       "1006          None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "1007          None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "1008     LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "985      LayerNorm  ExponentialLR    0.5579  0.3732   0.3787  \n",
       "151      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "980           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "979           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "332           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "962      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "961      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "960      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "959      LayerNorm    MultiStepLR    0.4659  0.3732   0.3787  \n",
       "957      LayerNorm           None    0.4736  0.3732   0.3787  \n",
       "956      LayerNorm    MultiStepLR    0.3745  0.3732   0.3787  \n",
       "955      LayerNorm  ExponentialLR    0.3738  0.3732   0.3787  \n",
       "954      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "953           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "952           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "951           None           None    0.3735  0.3732   0.3787  \n",
       "334      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "848      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "846      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "199      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "765      LayerNorm           None    0.3736  0.3732   0.3787  \n",
       "200      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "228      LayerNorm           None    0.4738  0.3732   0.3787  \n",
       "368      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "229      LayerNorm  ExponentialLR    0.4783  0.3732   0.3787  \n",
       "231      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "746      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "745      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "744      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "743      LayerNorm    MultiStepLR    0.4685  0.3732   0.3787  \n",
       "742      LayerNorm  ExponentialLR    0.4736  0.3732   0.3787  \n",
       "741      LayerNorm           None    0.4690  0.3732   0.3787  \n",
       "740      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "737           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "736           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "735           None           None    0.3735  0.3732   0.3787  \n",
       "249           None           None    0.3735  0.3732   0.3787  \n",
       "717      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "716      LayerNorm    MultiStepLR    0.5514  0.3732   0.3787  \n",
       "715      LayerNorm  ExponentialLR    0.4730  0.3732   0.3787  \n",
       "714      LayerNorm           None    0.4756  0.3732   0.3787  \n",
       "710           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "709           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "708           None           None    0.3735  0.3732   0.3787  \n",
       "252      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "254      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "255      LayerNorm           None    0.4659  0.3732   0.3787  \n",
       "256      LayerNorm  ExponentialLR    0.4719  0.3732   0.3787  \n",
       "257      LayerNorm    MultiStepLR    0.4682  0.3732   0.3787  \n",
       "691      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "764           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "227      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "766      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "357           None           None    0.3735  0.3732   0.3787  \n",
       "796      LayerNorm  ExponentialLR    0.4727  0.3732   0.3787  \n",
       "797      LayerNorm    MultiStepLR    0.4676  0.3732   0.3787  \n",
       "800      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "360      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "359           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "358           None  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "204      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "361      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "821      LayerNorm    MultiStepLR    0.3740  0.3732   0.3787  \n",
       "823      LayerNorm  ExponentialLR    0.4733  0.3732   0.3787  \n",
       "824      LayerNorm    MultiStepLR    0.4725  0.3732   0.3787  \n",
       "203      LayerNorm    MultiStepLR    0.4664  0.3732   0.3787  \n",
       "827      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "201      LayerNorm           None    0.4757  0.3732   0.3787  \n",
       "768      LayerNorm           None    0.4771  0.3732   0.3787  \n",
       "795      LayerNorm           None    0.4710  0.3732   0.3787  \n",
       "282      LayerNorm           None    0.4942  0.3732   0.3787  \n",
       "364      LayerNorm  ExponentialLR    0.4746  0.3732   0.3787  \n",
       "226      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "772      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "773      LayerNorm    MultiStepLR    0.3736  0.3732   0.3787  \n",
       "367      LayerNorm  ExponentialLR    0.3735  0.3732   0.3787  \n",
       "366      LayerNorm           None    0.3735  0.3732   0.3787  \n",
       "365      LayerNorm    MultiStepLR    0.4744  0.3732   0.3787  \n",
       "225      LayerNorm           None    0.3736  0.3732   0.3787  \n",
       "224           None    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "363      LayerNorm           None    0.4819  0.3732   0.3787  \n",
       "362      LayerNorm    MultiStepLR    0.3735  0.3732   0.3787  \n",
       "232      LayerNorm  ExponentialLR    0.3749  0.3731   0.3787  \n",
       "1171     LayerNorm  ExponentialLR    0.3739  0.3731   0.3787  \n",
       "202      LayerNorm  ExponentialLR    0.4937  0.3731   0.3787  \n",
       "1148     LayerNorm    MultiStepLR    0.5449  0.3175   0.3120  \n",
       "636      LayerNorm           None    0.3646  0.3007   0.2899  \n",
       "822      LayerNorm           None    0.5170  0.3007   0.2899  \n",
       "1040     LayerNorm    MultiStepLR    0.5380  0.3007   0.2899  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "summary = pd.DataFrame.from_dict(total)\n",
    "summary_sort = summary.sort_values(by='F1-val', ascending=False)\n",
    "summary_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56735b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.232789,
     "end_time": "2023-03-20T22:23:18.994813",
     "exception": false,
     "start_time": "2023-03-20T22:23:18.762024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79d148",
   "metadata": {
    "papermill": {
     "duration": 0.230008,
     "end_time": "2023-03-20T22:23:19.458364",
     "exception": false,
     "start_time": "2023-03-20T22:23:19.228356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Наиболее хороший результат был получен при использовании стохастического градиентного спуска. Также в пятерку лучших результатов попали 3 стохастический градиентных спуска и 2 AdamW оптимизатора, что может объясняться большим количеством эпох и относительно малым рамзером пакета."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33650.236186,
   "end_time": "2023-03-20T22:23:22.389355",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-20T13:02:32.153169",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
